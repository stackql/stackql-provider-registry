openapi: 3.0.0
servers:
  - url: 'https://api.confluent.cloud'
    description: Confluent Cloud API
info:
  version: ''
  contact:
    name: Confluent Cloud
    url: 'https://www.confluent.io/cloud-contact-us/'
    email: support@confluent.io
  x-api-id: 46234552-5833-42eb-ba0f-883ad3f70d2b
  x-audience: external-public
  x-logo:
    url: 'https://assets.confluent.io/m/5ec23aa91903c00b/'
  title: Confluent Cloud APIs - connect
  description: connect
tags:
  - name: API Keys (iam/v2)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `ApiKey` objects represent access to different parts of Confluent Cloud. Some types
      of API keys represent access to a single cluster/resource such as a Kafka cluster,
      Schema Registry cluster or a ksqlDB cluster. Cloud API Keys represent access to resources within an organization
      that are not tied to a specific cluster, such as the Org API, IAM API, Metrics API or Connect API.

      The API allows you to list, create, update and delete your API Keys.


      Related guide: [API Keys in Confluent Cloud](https://docs.confluent.io/cloud/current/client-apps/api-keys.html).

      ## The API Keys Model
      <SchemaDefinition schemaRef="#/components/schemas/iam.v2.ApiKey" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `apikeys_per_org` | API Keys in one Confluent Cloud organization |
  - name: Environments (org/v2)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `Environment` objects represent an isolated namespace for your Confluent resources
      for organizational purposes.

      The API allows you to create, delete, and update your environments. You can retrieve
      individual environments as well as a list of all your environments.


      Related guide: [Environments in Confluent Cloud](https://docs.confluent.io/cloud/current/access-management/environments.html).

      ## The Environments Model
      <SchemaDefinition schemaRef="#/components/schemas/org.v2.Environment" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `environments_per_org` | Environments in one Confluent Cloud organization |
  - name: Organizations (org/v2)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `Organization` objects represent a customer organization. An organization contains all customer
      resources (e.g., Environments, Kafka Clusters, Service Accounts, API Keys) and is tied to a billing
      agreement (including any annual commitment or support plan).

      The API allows you to list, view, and update your organizations.


      Related guide: [Organizations for Confluent Cloud](https://docs.confluent.io/cloud/current/access-management/hierarchy/organizations/cloud-organization.html).

      ## The Organizations Model
      <SchemaDefinition schemaRef="#/components/schemas/org.v2.Organization" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `organizations_per_user` | Confluent Cloud organizations a user belongs to |
  - name: Users (iam/v2)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `User` objects represent individuals who may access your Confluent resources.

      The API allows you to retrieve, update, and delete individual users, as well as list of all your
      users. This API cannot be used to create new user accounts.


      Related guide: [Users in Confluent Cloud](https://docs.confluent.io/cloud/current/access-management/user-account.html).

      ## The Users Model
      <SchemaDefinition schemaRef="#/components/schemas/iam.v2.User" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `users_per_org` | Users in one Confluent Cloud organization |
  - name: Service Accounts (iam/v2)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `ServiceAccount` objects are typically used to represent applications and other non-human principals
      that may access your Confluent resources.

      The API allows you to create, retrieve, update, and delete individual service accounts, as well as
      list all your service accounts.


      Related guide: [Service Accounts in Confluent Cloud](https://docs.confluent.io/cloud/current/access-management/service-account.html).

      ## The Service Accounts Model
      <SchemaDefinition schemaRef="#/components/schemas/iam.v2.ServiceAccount" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `service_accounts_per_org` | Service Accounts in one Confluent Cloud organization |
  - name: Invitations (iam/v2)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `Invitation` objects represent invitations to invite users to join your organizations in Confluent Cloud.

      The API allows you to list all your invitations, as well as create, read, and delete a specified invitation.


      Related guide: [User invitations in Confluent Cloud](https://docs.confluent.io/cloud/current/access-management/identity/user-accounts.html).

      ## The Invitations Model
      <SchemaDefinition schemaRef="#/components/schemas/iam.v2.Invitation" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `invitations_per_org` | Invitations in a Confluent Cloud organization |
  - name: IP Groups (iam/v2)
    description: |-
      [![Limited Availability](https://img.shields.io/badge/Lifecycle%20Stage-Limited%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy) [![Request Access To IP Groups API](https://img.shields.io/badge/-Request%20Access%20To%20IP%20Groups%20API-%23bc8540)](mailto:cloud-support@confluent.io?subject=Request%20to%20join%20IP%20Filtering%20API%20Limited%20Access&body=I%E2%80%99d%20like%20to%20join%20the%20Confluent%20Cloud%20API%20Limited%20Access%20for%20IP%20Filtering.%0AMy%20Cloud%20Organization%20ID%20is%20%3Cretrieve%20from%20https%3A//confluent.cloud/settings/billing/payment%3E.%0A)

      Definitions of networks which can be named and referred by IP blocks, commonly used to attach to IP Filter rules.


      ## The IP Groups Model
      <SchemaDefinition schemaRef="#/components/schemas/iam.v2.IpGroup" />
  - name: IP Filters (iam/v2)
    description: |-
      [![Limited Availability](https://img.shields.io/badge/Lifecycle%20Stage-Limited%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy) [![Request Access To IP Filters API](https://img.shields.io/badge/-Request%20Access%20To%20IP%20Filters%20API-%23bc8540)](mailto:ccloud-api-access+iam-v2-limited-availability@confluent.io?subject=Request%20to%20join%20iam/v2%20API%20Limited%20Availability&body=I%E2%80%99d%20like%20to%20join%20the%20Confluent%20Cloud%20API%20Limited%20Availability%20for%20iam/v2%20to%20provide%20early%20feedback%21%20My%20Cloud%20Organization%20ID%20is%20%3Cretrieve%20from%20https%3A//confluent.cloud/settings/billing/payment%3E.)

      `IP Filter` objects are bindings between IP Groups and Confluent resource(s).
      For example, a binding between "CorpNet" and "Management APIs" will enforce that
      access must come from one of the CIDR blocks associated with CorpNet.
      If there are multiple IP filters bound to a resource, a request matching any of the CIDR blocks
      for any of the IP Group will allow the request.
      If there are no IP Filters for a resource, then access will be granted to requests originating
      from any IP Address.


      ## The IP Filters Model
      <SchemaDefinition schemaRef="#/components/schemas/iam.v2.IpFilter" />
  - name: Role Bindings (iam/v2)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      A role binding grants a Principal a role on resources that match a pattern.

      The API allows you to perform create, delete, and list operations on role bindings.


      Related guide: [Role-Based Access Control (RBAC)](https://docs.confluent.io/cloud/current/access-management/access-control/cloud-rbac.html).

      ## The Role Bindings Model
      <SchemaDefinition schemaRef="#/components/schemas/iam.v2.RoleBinding" />
  - name: Subscriptions (notifications/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `Subscription` objects represent the intent of the customers to get notifications of particular types.
      A subscription is created for a particular `NotificationType` and the user will get notifications on the
      `Integrations` that are provided while creating the subscription.

      This API allows you to create, retrieve, and update subscriptions,
      as well as to view the list of all your subscriptions. You can also delete subscriptions
      with RECOMMENDED or OPTIONAL notification types. Subscriptions with REQUIRED notification types cannot be deleted.


      Related guide: [Cloud Notifications](https://docs.confluent.io/cloud/current/monitoring/configure-notifications.html#notifications-for-ccloud).

      ## The Subscriptions Model
      <SchemaDefinition schemaRef="#/components/schemas/notifications.v1.Subscription" />
  - name: Integrations (notifications/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      You can create an `Integration` to specify how we can notify you when we receive an alert/notification for
      a subscription. Please note that you can only perform create, update and delete operations for integrations
      of type `Webhook`, `Slack` and `MsTeams`. You cannot create, update or delete integrations of type `RoleEmail`
      and `UserEmail`.


      Related guide: [Cloud Notifications](https://docs.confluent.io/cloud/current/monitoring/configure-notifications.html#notifications-for-ccloud).

      ## The Integrations Model
      <SchemaDefinition schemaRef="#/components/schemas/notifications.v1.Integration" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `integrations_per_org` | Maximum number of integrations in one Confluent Cloud organization |
  - name: Notification Types (notifications/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      The type of notifications (and their corresponding metadata) supported by Confluent.


      Related guide: [Cloud Notifications](https://docs.confluent.io/cloud/current/monitoring/configure-notifications.html#notifications-for-ccloud).

      ## The Notification Types Model
      <SchemaDefinition schemaRef="#/components/schemas/notifications.v1.NotificationType" />
  - name: Clusters (cmk/v2)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `Clusters` objects represent Apache Kafka Clusters on Confluent Cloud.

      The API allows you to list, create, read, update, and delete your Kafka clusters.


      Related guide: [Confluent Cloud Cluster Management for Apache Kafka APIs](https://docs.confluent.io/cloud/current/clusters/cluster-api.html).

      ## The Clusters Model
      <SchemaDefinition schemaRef="#/components/schemas/cmk.v2.Cluster" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `kafka_clusters_per_environment` | Number of clusters in one Confluent Cloud environment |
  - name: Clusters (ksqldbcm/v2)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `Cluster` represents a ksqlDB runtime that you can issue queries to using its API endpoint.
      It executes SQL statements and queries which under the hood get built into corresponding
      Kafka Streams topologies. The API allows you to list, create, read, and delete your ksqlDB clusters.


      Related guide: [ksqlDB in Confluent Cloud](https://docs.confluent.io/cloud/current/ksqldb/ksqldb-cluster-api.html).

      ## The Clusters Model
      <SchemaDefinition schemaRef="#/components/schemas/ksqldbcm.v2.Cluster" />

      ## Quotas and Limits
      This resource is subject to the following quotas:

      | Quota | Description |
      | --- | --- |
      | `ksql.limits.max_apps_per_cluster` | Clusters in one Confluent Cloud Kafka Cluster. |
  - name: Connectors (connect/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      API for Managed Connectors or Custom Connectors in Confluent Cloud.

      The API allows you to list, create, get, update and delete a Managed Connector or Custom Connector in Confluent Cloud.

      Connect metrics are available through the [Metrics v2 API](https://api.telemetry.confluent.cloud/docs#tag/Version-2).

      Related guide: [Confluent Cloud API and Managed Connectors](https://docs.confluent.io/cloud/current/connectors/connect-api-section.html).
  - name: Lifecycle (connect/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      API for managing the lifecycle for a Managed Connector or Custom Connector in Confluent Cloud. Operations currently supported are Pause and Resume.
  - name: Status (connect/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      API for requesting the status or the tasks for a Managed Connector or Custom Connector in Confluent Cloud.
  - name: Managed Connector Plugins (connect/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      API for Managed connectors in Confluent Cloud.
  - name: Offsets (connect/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      API for managing the offsets for a Managed Connector.

      Related guide: [Manage Connector Offsets](https://docs.confluent.io/cloud/current/connectors/offsets.html#manage-offsets-for-fully-managed-connectors-in-ccloud)
  - name: Custom Connector Plugins (connect/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      CustomConnectorPlugins objects represent Custom Connector Plugins on Confluent Cloud.
      The API allows you to list, create, read, update, and delete your Custom Connector Plugins.
      Related guide:
      [Custom Connector Plugin API](https://docs.confluent.io/cloud/current/connectors/connect-api-section.html).


      ## The Custom Connector Plugins Model
      <SchemaDefinition schemaRef="#/components/schemas/connect.v1.CustomConnectorPlugin" />
  - name: Presigned Urls (connect/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      Request a presigned upload URL for new Custom Connector Plugin. Note that
      the URL policy expires in one hour. If the policy expires, you can request
      a new presigned upload URL.

      Related guide:
      [Custom Connector Plugin API](https://docs.confluent.io/cloud/current/connectors/connect-api-section.html).


      ## The Presigned Urls Model
      <SchemaDefinition schemaRef="#/components/schemas/connect.v1.PresignedUrl" />
  - name: Cluster (v3)
    description: '[![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)'
  - name: Configs (v3)
    description: '[![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)'
  - name: ACL (v3)
    description: '[![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)'
  - name: Consumer Group (v3)
    description: '[![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)'
  - name: Partition (v3)
    description: '[![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)'
  - name: Topic (v3)
    description: '[![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)'
  - name: Records (v3)
    description: '[![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)'
  - name: Cluster Linking (v3)
    description: '[![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)'
  - name: Applied Quotas (service-quota/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      A `quota` object represents a quota configuration for a specific Confluent Cloud resource.
      Use this API to retrieve an individual quota or list of quotas for a given scope.


      Related guide: [Service Quotas for Confluent Cloud](https://docs.confluent.io/cloud/current/quotas/index.html).

      ## The Applied Quotas Model
      <SchemaDefinition schemaRef="#/components/schemas/service-quota.v1.AppliedQuota" />
  - name: Scopes (service-quota/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      Gets a list of all available scopes for applied quotas.


      Related guide: [Quota Scopes](https://docs.confluent.io/cloud/current/quotas/quotas.html#query-for-scopes).

      ## The Scopes Model
      <SchemaDefinition schemaRef="#/components/schemas/service-quota.v1.Scope" />
  - name: Entitlements (partner/v2)
    description: |
      [![Early Access](https://img.shields.io/badge/Lifecycle%20Stage-Early%20Access-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy) [![Request Access To Partner v2](https://img.shields.io/badge/-Request%20Access%20To%20Partner%20v2-%23bc8540)](mailto:ccloud-api-access+partner-v2-early-access@confluent.io?subject=Request%20to%20join%20partner/v2%20API%20Early%20Access&body=I%E2%80%99d%20like%20to%20join%20the%20Confluent%20Cloud%20API%20Early%20Access%20for%20partner/v2%20to%20provide%20early%20feedback%21%20My%20Cloud%20Organization%20ID%20is%20%3Cretrieve%20from%20https%3A//confluent.cloud/settings/billing/payment%3E.)

      `Entitlement` objects represent metadata about a marketplace entitlement.

      An entitlement includes metadata about a marketplace purchase
      (start date, end date, billing information, partner IDs, etc).
      The API allows partners to create, read, and list entitlements. (Unless you
      need entitlement creation and customer registration to be separate,
      we recommend using the Signup API to create an organization and entitlement
      at the same time)

      The API only allows authorized partners to interact with the Entitlements API.
  - name: Regions (srcm/v2)
    description: |-
      [![Deprecated](https://img.shields.io/badge/Lifecycle%20Stage-Deprecated-%23ff005c)](#section/Versioning/API-Lifecycle-Policy)

      `Region` objects represent cloud provider regions available when placing Schema Registry clusters.
      The API allows you to list Schema Registry regions.


      Related guides:
      * [Confluent Cloud providers and region support](https://docs.confluent.io/cloud/current/stream-governance/packages.html#cloud-providers-and-region-support).
      * [srcm/v3 Migration Guide](https://docs.confluent.io/cloud/current/stream-governance/packages.html#deprecation-of-srcm-v2-clusters-and-regions-apis-and-upgrade-guide).


      ## The Regions Model
      <SchemaDefinition schemaRef="#/components/schemas/srcm.v2.Region" />
  - name: Clusters (srcm/v2)
    description: |-
      [![Deprecated](https://img.shields.io/badge/Lifecycle%20Stage-Deprecated-%23ff005c)](#section/Versioning/API-Lifecycle-Policy)

      `Clusters` objects represent Schema Registry Clusters on Confluent Cloud.

      The API allows you to list, create, read, and delete your Schema Registry clusters.


      Related guides:
      * [Confluent Cloud Schema Registry Cluster APIs](https://docs.confluent.io/cloud/current/stream-governance/clusters-regions-api.html#schema-registry-cluster-management).
      * [srcm/v3 Migration Guide](https://docs.confluent.io/cloud/current/stream-governance/packages.html#deprecation-of-srcm-v2-clusters-and-regions-apis-and-upgrade-guide).


      ## The Clusters Model
      <SchemaDefinition schemaRef="#/components/schemas/srcm.v2.Cluster" />
  - name: Clusters (srcm/v3)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `Clusters` objects represent Schema Registry Clusters on Confluent Cloud.

      The API allows you to list and read your Schema Registry clusters.


      Related guide: [Confluent Cloud Schema Registry Cluster APIs](https://docs.confluent.io/cloud/current/stream-governance/clusters-regions-api.html#schema-registry-cluster-management).

      ## The Clusters Model
      <SchemaDefinition schemaRef="#/components/schemas/srcm.v3.Cluster" />
  - name: Compatibility (v1)
    description: |-
      [![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      The API allows you to test schema compatibility.

      Related guide: [Manage Schemas in Confluent Cloud](https://docs.confluent.io/cloud/current/sr/schemas-manage.html#manage-schemas-in-ccloud).
  - name: Config (v1)
    description: |-
      [![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      The API allows you to manage and query schema compatibility settings and cluster configurations.

      Related guide: [Manage Schemas in Confluent Cloud](https://docs.confluent.io/cloud/current/sr/schemas-manage.html#manage-schemas-in-ccloud).
  - name: Contexts (v1)
    description: |-
      [![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      The API allows you to retrieve information about schema contexts.

      Related guide: [Manage Schemas in Confluent Cloud](https://docs.confluent.io/cloud/current/sr/schemas-manage.html#manage-schemas-in-ccloud).
  - name: Exporters (v1)
    description: |-
      [![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      The API allows you to create, retrieve, update, and delete exporters.

      Related guide: [Manage Schemas in Confluent Cloud](https://docs.confluent.io/cloud/current/sr/schemas-manage.html#manage-schemas-in-ccloud).
  - name: Modes (v1)
    description: |-
      [![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      The API allows you to create, retrieve, update, and delete schema subjects modes of operation.

      Related guide: [Manage Schemas in Confluent Cloud](https://docs.confluent.io/cloud/current/sr/schemas-manage.html#manage-schemas-in-ccloud).
  - name: Schemas (v1)
    description: |-
      [![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      The API allows you to create, retrieve, update, and delete schemas.

      Related guide: [Manage Schemas in Confluent Cloud](https://docs.confluent.io/cloud/current/sr/schemas-manage.html#manage-schemas-in-ccloud).
  - name: Subjects (v1)
    description: |-
      [![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      The API allows you to create, retrieve, update, and delete schema subjects and versions.

      Related guide: [Manage Schemas in Confluent Cloud](https://docs.confluent.io/cloud/current/sr/schemas-manage.html#manage-schemas-in-ccloud).
  - name: Key Encryption Keys (v1)
    description: |-
      [![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      The API allows you to create, retrieve, update, and delete key encryption keys.

      Related guide: [Manage Schemas in Confluent Cloud](https://docs.confluent.io/cloud/current/sr/schemas-manage.html#manage-schemas-in-ccloud).
  - name: Data Encryption Keys (v1)
    description: |-
      [![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      The API allows you to create, retrieve, update, and delete data encryption keys.

      Related guide: [Manage Schemas in Confluent Cloud](https://docs.confluent.io/cloud/current/sr/schemas-manage.html#manage-schemas-in-ccloud).
  - name: Entity (v1)
    description: |-
      [![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      The API allows you to create, retrieve, update, and delete catalog entities.

      Related guide: [Catalog API Documentation](https://docs.confluent.io/cloud/current/stream-governance/stream-catalog.html#catalog-api-documentation).
  - name: Search (v1)
    description: |-
      [![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      The API allows you to search for entities.

      Related guide: [Catalog API Documentation](https://docs.confluent.io/cloud/current/stream-governance/stream-catalog.html#catalog-api-documentation).
  - name: Types (v1)
    description: |-
      [![Generally Available](https://img.shields.io/badge/Lifecycle%20Stage-Generally%20Available-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      The API allows you to create, retrieve, update, and delete catalog types such as tag definitions.

      Related guide: [Catalog API Documentation](https://docs.confluent.io/cloud/current/stream-governance/stream-catalog.html#catalog-api-documentation).
  - name: Provider Shared Resources (cdx/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `ProviderSharedResource` object contains details of the data stream
      (topic, schema registry subjects, sharing metadata) that you have shared through Stream Sharing.


      ## The Provider Shared Resources Model
      <SchemaDefinition schemaRef="#/components/schemas/cdx.v1.ProviderSharedResource" />
  - name: Provider Shares (cdx/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `ProviderShare` object respresents the share that you have created through Stream Sharing.


      Related guide: [Provider Stream Shares in Confluent Cloud](https://docs.confluent.io/cloud/current/stream-sharing/produce-shared-data.html#stream-shares).

      ## The Provider Shares Model
      <SchemaDefinition schemaRef="#/components/schemas/cdx.v1.ProviderShare" />
  - name: Consumer Shared Resources (cdx/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `ConsumerSharedResource` object contains details of the data stream
      (topic, schema registry subjects, sharing metadata) that you received through Stream Sharing.


      ## The Consumer Shared Resources Model
      <SchemaDefinition schemaRef="#/components/schemas/cdx.v1.ConsumerSharedResource" />
  - name: Consumer Shares (cdx/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `ConsumerShare` object respresents the share that you received through Stream Sharing.


      Related guide: [Consumer Stream Shares in Confluent Cloud](https://docs.confluent.io/cloud/current/stream-sharing/consume-shared-data.html).

      ## The Consumer Shares Model
      <SchemaDefinition schemaRef="#/components/schemas/cdx.v1.ConsumerShare" />
  - name: Shared Tokens (cdx/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      Encrypted Token shared with consumer


      ## The Shared Tokens Model
      <SchemaDefinition schemaRef="#/components/schemas/cdx.v1.SharedToken" />
  - name: Opt Ins (cdx/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      Stream sharing opt in options

      ## The Opt Ins Model
      <SchemaDefinition schemaRef="#/components/schemas/cdx.v1.OptIn" />
  - name: Organizations (partner/v2)
    description: |
      [![Early Access](https://img.shields.io/badge/Lifecycle%20Stage-Early%20Access-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy) [![Request Access To Partner v2](https://img.shields.io/badge/-Request%20Access%20To%20Partner%20v2-%23bc8540)](mailto:ccloud-api-access+partner-v2-early-access@confluent.io?subject=Request%20to%20join%20partner/v2%20API%20Early%20Access&body=I%E2%80%99d%20like%20to%20join%20the%20Confluent%20Cloud%20API%20Early%20Access%20for%20partner/v2%20to%20provide%20early%20feedback%21%20My%20Cloud%20Organization%20ID%20is%20%3Cretrieve%20from%20https%3A//confluent.cloud/settings/billing/payment%3E.)

      `Organizations` objects represent an entire Confluent Cloud organization.
      Partners are allowed to get an organization they have signed up or
      list all organizations they have signed up.
  - name: Signup (partner/v2)
    description: |
      [![Early Access](https://img.shields.io/badge/Lifecycle%20Stage-Early%20Access-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy) [![Request Access To Partner v2](https://img.shields.io/badge/-Request%20Access%20To%20Partner%20v2-%23bc8540)](mailto:ccloud-api-access+partner-v2-early-access@confluent.io?subject=Request%20to%20join%20partner/v2%20API%20Early%20Access&body=I%E2%80%99d%20like%20to%20join%20the%20Confluent%20Cloud%20API%20Early%20Access%20for%20partner/v2%20to%20provide%20early%20feedback%21%20My%20Cloud%20Organization%20ID%20is%20%3Cretrieve%20from%20https%3A//confluent.cloud/settings/billing/payment%3E.)

      `Signup` APIs can only be performed by partners.
  - name: Networks (networking/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `Network` represents a network (VPC) in Confluent Cloud. All Networks exist within Confluent-managed cloud
      provider accounts. Dedicated networks support more networking options but can only contain Dedicated clusters.
      Shared networks can contain any cluster type.

      The API allows you to list, create, read, update, and delete your networks.


      Related guide: [APIs to manage networks in Confluent Cloud](https://docs.confluent.io/cloud/current/networking/overview.html).

      ## The Networks Model
      <SchemaDefinition schemaRef="#/components/schemas/networking.v1.Network" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `dedicated_networks_per_environment` | Number of dedicated networks per Confluent Cloud environment |
  - name: Peerings (networking/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      Add or remove VPC/VNet peering connections between your VPC/VNet and Confluent Cloud.

      Related guides:
      * [Use VPC peering connections with Confluent Cloud on AWS](https://docs.confluent.io/cloud/current/networking/peering/aws-peering.html).
      * [Use VNet peering connections with Confluent Cloud on Azure](https://docs.confluent.io/cloud/current/networking/peering/azure-peering.html).
      * [Use VPC peering connections with Confluent Cloud on Google Cloud](https://docs.confluent.io/cloud/current/networking/peering/gcp-peering.html).


      ## The Peerings Model
      <SchemaDefinition schemaRef="#/components/schemas/networking.v1.Peering" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `peerings_per_network` | Number of peerings per network |
  - name: Transit Gateway Attachments (networking/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      AWS Transit Gateway Attachments

      Related guide: [APIs to manage AWS Transit Gateway Attachments](https://docs.confluent.io/cloud/current/networking/aws-transit-gateway.html).

      ## The Transit Gateway Attachments Model
      <SchemaDefinition schemaRef="#/components/schemas/networking.v1.TransitGatewayAttachment" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `tgw_attachments_per_network` | Number of TGW attachments per network |
  - name: Private Link Accesses (networking/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      Add or remove access to PrivateLink endpoints by AWS account, Azure subscription and GCP project ID.

      Related guides:
      * [Use Google Cloud Private Service Connect with Confluent Cloud](https://docs.confluent.io/cloud/current/networking/private-links/gcp-private-service-connect.html).
      * [Use Azure Private Link with Confluent Cloud](https://docs.confluent.io/cloud/current/networking/private-links/azure-privatelink.html).
      * [Use AWS PrivateLink with Confluent Cloud](https://docs.confluent.io/cloud/current/networking/private-links/aws-privatelink.html).


      ## The Private Link Accesses Model
      <SchemaDefinition schemaRef="#/components/schemas/networking.v1.PrivateLinkAccess" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `private_link_accounts_per_network` | Number of AWS accounts per network |
      | `private_link_subscriptions_per_network` | Number of Azure subscriptions per network |
      | `private_service_connect_projects_per_network` | Number of GCP projects per network |
  - name: Network Link Services (networking/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      Network Link Service is associated with a Private Link Confluent Cloud Network.
      It enables connectivity from other Private Link Confluent Cloud Networks based on
      the configured accept policies.


      Related guide: [Network Linking Overview](https://docs.confluent.io/cloud/current/networking/network-linking.html).

      ## The Network Link Services Model
      <SchemaDefinition schemaRef="#/components/schemas/networking.v1.NetworkLinkService" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `network_link_service_per_network` | Number of network link services per network |
  - name: Network Link Endpoints (networking/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      A Network Link Enpoint is associated with a Private Link Confluent Cloud Network at the origin and a
      Network Link Service (associated with another Private Link Confluent Cloud Network) at the target.
      It enables connectivity between the origin network and the target network.
      It can only be associated with a Private Link network.


      Related guide: [Network Linking Overview](https://docs.confluent.io/cloud/current/networking/network-linking.html).

      ## The Network Link Endpoints Model
      <SchemaDefinition schemaRef="#/components/schemas/networking.v1.NetworkLinkEndpoint" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `network_link_endpoints_per_network` | Number of network link endpoints per network |
  - name: Network Link Service Associations (networking/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      List of incoming Network Link Enpoints associated with the Network Link Service.


      Related guide: [Network Linking Overview](https://docs.confluent.io/cloud/current/networking/network-linking.html).

      ## The Network Link Service Associations Model
      <SchemaDefinition schemaRef="#/components/schemas/networking.v1.NetworkLinkServiceAssociation" />
  - name: Gateways (networking/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      A gateway is a resource that defines network access to Confluent cloud resources.


      ## The Gateways Model
      <SchemaDefinition schemaRef="#/components/schemas/networking.v1.Gateway" />
  - name: IP Addresses (networking/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      IP Addresses

      Related guide: [Use Public Egress IP addresses on Confluent Cloud](https://docs.confluent.io/cloud/current/networking/static-egress-ip-addresses.html)

      ## The IP Addresses Model
      <SchemaDefinition schemaRef="#/components/schemas/networking.v1.IpAddress" />
  - name: Private Link Attachments (networking/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      PrivateLink attachment objects represent reservations to establish PrivateLink connections
      to a cloud region in order to access resources that belong to a Confluent Cloud Environment.
      The API allows you to list, create, read update and delete your PrivateLink attachments.


      ## The Private Link Attachments Model
      <SchemaDefinition schemaRef="#/components/schemas/networking.v1.PrivateLinkAttachment" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `private_link_attachments_per_environment` | Number of PrivateLink Attachments per environment |
  - name: Private Link Attachment Connections (networking/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      PrivateLink attachment connection objects represent connections established to a cloud region
      in order to access resources that belong to a Confluent Cloud Environment.
      The API allows you to list, create, read update and delete your PrivateLink attachment connections.


      ## The Private Link Attachment Connections Model
      <SchemaDefinition schemaRef="#/components/schemas/networking.v1.PrivateLinkAttachmentConnection" />
  - name: Identity Providers (iam/v2)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `IdentityProvider` objects represent external OAuth-OIDC providers in Confluent Cloud.

      The API allows you to list, create, read, update, and delete your Identity Provider.


      Related guide: [OAuth for Confluent Cloud](https://docs.confluent.io/cloud/current/access-management/authenticate/oauth/overview.html).

      ## The Identity Providers Model
      <SchemaDefinition schemaRef="#/components/schemas/iam.v2.IdentityProvider" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `identity_providers_per_org` | Number of OAuth identity providers per organization |
      | `public_keys_per_provider` | Number of public keys saved per identity provider |
  - name: Jwks (iam/v2)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `JWKS` objects represent public key sets for a specific OAuth/OpenID Connect provider within
      Confluent Cloud.

      The API allows you to refresh JWKS public key data.


      Related guide: [OAuth for Confluent Cloud](https://docs.confluent.io/cloud/current/access-management/authenticate/oauth/overview.html).

      ## The Jwks Model
      <SchemaDefinition schemaRef="#/components/schemas/iam.v2.Jwks" />
  - name: Identity Pools (iam/v2)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `IdentityPool` objects represent groups of identities tied to a given a `IdentityProvider`
      that authorizes them to Confluent Cloud resources.

      It provides a mapping functionality of your `Identity Provider` user to a Confluent identity pool that
      is then used to provide access to Confluent Resources.


      Related guide: [Use identity pools with your OAuth provider](https://docs.confluent.io/cloud/current/access-management/authenticate/oauth/identity-pools.html).

      ## The Identity Pools Model
      <SchemaDefinition schemaRef="#/components/schemas/iam.v2.IdentityPool" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `identity_pools_per_provider` | Number of Identity Pools per Identity Provider |
  - name: OAuth Tokens (sts/v1)
    description: |
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      OAuth Token is a [JSON Web Token (JWT)](https://www.rfc-editor.org/rfc/rfc7519) that enables the use of
      external identities to access Confluent Cloud APIs
  - name: Client Quotas (kafka-quotas/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `ClientQuota` objects represent Client Quotas you can set at the service account level.

      The API allows you to list, create, read, update, and delete your client quotas.


      Related guide: [Client Quotas in Confluent Cloud](https://docs.confluent.io/cloud/current/clusters/client-quotas.html).

      ## The Client Quotas Model
      <SchemaDefinition schemaRef="#/components/schemas/kafka-quotas.v1.ClientQuota" />
  - name: Pipelines (sd/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `Pipeline` objects represent information about a user-defined pipeline of Confluent Cloud components.
      The pipeline's content is available separately.

      The API allows you to create, retrieve, update, and delete your pipelines,
      as well as list all of your pipelines for the particular environment and Kafka cluster.


      Related guide: [Pipelines in Confluent Cloud](https://docs.confluent.io/cloud/current/stream-designer/).

      ## The Pipelines Model
      <SchemaDefinition schemaRef="#/components/schemas/sd.v1.Pipeline" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `pipelines_per_org` | Pipelines in one Confluent Cloud organization |
      | `pipelines_per_cluster` | Pipelines in one Confluent Cloud Kafka cluster |
  - name: Keys (byok/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `Key` objects represent customer managed keys on dedicated Confluent Cloud clusters.

      Keys are used to protect data at rest stored in your dedicated Confluent Cloud clusters on AWS, Azure, and GCP.
      This API allows you to upload and retrieve self-managed keys on Confluent Cloud.


      Related guide: [Confluent Cloud Bring Your Own Key (BYOK) Management API](https://docs.confluent.io/cloud/current/clusters/byok/index.html).

      ## The Keys Model
      <SchemaDefinition schemaRef="#/components/schemas/byok.v1.Key" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `byok.max_keys.per_org` | BYOK keys in one Confluent Cloud organisation. |
  - name: Costs (billing/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `Cost` objects represent the aggregated billing costs for an organization


      Related guide: [Retrieve costs for a range of dates](https://docs.confluent.io/cloud/current/billing/overview.html#retrieve-costs-for-a-range-of-dates).

      ## The Costs Model
      <SchemaDefinition schemaRef="#/components/schemas/billing.v1.Cost" />
  - name: Group Mappings (iam/v2/sso)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `GroupMapping` objects establish relationships between user groups in your SSO
      identity provider and specific RBAC roles in Confluent Cloud.

      Group mappings enable automated and secure access control to Confluent Cloud resources,
      reducing administrative workload by streamlining user provisioning and authorization.


      Related guide: [Use group mappings with your SSO identity provider](https://docs.confluent.io/cloud/current/access-management/authenticate/sso/group-mapping/overview.html).

      ## The Group Mappings Model
      <SchemaDefinition schemaRef="#/components/schemas/iam.v2.sso.GroupMapping" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `group_mappings_per_org` | Number of group mappings per organization |
  - name: Compute Pools (fcpm/v2)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      A Compute Pool represents a set of compute resources that is used to run your Queries.
      The resources (CPUs, memory,) provided by a Compute Pool are shared between all Queries that use it.


      ## The Compute Pools Model
      <SchemaDefinition schemaRef="#/components/schemas/fcpm.v2.ComputePool" />
  - name: Regions (fcpm/v2)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `Region` objects represent cloud provider regions available when placing Flink compute pools.
      The API allows you to list Flink regions.


      ## The Regions Model
      <SchemaDefinition schemaRef="#/components/schemas/fcpm.v2.Region" />
  - name: Statements (sql/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `Statement` represents a core resource used to model SQL statements for execution.
      A statement generalizes DDL, DML, DQL, etc., but doesnt attempt to handle session
      management or any higher-level functionality.
      The API allows you to list, create, read, and delete your statements.
      ## The Statements Model
      <SchemaDefinition schemaRef="#/components/schemas/sql.v1.Statement" />
  - name: Statement Results (sql/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `StatementResult` represents a result of a `Statement` resource.
      The API allows you to read your statement's results.
      ## The Statement Results Model
      <SchemaDefinition schemaRef="#/components/schemas/sql.v1.StatementResult" />
  - name: Statement Exceptions (sql/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `StatementException` represents an exception of a `Statement` resource.
      The API allows you to read your statement's exceptions.
      ## The Statement Exceptions Model
      <SchemaDefinition schemaRef="#/components/schemas/sql.v1.StatementException" />
  - name: Connections (sql/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `Connection` represents a core resource used to model SQL connections for execution.
      A connection generalizes DDL, DML, DQL, etc., but doesnt attempt to handle session
      management or any higher-level functionality.
      The API allows you to list, create, read, and delete your connections.
      ## The Connections Model
      <SchemaDefinition schemaRef="#/components/schemas/sql.v1.Connection" />
  - name: DNS Forwarders (networking/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      Add, remove, and update DNS forwarder for your gateway.

      Related guides:
      * [Use VPC peering connections with Confluent Cloud on AWS](https://docs.confluent.io/cloud/current/networking/peering/aws-peering.html).
      * [Use VNet peering connections with Confluent Cloud on Azure](https://docs.confluent.io/cloud/current/networking/peering/azure-peering.html).


      ## The DNS Forwarders Model
      <SchemaDefinition schemaRef="#/components/schemas/networking.v1.DnsForwarder" />
  - name: Access Points (networking/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      AccessPoint objects represent network connections in and out of Gateways.
      This API allows you to list, create, read, update, and delete your access points.


      ## The Access Points Model
      <SchemaDefinition schemaRef="#/components/schemas/networking.v1.AccessPoint" />
  - name: DNS Records (networking/v1)
    description: |-
      [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      DNS record objects are associated with Confluent Cloud networking resources. This API allows you to list, create, read, update, and delete your DNS records.

      ## The DNS Records Model
      <SchemaDefinition schemaRef="#/components/schemas/networking.v1.DnsRecord" />
  - name: Certificate Authorities (iam/v2)
    description: |-
      [![Limited Availability](https://img.shields.io/badge/Lifecycle%20Stage-Limited%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `CertificateAuthority` objects represent signing certificate authorities in Confluent Cloud.

      The API allows you to list, create, read, update, and delete your Certificate Authority.


      Related guide: [Manage certificate authorities used for client authentication with X.509 certificates.](https://docs.confluent.io/cloud/current/access-management/authenticate/mtls/overview.html).

      ## The Certificate Authorities Model
      <SchemaDefinition schemaRef="#/components/schemas/iam.v2.CertificateAuthority" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `certificate_authorities_per_org` | Number of certificate authorities per organization |
  - name: Certificate Identity Pools (iam/v2)
    description: |-
      [![Limited Availability](https://img.shields.io/badge/Lifecycle%20Stage-Limited%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

      `Identitypool` objects represent workload identities in Confluent Cloud.

      The API allows you to list, create, read, update, and delete your identity pools associated
      with Certificate Authorities


      Related guide: [Manage Certificate Identity Pools for Granular Client Access Management](https://docs.confluent.io/cloud/current/access-management/authenticate/mtls/configure.html#step-2-create-certificate-identity-pools-for-granular-access-control).

      ## The Certificate Identity Pools Model
      <SchemaDefinition schemaRef="#/components/schemas/iam.v2.CertificateIdentityPool" />

      ## Quotas and Limits
      This resource is subject to the [following quotas](https://docs.confluent.io/cloud/current/quotas/overview.html):

      | Quota | Description |
      | --- | --- |
      | `identity_pools_per_certificate_authority` | Number of Identity Pools per Certificate Authority |
  - name: Integrations (pim/v1)
    description: |-
      [![Early Access](https://img.shields.io/badge/Lifecycle%20Stage-Early%20Access-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy) [![Request Access To Provider Integration](https://img.shields.io/badge/-Request%20Access%20To%20Provider%20Integration-%23bc8540)](mailto:ccloud-api-access+pim-v1-early-access@confluent.io?subject=Request%20to%20join%20pim/v1%20API%20Early%20Access&body=I%E2%80%99d%20like%20to%20join%20the%20Confluent%20Cloud%20API%20Early%20Access%20for%20pim/v1%20to%20provide%20early%20feedback%21%20My%20Cloud%20Organization%20ID%20is%20%3Cretrieve%20from%20https%3A//confluent.cloud/settings/billing/payment%3E.)

      `Provider Integration` objects represent access to public cloud service provider (CSP) resources
      that may be accessed by Confluent resources (for example, connectors).

      The API allows you to create, retrieve, and delete individual integrations, and also obtain a
      list of all your provider integrations.


      Related guide: [Provider Integration in Confluent Cloud](https://docs.confluent.io/home/overview.html).

      ## The Integrations Model
      <SchemaDefinition schemaRef="#/components/schemas/pim.v1.Integration" />
  - name: Flink Artifacts (artifact/v1)
    description: |-
      [![Early Access](https://img.shields.io/badge/Lifecycle%20Stage-Early%20Access-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy) [![Request Access To Flink Artifact API EA](https://img.shields.io/badge/-Request%20Access%20To%20Flink%20Artifact%20API%20EA-%23bc8540)](mailto:ccloud-api-access+artifact-v1-early-access@confluent.io?subject=Request%20to%20join%20artifact/v1%20API%20Early%20Access&body=I%E2%80%99d%20like%20to%20join%20the%20Confluent%20Cloud%20API%20Early%20Access%20for%20artifact/v1%20to%20provide%20early%20feedback%21%20My%20Cloud%20Organization%20ID%20is%20%3Cretrieve%20from%20https%3A//confluent.cloud/settings/billing/payment%3E.)

      FlinkArtifact objects represent Flink Artifacts on Confluent Cloud.


      ## The Flink Artifacts Model
      <SchemaDefinition schemaRef="#/components/schemas/artifact.v1.FlinkArtifact" />
  - name: Presigned Urls (artifact/v1)
    description: |-
      [![Early Access](https://img.shields.io/badge/Lifecycle%20Stage-Early%20Access-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy) [![Request Access To Flink Artifact API EA](https://img.shields.io/badge/-Request%20Access%20To%20Flink%20Artifact%20API%20EA-%23bc8540)](mailto:ccloud-api-access+artifact-v1-early-access@confluent.io?subject=Request%20to%20join%20artifact/v1%20API%20Early%20Access&body=I%E2%80%99d%20like%20to%20join%20the%20Confluent%20Cloud%20API%20Early%20Access%20for%20artifact/v1%20to%20provide%20early%20feedback%21%20My%20Cloud%20Organization%20ID%20is%20%3Cretrieve%20from%20https%3A//confluent.cloud/settings/billing/payment%3E.)

      Request a presigned upload URL for new Flink Artifact. Note that
      the URL policy expires in one hour. If the policy expires, you can request
      a new presigned upload URL.


      ## The Presigned Urls Model
      <SchemaDefinition schemaRef="#/components/schemas/artifact.v1.PresignedUrl" />
  - name: Flink Artifact Versions (artifact/v1)
    description: |-
      [![Early Access](https://img.shields.io/badge/Lifecycle%20Stage-Early%20Access-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy) [![Request Access To Flink Artifact API EA](https://img.shields.io/badge/-Request%20Access%20To%20Flink%20Artifact%20API%20EA-%23bc8540)](mailto:ccloud-api-access+artifact-v1-early-access@confluent.io?subject=Request%20to%20join%20artifact/v1%20API%20Early%20Access&body=I%E2%80%99d%20like%20to%20join%20the%20Confluent%20Cloud%20API%20Early%20Access%20for%20artifact/v1%20to%20provide%20early%20feedback%21%20My%20Cloud%20Organization%20ID%20is%20%3Cretrieve%20from%20https%3A//confluent.cloud/settings/billing/payment%3E.)

      FlinkArtifactVersion objects represent Flink Artifact Versions on Confluent Cloud.


      ## The Flink Artifact Versions Model
      <SchemaDefinition schemaRef="#/components/schemas/artifact.v1.FlinkArtifactVersion" />
components:
  schemas:
    AclOperation:
      type: string
      x-extensible-enum:
        - UNKNOWN
        - ANY
        - ALL
        - READ
        - WRITE
        - CREATE
        - DELETE
        - ALTER
        - DESCRIBE
        - CLUSTER_ACTION
        - DESCRIBE_CONFIGS
        - ALTER_CONFIGS
        - IDEMPOTENT_WRITE
    AclPatternType:
      type: string
      x-extensible-enum:
        - UNKNOWN
        - ANY
        - MATCH
        - LITERAL
        - PREFIXED
    AclPermission:
      type: string
      x-extensible-enum:
        - UNKNOWN
        - ANY
        - DENY
        - ALLOW
    AclResourceType:
      type: string
      enum:
        - UNKNOWN
        - ANY
        - TOPIC
        - GROUP
        - CLUSTER
        - TRANSACTIONAL_ID
        - DELEGATION_TOKEN
    BrokerTaskType:
      type: string
      enum:
        - add-broker
        - remove-broker
    MirrorTopicStatus:
      enum:
        - ACTIVE
        - FAILED
        - LINK_FAILED
        - LINK_PAUSED
        - PAUSED
        - PENDING_STOPPED
        - SOURCE_UNAVAILABLE
        - STOPPED
        - PENDING_MIRROR
        - PENDING_SYNCHRONIZE
        - PENDING_SETUP_FOR_RESTORE
        - PENDING_RESTORE
      type: string
    connect.v1.ConnectorError:
      type: object
      properties:
        error:
          type: object
          description: Connector Error with error code and message.
          properties:
            code:
              type: integer
              description: Error code for the type of error
            message:
              type: string
              description: Human readable error message
    AlterConfigBatchRequestData:
      type: object
      required:
        - data
      properties:
        data:
          type: array
          items:
            type: object
            required:
              - name
            properties:
              name:
                type: string
              value:
                type: string
                nullable: true
              operation:
                type: string
                x-extensible-enum:
                  - SET
                  - DELETE
                nullable: true
        validate_only:
          type: boolean
    CreateAclRequestData:
      type: object
      required:
        - resource_type
        - resource_name
        - pattern_type
        - principal
        - host
        - operation
        - permission
      properties:
        resource_type:
          $ref: '#/components/schemas/AclResourceType'
        resource_name:
          type: string
        pattern_type:
          $ref: '#/components/schemas/AclPatternType'
        principal:
          type: string
        host:
          type: string
        operation:
          $ref: '#/components/schemas/AclOperation'
        permission:
          $ref: '#/components/schemas/AclPermission'
    CreateAclRequestDataList:
      allOf:
        - type: object
          required:
            - data
          properties:
            data:
              type: array
              items:
                $ref: '#/components/schemas/CreateAclRequestData'
    CreateTopicRequestData:
      type: object
      required:
        - topic_name
      properties:
        topic_name:
          type: string
        partitions_count:
          type: integer
        replication_factor:
          type: integer
        configs:
          type: array
          items:
            type: object
            required:
              - name
            properties:
              name:
                type: string
              value:
                type: string
                nullable: true
        validate_only:
          type: boolean
    ProduceRequest:
      type: object
      properties:
        partition_id:
          type: integer
          nullable: true
          format: int32
        headers:
          type: array
          items:
            $ref: '#/components/schemas/ProduceRequestHeader'
        key:
          $ref: '#/components/schemas/ProduceRequestData'
        value:
          $ref: '#/components/schemas/ProduceRequestData'
        timestamp:
          type: string
          format: date-time
          nullable: true
    UpdateConfigRequestData:
      type: object
      properties:
        value:
          type: string
          nullable: true
    CreateLinkRequestData:
      properties:
        source_cluster_id:
          type: string
        destination_cluster_id:
          type: string
        remote_cluster_id:
          description: The expected remote cluster ID.
          type: string
        cluster_link_id:
          description: 'The expected cluster link ID. Can be provided when creating the second side of a bidirectional link for validating the link ID is as expected. If it''s not provided, it''s inferred from the remote cluster.'
          type: string
        configs:
          items:
            $ref: '#/components/schemas/ConfigData'
          type: array
      type: object
    UpdateLinkConfigRequestData:
      properties:
        value:
          type: string
      required:
        - value
      type: object
    CreateMirrorTopicRequestData:
      properties:
        source_topic_name:
          type: string
        mirror_topic_name:
          type: string
        replication_factor:
          type: integer
        configs:
          type: array
          items:
            $ref: '#/components/schemas/ConfigData'
      required:
        - source_topic_name
      type: object
    AlterMirrorsRequestData:
      properties:
        mirror_topic_names:
          description: The mirror topics specified as a list of topic names.
          type: array
          items:
            type: string
        mirror_topic_name_pattern:
          description: The mirror topics specified as a pattern.
          type: string
      type: object
    RemoveBrokersRequestData:
      properties:
        broker_ids:
          type: array
          items:
            type: integer
      required:
        - broker_ids
      type: object
    BrokerReplicaExclusionBatchRequestData:
      type: object
      required:
        - data
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/BrokerReplicaExclusionRequestData'
    ProduceRequestHeader:
      type: object
      required:
        - name
      properties:
        name:
          type: string
        value:
          type: string
          format: byte
          nullable: true
    ProduceRequestData:
      type: object
      properties:
        type:
          type: string
          x-extensible-enum:
            - BINARY
            - JSON
            - STRING
        data:
          $ref: '#/components/schemas/AnyValue'
      nullable: true
    ConfigData:
      example:
        name: name
        value: value
      properties:
        name:
          type: string
        value:
          nullable: true
          type: string
      required:
        - name
        - value
    BrokerReplicaExclusionRequestData:
      type: object
      required:
        - broker_id
        - reason
      properties:
        broker_id:
          type: integer
        reason:
          type: string
    AnyValue:
      nullable: true
    connect.v1.ConnectorWithOffsets:
      type: object
      properties:
        name:
          type: string
          description: Name of the connector
        config:
          type: object
          description: |-
            Configuration parameters for the connector. These configurations
            are the minimum set of key-value pairs which can be used to
            define how the connector connects Kafka to the external system.
            Some of these key-value pairs are common to all the connectors, such as
            connection parameters to Kafka, connector metadata, etc. The list
            of common connector configurations is as follows
            - cloud.environment
            - cloud.provider
            - connector.class
            - kafka.api.key
            - kafka.api.secret
            - kafka.endpoint
            - kafka.region
            - name
            A specific connector such as `GcsSink` would have additional
            parameters such as `gcs.bucket.name`, `flush.size`, etc.
          required:
            - cloud.environment
            - cloud.provider
            - connector.class
            - name
            - kafka.endpoint
            - kafka.region
            - kafka.api.key
            - kafka.api.secret
          properties:
            cloud.environment:
              type: string
              description: The cloud environment type.
            cloud.provider:
              type: string
              description: 'The cloud service provider, e.g. aws, azure, etc.'
              x-extensible-enum:
                - aws
                - azure
                - gcp
            connector.class:
              type: string
              description: 'The connector class name. E.g. BigQuerySink, GcsSink, etc.'
            name:
              type: string
              description: Name or alias of the class (plugin) for this connector.
            kafka.endpoint:
              type: string
              description: The Kafka cluster endpoint.
            kafka.region:
              type: string
              description: The Kafka cluster region.
            kafka.api.key:
              type: string
              description: The Kafka cluster API key.
            kafka.api.secret:
              type: string
              description: The Kafka cluster API secret.
              x-redact: true
          additionalProperties:
            type: string
        tasks:
          type: array
          description: List of active tasks generated by the connector
          items:
            type: object
            properties:
              connector:
                type: string
                description: The name of the connector the task belongs to
              task:
                type: integer
                description: Task ID within the connector
            required:
              - connector
              - task
        type:
          type: string
          description: 'Type of connector, sink or source'
          enum:
            - sink
            - source
        offsets:
          $ref: '#/components/schemas/connect.v1.Offsets'
      required:
        - name
        - config
    connect.v1.Offsets:
      type: array
      description: Array of offsets which are categorised into partitions.
      items:
        type: object
        properties:
          partition:
            type: object
            additionalProperties: true
            description: |-
              The partition information. For sink connectors this is the kafka topic and 
              partition. For source connectors this is depends on the partitions defined by the 
              source connector. For example, the table which this task is pulling data from in a
              JDBC based MySQL source connector.
              Please refer to the [documentation](https://docs.confluent.io/cloud/current/connectors/offsets.html#manage-offsets-for-fully-managed-connectors-in-ccloud) for 
              more information.
          offset:
            type: object
            additionalProperties: true
            description: |-
              The offset of the partition. For sink connectors this is the kafka offset. For 
              source connectors this is depends on the offset defined by the source connector. 
              For example, the timestamp and incrementing column info in a table, for a JDBC based 
              MySQL source connector.
              Please refer to the [documentation](https://docs.confluent.io/cloud/current/connectors/offsets.html#manage-offsets-for-fully-managed-connectors-in-ccloud) for 
              more information.
    connect.v1.ConnectorExpansionMap:
      type: object
      additionalProperties:
        $ref: '#/components/schemas/connect.v1.ConnectorExpansion'
    connect.v1.ConnectorExpansion:
      type: object
      description: Name of connector
      properties:
        id:
          type: object
          description: The ID of connector.
          properties:
            id:
              type: string
              description: The ID of the connector.
            id_type:
              type: string
              description: Type of the value in the `id` property.
        info:
          type: object
          description: Metadata of the connector.
          properties:
            name:
              type: string
              description: Name of the connector.
            config:
              type: object
              description: |-
                Configuration parameters for the connector. These configurations
                are the minimum set of key-value pairs (KVP) which are used to
                define how the connector connects Kafka to the external system.
                Some of these KVPs are common to all the connectors, such as
                connection parameters to Kafka, connector metadata, etc. The list
                of common connector configurations is as follows

                  - cloud.environment
                  - cloud.provider
                  - connector.class
                  - kafka.api.key
                  - kafka.api.secret
                  - kafka.endpoint
                  - kafka.region
                  - name

                For example, a connector like `GcsSink` would have additional
                parameters such as `gcs.bucket.name`, `flush.size`, etc.
              required:
                - cloud.environment
                - cloud.provider
                - connector.class
                - name
                - kafka.endpoint
                - kafka.region
                - kafka.api.key
                - kafka.api.secret
              properties:
                cloud.environment:
                  type: string
                  description: The cloud environment type.
                cloud.provider:
                  type: string
                  description: 'The cloud service provider, e.g. aws, azure, etc.'
                  x-extensible-enum:
                    - aws
                    - azure
                    - gcp
                connector.class:
                  type: string
                  description: 'The connector class name. E.g. BigQuerySink, GcsSink, etc.'
                name:
                  type: string
                  description: Name or alias of the class (plugin) for this connector.
                kafka.endpoint:
                  type: string
                  description: The kafka cluster endpoint.
                kafka.region:
                  type: string
                  description: The kafka cluster region.
                kafka.api.key:
                  type: string
                  description: The kafka cluster api key.
                kafka.api.secret:
                  type: string
                  description: The kafka cluster api secret key.
                  x-redact: true
              additionalProperties:
                type: string
        status:
          type: object
          description: Status of the connector and its tasks.
          properties:
            name:
              type: string
              description: The name of the connector.
            type:
              type: string
              description: 'Type of connector, sink or source.'
              enum:
                - sink
                - source
            connector:
              type: object
              description: A map containing connector status.
              required:
                - state
                - worker_id
              properties:
                state:
                  type: string
                  description: The state of the connector.
                  enum:
                    - NONE
                    - PROVISIONING
                    - RUNNING
                    - DEGRADED
                    - FAILED
                    - PAUSED
                    - DELETED
                worker_id:
                  type: string
                  description: The worker ID of the connector.
                trace:
                  type: string
                  description: Exception message in case of an error.
            tasks:
              type: array
              description: A map containing the task status.
              items:
                type: object
                properties:
                  id:
                    type: integer
                    description: The ID of task.
                  state:
                    type: string
                    description: The state of the task.
                  worker_id:
                    type: string
                    description: The worker ID of the task.
                  msg:
                    type: string
                required:
                  - id
                  - state
                  - worker_id
          required:
            - name
            - type
            - connector
    connect.v1.Connector:
      type: object
      properties:
        name:
          type: string
          description: Name of the connector
        config:
          type: object
          description: |-
            Configuration parameters for the connector. These configurations
            are the minimum set of key-value pairs (KVP) which can be used to
            define how the connector connects Kafka to the external system.
            Some of these KVPs are common to all the connectors, such as
            connection parameters to Kafka, connector metadata, etc. The list
            of common connector configurations is as follows

            - cloud.environment
            - cloud.provider
            - connector.class
            - kafka.api.key
            - kafka.api.secret
            - kafka.endpoint
            - kafka.region
            - name

            A specific connector such as `GcsSink` would have additional
            parameters such as `gcs.bucket.name`, `flush.size`, etc.
          required:
            - cloud.environment
            - cloud.provider
            - connector.class
            - name
            - kafka.endpoint
            - kafka.region
            - kafka.api.key
            - kafka.api.secret
          properties:
            cloud.environment:
              type: string
              description: The cloud environment type.
            cloud.provider:
              type: string
              description: 'The cloud service provider, e.g. aws, azure, etc.'
              x-extensible-enum:
                - aws
                - azure
                - gcp
            connector.class:
              type: string
              description: 'The connector class name. E.g. BigQuerySink, GcsSink, etc.'
            name:
              type: string
              description: Name or alias of the class (plugin) for this connector.
            kafka.endpoint:
              type: string
              description: The kafka cluster endpoint.
            kafka.region:
              type: string
              description: The kafka cluster region.
            kafka.api.key:
              type: string
              description: The kafka cluster api key.
            kafka.api.secret:
              type: string
              description: The kafka cluster api secret key.
              x-redact: true
          additionalProperties:
            type: string
        tasks:
          type: array
          description: List of active tasks generated by the connector
          items:
            type: object
            properties:
              connector:
                type: string
                description: The name of the connector the task belongs to
              task:
                type: integer
                description: Task ID within the connector
            required:
              - connector
              - task
        type:
          type: string
          description: 'Type of connector, sink or source'
          enum:
            - sink
            - source
      required:
        - name
        - config
    connect.v1.Connectors:
      type: array
      description: List of active task configs that have been created by the connector
      items:
        type: object
        properties:
          id:
            type: object
            description: The ID of task.
            properties:
              connector:
                type: string
                description: The name of the connector the task belongs to.
              task:
                type: integer
                description: Task ID within the connector.
          config:
            type: object
            description: |-
              Configuration parameters for the connector. These configurations
              are the minimum set of key-value pairs (KVP) which can be used to
              define how the connector connects Kafka to the external system.
              Some of these KVPs are common to all the connectors, such as
              connection parameters to Kafka, connector metadata, etc. The list
              of common connector configurations is as follows

                - cloud.environment
                - cloud.provider
                - connector.class
                - kafka.api.key
                - kafka.api.secret
                - kafka.endpoint
                - kafka.region
                - name

              A specific connector such as `GcsSink` would have additional
              parameters such as `gcs.bucket.name`, `flush.size`, etc.
            required:
              - cloud.environment
              - cloud.provider
              - connector.class
              - name
              - kafka.endpoint
              - kafka.region
              - kafka.api.key
              - kafka.api.secret
            properties:
              cloud.environment:
                type: string
                description: The cloud environment type.
              cloud.provider:
                type: string
                description: 'The cloud service provider, e.g. aws, azure, etc.'
                x-extensible-enum:
                  - aws
                  - azure
                  - gcp
              connector.class:
                type: string
                description: 'The connector class name. E.g. BigQuerySink, GcsSink, etc.'
              name:
                type: string
                description: Name or alias of the class (plugin) for this connector.
              kafka.endpoint:
                type: string
                description: The kafka cluster endpoint.
              kafka.region:
                type: string
                description: The kafka cluster region.
              kafka.api.key:
                type: string
                description: The kafka cluster api key.
              kafka.api.secret:
                type: string
                description: The kafka cluster api secret key.
                x-redact: true
            additionalProperties:
              type: string
    connect.v1.ConnectorOffsets:
      type: object
      description: Offsets for a connector
      properties:
        name:
          type: string
          description: The name of the connector.
        id:
          type: string
          description: The ID of the connector.
        offsets:
          $ref: '#/components/schemas/connect.v1.Offsets'
        metadata:
          type: object
          description: Metadata of the connector offset.
          properties:
            observed_at:
              type: string
              format: date-time
              example: '2024-02-20T15:14:19Z'
              readOnly: true
              description: 'The time at which the offsets were observed. The time is in UTC, ISO 8601 format.'
    connect.v1.AlterOffsetRequestInfo:
      type: object
      description: The request made to alter offsets.
      properties:
        id:
          type: string
          description: The ID of the connector.
        name:
          type: string
          description: The name of the connector.
        offsets:
          $ref: '#/components/schemas/connect.v1.Offsets'
        requested_at:
          type: string
          format: date-time
          readOnly: true
          example: '2024-02-20T15:14:19Z'
          description: 'The time at which the request was made. The time is in UTC, ISO 8601 format.'
        type:
          $ref: '#/components/schemas/connect.v1.AlterOffsetRequestType'
      required:
        - id
        - name
        - type
        - requested_at
    connect.v1.AlterOffsetRequest:
      type: object
      description: Request to alter the offset of a connector. The offsets parameter is options for DELETE type.
      properties:
        type:
          $ref: '#/components/schemas/connect.v1.AlterOffsetRequestType'
        offsets:
          $ref: '#/components/schemas/connect.v1.Offsets'
      required:
        - type
    connect.v1.AlterOffsetRequestType:
      type: string
      enum:
        - PATCH
        - DELETE
      description: |-
        The type of alter operation. PATCH will update the offset to the provided values.
        The update will only happen for the partitions provided in the request. 
        DELETE will delete the offset for the provided partitions and reset them back to the
        base state. It is as if, a fresh new connector was created.

        For sink connectors PATCH/DELETE will move the offsets to the provided point in the 
        topic partition. If the offset provided is not present in the topic partition it will
        by default reset to the earliest offset in the topic partition.

        For source connectors, post PATCH/DELETE the connector will attempt to read from the 
        position defined in the altered offsets.
    connect.v1.AlterOffsetStatus:
      type: object
      description: |-
        Status of the alter offset operation. The previous offsets in the response 
        is the offsets that the connector last processed, before the offsets were altered,
        via a patch or delete operation.
      properties:
        request:
          $ref: '#/components/schemas/connect.v1.AlterOffsetRequestInfo'
        status:
          type: object
          description: The response of the alter offsets operation.
          properties:
            phase:
              type: string
              x-extensible-enum:
                - PENDING
                - PENDING_VALIDATION
                - APPLIED
                - FAILED
              description: |-
                The phase of the alter offset operation. 

                PENDING: The offset alter operation is in progress.

                APPLIED: The offset alter operation has been applied to the connector.

                FAILED:  The offset alter operation has failed to be applied to the connector.
            message:
              type: string
              description: An info message from the alter offset operation.
          required:
            - phase
        previous_offsets:
          $ref: '#/components/schemas/connect.v1.Offsets'
        applied_at:
          type: string
          nullable: true
          format: date-time
          example: '2024-02-20T15:14:19Z'
          readOnly: true
          description: 'The time at which the offsets were applied. The time is in UTC, ISO 8601 format.'
      required:
        - request
        - status
    SearchFilter:
      description: Filter a collection by a string search
      type: string
    connect.v1.CustomConnectorPluginList:
      type: object
      description: |-
        CustomConnectorPlugins objects represent Custom Connector Plugins on Confluent Cloud.
        The API allows you to list, create, read, update, and delete your Custom Connector Plugins.
        Related guide:
        [Custom Connector Plugin API](https://docs.confluent.io/cloud/current/connectors/connect-api-section.html).


        ## The Custom Connector Plugins Model
        <SchemaDefinition schemaRef="#/components/schemas/connect.v1.CustomConnectorPlugin" />
      required:
        - api_version
        - kind
        - metadata
        - data
      properties:
        api_version:
          type: string
          enum:
            - connect/v1
          description: APIVersion defines the schema version of this representation of a resource.
          readOnly: true
        kind:
          type: string
          description: Kind defines the object this REST resource represents.
          readOnly: true
          enum:
            - CustomConnectorPluginList
        metadata:
          allOf:
            - $ref: '#/components/schemas/ListMeta'
            - properties:
                first:
                  example: 'https://api.confluent.cloud/connect/v1/custom-connector-plugins'
                last:
                  example: 'https://api.confluent.cloud/connect/v1/custom-connector-plugins?page_token=bcAOehAY8F16YD84Z1wT'
                prev:
                  example: 'https://api.confluent.cloud/connect/v1/custom-connector-plugins?page_token=YIXRY97wWYmwzrax4dld'
                next:
                  example: 'https://api.confluent.cloud/connect/v1/custom-connector-plugins?page_token=UvmDWOB1iwfAIBPj6EYb'
        data:
          type: array
          description: A data property that contains an array of resource items. Each entry in the array is a separate resource.
          items:
            allOf:
              - $ref: '#/components/schemas/connect.v1.CustomConnectorPlugin'
              - type: object
                required:
                  - id
                  - metadata
                  - display_name
                  - connector_class
                  - connector_type
                  - upload_source
          uniqueItems: true
    ListMeta:
      type: object
      description: ListMeta describes metadata that resource collections may have
      properties:
        first:
          description: 'A link to the first page of results. If a response does not contain a first link, then direct navigation to the first page is not supported.'
          type: string
          format: uri
          nullable: true
          example: 'https://api.confluent.cloud/v2/resourcekinds'
        last:
          description: 'A link to the last page of results. If a response does not contain a last link, then direct navigation to the last page is not supported.'
          type: string
          format: uri
          nullable: true
          example: 'https://api.confluent.cloud/v2/resourcekinds?page_token=bcAOehAY8F16YD84Z1wT'
        prev:
          description: 'A link to the previous page of results. If a response does not contain a prev link, then either there is no previous data or backwards traversal through the result set is not supported.'
          type: string
          format: uri
          nullable: true
          example: 'https://api.confluent.cloud/v2/resourcekinds?page_token=YIXRY97wWYmwzrax4dld'
        next:
          description: 'A link to the next page of results. If a response does not contain a next link, then there is no more data available.'
          type: string
          format: uri
          nullable: true
          example: 'https://api.confluent.cloud/v2/resourcekinds?page_token=UvmDWOB1iwfAIBPj6EYb'
        total_size:
          description: Number of records in the full result set. This response may be paginated and have a smaller number of records.
          type: integer
          format: int32
          minimum: 0
          example: 123
    connect.v1.CustomConnectorPlugin:
      type: object
      description: |-
        CustomConnectorPlugins objects represent Custom Connector Plugins on Confluent Cloud.
        The API allows you to list, create, read, update, and delete your Custom Connector Plugins.
        Related guide:
        [Custom Connector Plugin API](https://docs.confluent.io/cloud/current/connectors/connect-api-section.html).


        ## The Custom Connector Plugins Model
        <SchemaDefinition schemaRef="#/components/schemas/connect.v1.CustomConnectorPlugin" />
      properties:
        api_version:
          type: string
          enum:
            - connect/v1
          description: APIVersion defines the schema version of this representation of a resource.
          readOnly: true
        kind:
          type: string
          description: Kind defines the object this REST resource represents.
          readOnly: true
          enum:
            - CustomConnectorPlugin
        id:
          description: 'ID is the "natural identifier" for an object within its scope/namespace; it is normally unique across time but not space. That is, you can assume that the ID will not be reclaimed and reused after an object is deleted ("time"); however, it may collide with IDs for other object `kinds` or objects of the same `kind` within a different scope/namespace ("space").'
          type: string
          maxLength: 255
          readOnly: true
          example: dlz-f3a90de
        metadata:
          allOf:
            - $ref: '#/components/schemas/ObjectMeta'
            - properties:
                self:
                  example: 'https://api.confluent.cloud/connect/v1/custom-connector-plugins/ccp-12345'
                resource_name:
                  example: 'crn://confluent.cloud/organization=9bb441c4-edef-46ac-8a41-c49e44a3fd9a/custom-connector-plugin=ccp-12345'
        display_name:
          type: string
          description: Display name of Custom Connector Plugin.
          maxLength: 60
        content_format:
          type: string
          example: ZIP
          description: Archive format of Custom Connector Plugin.
          x-extensible-enum:
            - ZIP
            - JAR
          readOnly: true
        description:
          type: string
          description: Description of Custom Connector Plugin.
          maxLength: 256
        documentation_link:
          maxLength: 512
          type: string
          pattern: '^$|^(http://|https://).+'
          example: 'https://github.com/confluentinc/kafka-connect-datagen'
          description: Document link of Custom Connector Plugin.
        connector_class:
          type: string
          maxLength: 150
          pattern: '^(([a-zA-Z][a-zA-Z_$0-9]*(\.[a-zA-Z][a-zA-Z_$0-9]*)*)\.)?([a-zA-Z][a-zA-Z_$0-9]*)$'
          description: Java class or alias for connector. You can get connector class from connector documentation provided by developer.
          example: io.confluent.kafka.connect.datagen.DatagenConnector
          x-immutable: true
        connector_type:
          type: string
          description: |
            Custom Connector type.
          example: SOURCE
          x-extensible-enum:
            - SOURCE
            - SINK
          x-immutable: true
        cloud:
          type: string
          description: Cloud provider where the Custom Connector Plugin archive is uploaded.
          example: AWS
          default: AWS
          x-extensible-enum:
            - AWS
            - GCP
            - AZURE
          x-immutable: true
        sensitive_config_properties:
          type: array
          description: A sensitive property is a connector configuration property that must be hidden after a user enters property value when setting up connector.
          items:
            type: string
            pattern: '^[\w\+\.-]+$'
            maxLength: 150
          example:
            - passwords
            - keys
            - tokens
        upload_source:
          type: object
          oneOf:
            - $ref: '#/components/schemas/connect.v1.UploadSource.PresignedUrl'
          description: '[immutable] Upload source of Custom Connector Plugin. Only required in `create` request, will be ignored in `read`, `update` or `list`.'
          discriminator:
            propertyName: location
            mapping:
              PRESIGNED_URL_LOCATION: '#/components/schemas/connect.v1.UploadSource.PresignedUrl'
    Failure:
      type: object
      description: Provides information about problems encountered while performing an operation.
      required:
        - errors
      properties:
        errors:
          description: List of errors which caused this operation to fail
          type: array
          items:
            $ref: '#/components/schemas/Error'
          uniqueItems: true
    ObjectMeta:
      description: 'ObjectMeta is metadata that all persisted resources must have, which includes all objects users must create.'
      required:
        - self
      properties:
        self:
          description: 'Self is a Uniform Resource Locator (URL) at which an object can be addressed. This URL encodes the service location, API version, and other particulars necessary to locate the resource at a point in time'
          type: string
          format: uri
          readOnly: true
          example: 'https://api.confluent.cloud/v2/kafka-clusters/lkc-f3a90de'
        resource_name:
          description: Resource Name is a Uniform Resource Identifier (URI) that is globally unique across space and time. It is represented as a Confluent Resource Name
          type: string
          format: uri
          readOnly: true
          example: 'crn://confluent.cloud/kafka=lkc-f3a90de'
        created_at:
          type: string
          format: date-time
          example: '2006-01-02T15:04:05-07:00'
          readOnly: true
          description: The date and time at which this object was created. It is represented in RFC3339 format and is in UTC.
        updated_at:
          type: string
          format: date-time
          example: '2006-01-02T15:04:05-07:00'
          readOnly: true
          description: The date and time at which this object was last updated. It is represented in RFC3339 format and is in UTC.
        deleted_at:
          type: string
          format: date-time
          example: '2006-01-02T15:04:05-07:00'
          readOnly: true
          description: The date and time at which this object was (or will be) deleted. It is represented in RFC3339 format and is in UTC.
      readOnly: true
    connect.v1.UploadSource.PresignedUrl:
      type: object
      description: Presigned URL of the uploaded Custom Connector Plugin archive.
      properties:
        location:
          type: string
          description: |
            Location of the Custom Connector Plugin source.
          x-extensible-enum:
            - PRESIGNED_URL_LOCATION
          example: PRESIGNED_URL_LOCATION
        upload_id:
          type: string
          example: e53bb2e8-8de3-49fa-9fb1-4e3fd9a16b66
          description: Upload ID returned by the `/presigned-upload-url` API. This field returns an empty string in all responses.
      required:
        - location
        - upload_id
    Error:
      type: object
      description: Describes a particular error encountered while performing an operation.
      properties:
        id:
          description: A unique identifier for this particular occurrence of the problem.
          type: string
          maxLength: 255
        status:
          description: 'The HTTP status code applicable to this problem, expressed as a string value.'
          type: string
        code:
          description: 'An application-specific error code, expressed as a string value.'
          type: string
        title:
          description: 'A short, human-readable summary of the problem. It **SHOULD NOT** change from occurrence to occurrence of the problem, except for purposes of localization.'
          type: string
        detail:
          description: A human-readable explanation specific to this occurrence of the problem.
          type: string
        source:
          type: object
          description: 'If this error was caused by a particular part of the API request, the source will point to the query string parameter or request body property that caused it.'
          properties:
            pointer:
              description: 'A JSON Pointer [RFC6901] to the associated entity in the request document [e.g. "/spec" for a spec object, or "/spec/title" for a specific field].'
              type: string
            parameter:
              description: A string indicating which query parameter caused the error.
              type: string
        error_code:
          type: integer
          format: int32
        message:
          type: string
          nullable: true
      additionalProperties: false
    connect.v1.CustomConnectorPluginUpdate:
      type: object
      description: |-
        CustomConnectorPlugins objects represent Custom Connector Plugins on Confluent Cloud.
        The API allows you to list, create, read, update, and delete your Custom Connector Plugins.
        Related guide:
        [Custom Connector Plugin API](https://docs.confluent.io/cloud/current/connectors/connect-api-section.html).


        ## The Custom Connector Plugins Model
        <SchemaDefinition schemaRef="#/components/schemas/connect.v1.CustomConnectorPlugin" />
      properties:
        api_version:
          type: string
          enum:
            - connect/v1
          description: APIVersion defines the schema version of this representation of a resource.
          readOnly: true
        kind:
          type: string
          description: Kind defines the object this REST resource represents.
          readOnly: true
          enum:
            - CustomConnectorPlugin
        id:
          description: 'ID is the "natural identifier" for an object within its scope/namespace; it is normally unique across time but not space. That is, you can assume that the ID will not be reclaimed and reused after an object is deleted ("time"); however, it may collide with IDs for other object `kinds` or objects of the same `kind` within a different scope/namespace ("space").'
          type: string
          maxLength: 255
          readOnly: true
          example: dlz-f3a90de
        metadata:
          allOf:
            - $ref: '#/components/schemas/ObjectMeta'
            - properties:
                self:
                  example: 'https://api.confluent.cloud/connect/v1/custom-connector-plugins/ccp-12345'
                resource_name:
                  example: 'crn://confluent.cloud/organization=9bb441c4-edef-46ac-8a41-c49e44a3fd9a/custom-connector-plugin=ccp-12345'
        display_name:
          type: string
          description: Display name of Custom Connector Plugin.
          maxLength: 60
        content_format:
          type: string
          example: ZIP
          description: Archive format of Custom Connector Plugin.
          x-extensible-enum:
            - ZIP
            - JAR
          readOnly: true
        description:
          type: string
          description: Description of Custom Connector Plugin.
          maxLength: 256
        documentation_link:
          maxLength: 512
          type: string
          pattern: '^$|^(http://|https://).+'
          example: 'https://github.com/confluentinc/kafka-connect-datagen'
          description: Document link of Custom Connector Plugin.
        sensitive_config_properties:
          type: array
          description: A sensitive property is a connector configuration property that must be hidden after a user enters property value when setting up connector.
          items:
            type: string
            pattern: '^[\w\+\.-]+$'
            maxLength: 150
          example:
            - passwords
            - keys
            - tokens
        upload_source:
          type: object
          oneOf:
            - $ref: '#/components/schemas/connect.v1.UploadSource.PresignedUrl'
          description: '[immutable] Upload source of Custom Connector Plugin. Only required in `create` request, will be ignored in `read`, `update` or `list`.'
          discriminator:
            propertyName: location
            mapping:
              PRESIGNED_URL_LOCATION: '#/components/schemas/connect.v1.UploadSource.PresignedUrl'
    connect.v1.PresignedUrlRequest:
      type: object
      description: |
        Request schema of the presigned upload URL.
      properties:
        api_version:
          type: string
          enum:
            - connect/v1
          description: APIVersion defines the schema version of this representation of a resource.
          readOnly: true
        kind:
          type: string
          description: Kind defines the object this REST resource represents.
          readOnly: true
          enum:
            - PresignedUrlRequest
        id:
          description: 'ID is the "natural identifier" for an object within its scope/namespace; it is normally unique across time but not space. That is, you can assume that the ID will not be reclaimed and reused after an object is deleted ("time"); however, it may collide with IDs for other object `kinds` or objects of the same `kind` within a different scope/namespace ("space").'
          type: string
          maxLength: 255
          readOnly: true
          example: dlz-f3a90de
        metadata:
          allOf:
            - $ref: '#/components/schemas/ObjectMeta'
            - properties:
                self:
                  example: 'https://api.confluent.cloud/connect/v1/presigned-url-requests/pur-12345'
                resource_name:
                  example: 'crn://confluent.cloud/organization=9bb441c4-edef-46ac-8a41-c49e44a3fd9a/presigned-url-request=pur-12345'
        content_format:
          type: string
          example: ZIP
          description: Archive format of the Custom Connector Plugin.
          x-extensible-enum:
            - JAR
            - ZIP
        cloud:
          type: string
          example: AWS
          default: AWS
          description: Cloud provider where the Custom Connector Plugin archive is uploaded.
          x-extensible-enum:
            - AWS
            - GCP
            - AZURE
    connect.v1.PresignedUrl:
      type: object
      description: |-
        Request a presigned upload URL for new Custom Connector Plugin. Note that
        the URL policy expires in one hour. If the policy expires, you can request
        a new presigned upload URL.

        Related guide:
        [Custom Connector Plugin API](https://docs.confluent.io/cloud/current/connectors/connect-api-section.html).


        ## The Presigned Urls Model
        <SchemaDefinition schemaRef="#/components/schemas/connect.v1.PresignedUrl" />
      properties:
        api_version:
          type: string
          enum:
            - connect/v1
          description: APIVersion defines the schema version of this representation of a resource.
          readOnly: true
        kind:
          type: string
          description: Kind defines the object this REST resource represents.
          readOnly: true
          enum:
            - PresignedUrl
        content_format:
          type: string
          description: Content format of the Custom Connector Plugin archive.
          example: ZIP
          x-extensible-enum:
            - ZIP
            - JAR
          readOnly: true
        cloud:
          type: string
          description: Cloud provider where the Custom Connector Plugin archive is uploaded.
          example: AWS
          x-extensible-enum:
            - AWS
            - GCP
            - AZURE
          readOnly: true
        upload_id:
          type: string
          description: Unique identifier of this upload.
          example: e53bb2e8-8de3-49fa-9fb1-4e3fd9a16b66
          readOnly: true
        upload_url:
          type: string
          format: uri
          description: Upload URL for the Custom Connector Plugin archive.
          example: 'https://confluent-custom-connectors-stag-us-west-2.s3.dualstack.us-west-2.amazonaws.com/'
          readOnly: true
        upload_form_data:
          type: object
          description: Upload form data of the Custom Connector Plugin. All values should be strings.
          example:
            bucket: confluent-custom-connectors-stag-us-west-2
            key: staging/custom-plugin/2f37f0b6-f8da-4e8b-bc5f-282ebb0511be/connect-e53bb2e8-8de3-49fa-9fb1-4e3fd9a16b66/plugin.zip
            policy: string
            x-amz-algorithm: AWS4-HMAC-SHA256
            x-amz-credential: string
            x-amz-date: 20230725T013857Z
            x-amz-security-token: string
            x-amz-signature: string
          readOnly: true
  parameters:
    AclHost:
      name: host
      description: The ACL host.
      in: query
      required: false
      schema:
        type: string
    AclOperation:
      name: operation
      description: The ACL operation.
      in: query
      required: false
      schema:
        $ref: '#/components/schemas/AclOperation'
    AclOperationRequired:
      name: operation
      description: The ACL operation.
      in: query
      required: true
      schema:
        $ref: '#/components/schemas/AclOperation'
    AclPatternType:
      name: pattern_type
      description: The ACL pattern type.
      in: query
      required: false
      schema:
        $ref: '#/components/schemas/AclPatternType'
    AclPatternTypeRequired:
      name: pattern_type
      description: The ACL pattern type.
      in: query
      required: true
      schema:
        $ref: '#/components/schemas/AclPatternType'
    AclPermission:
      name: permission
      description: The ACL permission.
      in: query
      required: false
      schema:
        $ref: '#/components/schemas/AclPermission'
    AclPermissionRequired:
      name: permission
      description: The ACL permission.
      in: query
      required: true
      schema:
        $ref: '#/components/schemas/AclPermission'
    AclPrincipal:
      name: principal
      description: The ACL principal. This is the Service Account name or user name.
      in: query
      required: false
      schema:
        type: string
    AclResourceName:
      name: resource_name
      description: The ACL resource name.
      in: query
      required: false
      schema:
        type: string
    AclResourceType:
      name: resource_type
      description: The ACL resource type.
      in: query
      required: false
      schema:
        $ref: '#/components/schemas/AclResourceType'
    AclResourceTypeRequired:
      name: resource_type
      description: The ACL resource type.
      in: query
      required: true
      schema:
        $ref: '#/components/schemas/AclResourceType'
    BrokerId:
      name: broker_id
      description: The Kafka broker ID.
      in: path
      required: true
      schema:
        type: integer
      example: 1
    ClusterId:
      name: cluster_id
      description: The Kafka cluster ID.
      in: path
      required: true
      schema:
        type: string
      example: cluster-1
    ConfigName:
      name: name
      description: The configuration parameter name.
      in: path
      required: true
      schema:
        type: string
      example: compression.type
    ConsumerGroupId:
      name: consumer_group_id
      description: The consumer group ID.
      in: path
      required: true
      schema:
        type: string
      example: consumer-group-1
    ConsumerId:
      name: consumer_id
      description: The consumer ID.
      in: path
      required: true
      schema:
        type: string
      example: consumer-1
    IncludeAuthorizedOperations:
      name: include_authorized_operations
      description: Specify if authorized operations should be included in the response.
      in: query
      required: false
      schema:
        type: boolean
    PartitionId:
      name: partition_id
      description: The partition ID.
      in: path
      required: true
      schema:
        type: integer
      example: 0
    TopicName:
      name: topic_name
      description: The topic name.
      in: path
      required: true
      schema:
        type: string
      example: topic-1
    BrokerTaskType:
      name: task_type
      description: The Kafka broker task type.
      in: path
      required: true
      schema:
        $ref: '#/components/schemas/BrokerTaskType'
      example: remove-broker
    ShouldShutdown:
      name: should_shutdown
      description: 'To shutdown the broker or not, Default: true'
      in: query
      required: false
      schema:
        type: boolean
      example: true
    ValidateOnly:
      name: validate_only
      description: 'To validate the action can be performed successfully or not. Default: false'
      in: query
      required: false
      schema:
        type: boolean
      example: false
    ValidateLink:
      name: validate_link
      description: 'To synchronously validate that the source cluster ID is expected and the dest cluster has the permission to read topics in the source cluster. Default: true'
      in: query
      required: false
      schema:
        type: boolean
      example: false
    IncludeTasks:
      name: include_tasks
      description: 'Whether to include cluster linking tasks in the response. Default: false'
      in: query
      required: false
      schema:
        type: boolean
      example: false
    IncludeStateTransitionErrors:
      name: include_state_transition_errors
      description: 'Whether to include mirror state transition errors in the response. Default: false'
      in: query
      required: false
      schema:
        type: boolean
      example: false
    Force:
      name: force
      description: 'Force the action. Default: false'
      in: query
      required: false
      schema:
        type: boolean
      example: false
    IncludePartitionLevelTruncationData:
      name: include_partition_level_truncation_data
      description: 'Whether to include partition level truncation information when truncating and restoring a topic in the response. Default: false'
      in: query
      required: false
      schema:
        type: boolean
      example: false
    LinkName:
      name: link_name
      description: The link name
      in: path
      required: true
      schema:
        type: string
      example: link-sb1
    LinkConfigName:
      name: config_name
      description: The link config name
      in: path
      required: true
      schema:
        type: string
      example: consumer.offset.sync.enable
    MirrorTopicStatus:
      name: mirror_status
      description: 'The status of the mirror topic. If not specified, all mirror topics will be returned.'
      in: query
      required: false
      schema:
        $ref: '#/components/schemas/MirrorTopicStatus'
      example: ACTIVE
    MirrorTopicName:
      name: mirror_topic_name
      description: Cluster Linking mirror topic name
      in: path
      required: true
      schema:
        type: string
      example: topic-1
    QueryParamLinkName:
      name: link_name
      description: The link name
      in: query
      required: true
      schema:
        type: string
      example: link-sb1
  responses:
    connect.v1.UnauthenticatedError:
      description: Unauthorized
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/connect.v1.ConnectorError'
          example:
            error:
              code: 401
              message: Unauthorized
    connect.v1.AccountNotFoundError:
      description: Not Found
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/connect.v1.ConnectorError'
          example:
            error:
              code: 404
              message: account not found
    RateLimitError:
      description: Rate Limit Exceeded
      headers:
        X-Request-Id:
          schema:
            type: string
          description: The unique identifier for the API request.
        X-RateLimit-Limit:
          schema:
            type: integer
          description: The maximum number of requests you're permitted to make per time period.
        X-RateLimit-Remaining:
          schema:
            type: integer
          description: The number of requests remaining in the current rate limit window.
        X-RateLimit-Reset:
          schema:
            type: integer
          description: |-
            The relative time in seconds until the current rate-limit window resets.  
              
            **Important:** This differs from Github and Twitter's same-named header which uses UTC epoch seconds. We use relative time to avoid client/server time synchronization issues.
        Retry-After:
          schema:
            type: integer
          description: The number of seconds to wait until the rate limit window resets. Only sent when the rate limit is reached.
    connect.v1.DefaultSystemError:
      description: Internal Server Error
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/connect.v1.ConnectorError'
          example:
            error:
              code: 500
              message: 'Oops, something went wrong'
    connect.v1.BadRequestError:
      description: Bad Request
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/connect.v1.ConnectorError'
          example:
            error:
              code: 400
              message: Bad Request
    connect.v1.OK:
      description: OK
      content:
        application/json:
          schema:
            type: object
            properties:
              error:
                type: object
                nullable: true
          example:
            error: null
    connect.v1.ResourceNotFoundError:
      description: Not Found
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/connect.v1.ConnectorError'
          example:
            error:
              code: 404
              message: resource not found
    connect.v1.ForbiddenError:
      description: Forbidden
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/connect.v1.ConnectorError'
          example:
            error:
              code: 403
              message: Forbidden
    BadRequestError:
      description: Bad Request
      headers:
        X-Request-Id:
          schema:
            type: string
          description: The unique identifier for the API request.
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Failure'
          example:
            errors:
              - id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                status: '400'
                code: invalid_filter
                title: Invalid Filter
                detail: The 'delorean' resource can't be filtered by 'num_doors'
                source:
                  parameter: num_doors
    UnauthenticatedError:
      x-summary: Unauthorized
      description: The request lacks valid authentication credentials for this resource.
      headers:
        X-Request-Id:
          schema:
            type: string
          description: The unique identifier for the API request.
        WWW-Authenticate:
          schema:
            type: string
          description: The unique identifier for the API request.
          example: 'Basic error="invalid_key", error_description="The API Key is invalid"'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Failure'
          example:
            errors:
              - id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                status: '401'
                code: user_unauthenticated
                title: Authentication Required
                detail: Valid authentication credentials must be provided
    UnauthorizedError:
      x-summary: Forbidden
      description: The access credentials were considered insufficient to grant access
      headers:
        X-Request-Id:
          schema:
            type: string
          description: The unique identifier for the API request.
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Failure'
          example:
            errors:
              - id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                status: '403'
                code: user_unauthorized
                title: User Access Unauthorized
                detail: The user 'mcfly' is not allowed to access the 'delorean' resource without the 'plutonium' role.
    DefaultSystemError:
      description: 'Oops, something went wrong!'
      headers:
        X-Request-Id:
          schema:
            type: string
          description: The unique identifier for the API request.
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Failure'
          example:
            errors:
              - id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                status: '500'
                code: out_of_gas
                title: DeLorean Out Of Gas
                detail: 'The DeLorean has run out of gas, but Doc Brown will fill ''er up for you asap'
    ConflictError:
      x-summary: Conflict
      description: The request is in conflict with the current server state
      headers:
        X-Request-Id:
          schema:
            type: string
          description: The unique identifier for the API request.
        Location:
          schema:
            type: string
            format: uri
            example: 'https://api.confluent.cloud/{object}/{id}'
          description: Resource URI of conflicting resource
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Failure'
          example:
            errors:
              - id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                status: '409'
                code: resource_already_exists
                title: Resource Already exists
                detail: The entitlement '91e3e86f-fca6-4f14-98f5-a48e64113ce2' already exists.
    ValidationError:
      description: Validation Failed
      headers:
        X-Request-Id:
          schema:
            type: string
          description: The unique identifier for the API request.
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Failure'
          example:
            errors:
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
              - status: '422'
                code: invalid_configuration
                id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                title: Validation Failed
                detail: 'The property ''/cluster/storage_size'' of type string did not match the following type: integer'
                source:
                  pointer: /cluster/storage_size
    NotFoundError:
      description: Not Found
      headers:
        X-Request-Id:
          schema:
            type: string
          description: The unique identifier for the API request.
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Failure'
          example:
            errors:
              - id: ed42afdc-f0d5-4c0d-b428-9fc6ed6e279d
                status: '404'
                title: Not Found
  securitySchemes:
    cloud-api-key:
      type: http
      scheme: basic
      description: Authenticate with Cloud API Keys using HTTP Basic Auth. Treat the Cloud API Key ID as the username and Cloud API Key Secret as the password.
    confluent-sts-access-token:
      type: oauth2
      description: Authenticate with Confluent API using this credentials (JSON Web Tokens) following OAuth 2.0.
      flows:
        clientCredentials:
          tokenUrl: 'https://api.confluent.cloud/sts/v1/oauth2/token'
          scopes: {}
    api-key:
      type: http
      scheme: basic
      description: Authenticate with API Keys using HTTP Basic Auth. Treat the API Key ID as the username and API Key Secret as the password.
    resource-api-key:
      type: http
      scheme: basic
      description: |
        Authenticate with resource-specific API Keys using HTTP Basic Auth. Treat the resource-specific API Key ID 
        as the username and resource-specific API Key Secret as the password.
    external-access-token:
      type: oauth2
      description: Authenticate with OAuth 2.0.
      flows:
        clientCredentials:
          tokenUrl: 'https://<oauth-identity-provider>/token'
          scopes: {}
    oauth:
      type: oauth2
      description: Authenticate with OAuth 2.0. Currently this is only supported for partner APIs.
      flows:
        clientCredentials:
          tokenUrl: /oauth2/token
          scopes:
            'partner:alter': enables partners to alter entitlements
            'partner:create': enables partners to create entitlements and signup on behalf of customers
            'partner:delete': enables partners to delete entitlements and organizations
            'partner:describe': enables partners to read and list entitlements and organizations
  requestBodies:
    AlterBrokerConfigBatchRequest:
      description: The alter broker configuration parameter batch request.
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/AlterConfigBatchRequestData'
          example:
            data:
              - name: max.connections
                operation: DELETE
              - name: compression.type
                value: gzip
    AlterClusterConfigBatchRequest:
      description: The alter cluster configuration parameter batch request.
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/AlterConfigBatchRequestData'
          example:
            data:
              - name: max.connections
                operation: DELETE
              - name: compression.type
                value: gzip
    AlterTopicConfigBatchRequest:
      description: The alter topic configuration parameter batch request.
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/AlterConfigBatchRequestData'
          examples:
            batch_alter_topic_configs:
              value:
                data:
                  - name: cleanup.policy
                    operation: DELETE
                  - name: compression.type
                    value: gzip
            validate_only_batch_alter_topic_configs:
              value:
                data:
                  - name: cleanup.policy
                    operation: DELETE
                  - name: compression.type
                    value: gzip
                validate_only: true
    CreateAclRequest:
      description: The ACL creation request.
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/CreateAclRequestData'
          example:
            resource_type: CLUSTER
            resource_name: kafka-cluster
            pattern_type: LITERAL
            principal: 'principalType:principalName'
            host: '*'
            operation: DESCRIBE
            permission: DENY
    BatchCreateAclRequest:
      description: The batch ACL creation request.
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/CreateAclRequestDataList'
          example:
            data:
              - resource_type: CLUSTER
                resource_name: kafka-cluster
                pattern_type: LITERAL
                principal: 'principalType:principalName'
                host: '*'
                operation: DESCRIBE
                permission: DENY
              - resource_type: TOPIC
                resource_name: kafka-cluster
                pattern_type: LITERAL
                principal: 'principalType:principalName'
                host: '*'
                operation: READ
                permission: ALLOW
    CreateTopicRequest:
      description: 'The topic creation request. Note that Confluent Cloud allows only specific replication factor values. Because of that the replication factor field should either be omitted or it should use one of the allowed values (see https://docs.confluent.io/cloud/current/client-apps/optimizing/durability.html).'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/CreateTopicRequestData'
          examples:
            uniform_replication:
              value:
                topic_name: topic-X
                partitions_count: 64
                replication_factor: 3
                configs:
                  - name: cleanup.policy
                    value: compact
                  - name: compression.type
                    value: gzip
            dry_run_create_topic:
              value:
                topic_name: topic-X
                partitions_count: 64
                replication_factor: 3
                validate_only: true
    ProduceRequest:
      description: 'A single record to be produced to Kafka. To produce multiple records in the same request, simply concatenate the records. The delivery reports are concatenated in the same order as the records are sent.'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/ProduceRequest'
          examples:
            binary_and_json:
              description: 'If using type, one of "BINARY", "JSON" or "STRING" is required.'
              value:
                partition_id: 1
                headers:
                  - name: Header-1
                    value: SGVhZGVyLTE=
                  - name: Header-2
                    value: SGVhZGVyLTI=
                key:
                  type: BINARY
                  data: Zm9vYmFy
                value:
                  type: JSON
                  data:
                    foo: bar
                timestamp: '2021-02-05T19:14:42Z'
            string:
              description: 'If using type, one of "BINARY", "JSON" or "STRING" is required.'
              value:
                value:
                  type: STRING
                  data: My message
            empty_value:
              description: key or value can be omitted entirely.
              value:
                key:
                  data: 1000
    UpdateBrokerConfigRequest:
      description: The broker configuration parameter update request.
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/UpdateConfigRequestData'
          example:
            value: gzip
    UpdateClusterConfigRequest:
      description: The cluster configuration parameter update request.
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/UpdateConfigRequestData'
          example:
            value: gzip
    UpdateTopicConfigRequest:
      description: The topic configuration parameter update request.
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/UpdateConfigRequestData'
          example:
            value: gzip
    CreateLinkRequest:
      description: Create a cluster link
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/CreateLinkRequestData'
          examples:
            destination_initiated_link:
              description: Create a destination initiated cluster link
              value:
                source_cluster_id: cluster-1
                configs:
                  - name: bootstrap.servers
                    value: cluster-1-bootstrap-server
                  - name: acl.sync.enable
                    value: 'false'
                  - name: consumer.offset.sync.ms
                    value: '30000'
                  - name: sasl.mechanism
                    value: PLAIN
                  - name: sasl.protocol
                    value: SASL_SSL
                  - name: sasl.jaas.config
                    value: sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='<Kafka API Key>' password='<Kafka API Secret>';
            source_initiated_link_at_source_cluster:
              description: Create a source initiated cluster link at source cluster
              value:
                destination_cluster_id: cluster-2
                configs:
                  - name: bootstrap.servers
                    value: cluster-2-bootstrap-server
                  - name: link.mode
                    value: SOURCE
                  - name: sasl.mechanism
                    value: PLAIN
                  - name: sasl.protocol
                    value: SASL_SSL
                  - name: sasl.jaas.config
                    value: sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='<Kafka API Key>' password='<Kafka API Secret>';
            source_initiated_link_at_destination_cluster:
              description: Create a source initiated cluster link at destination cluster
              value:
                destination_cluster_id: cluster-1
                configs:
                  - name: bootstrap.servers
                    value: cluster-1-bootstrap-server
                  - name: link.mode
                    value: DESTINATION
                  - name: connection.mode
                    value: INBOUND
                  - name: acl.sync.enable
                    value: 'false'
                  - name: sasl.mechanism
                    value: PLAIN
                  - name: sasl.protocol
                    value: SASL_SSL
                  - name: sasl.jaas.config
                    value: sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='<Kafka API Key>' password='<Kafka API Secret>';
            bidirectional_link_east:
              description: Create a bidirectional cluster link in east
              value:
                remote_cluster_id: cluster-west
                configs:
                  - name: bootstrap.servers
                    value: cluster-west-bootstrap-server
                  - name: link.mode
                    value: BIDIRECTIONAL
                  - name: cluster.link.prefix
                    value: west.
                  - name: sasl.mechanism
                    value: PLAIN
                  - name: sasl.protocol
                    value: SASL_SSL
                  - name: sasl.jaas.config
                    value: sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='<Kafka API Key>' password='<Kafka API Secret>';
            bidirectional_link_west:
              description: Create a bidirectional cluster link in west
              value:
                remote_cluster_id: cluster-east
                cluster_link_id: eEBkTffYSESld6EO898x3w
                configs:
                  - name: bootstrap.servers
                    value: cluster-east-bootstrap-server
                  - name: link.mode
                    value: BIDIRECTIONAL
                  - name: cluster.link.prefix
                    value: east.
                  - name: sasl.mechanism
                    value: PLAIN
                  - name: sasl.protocol
                    value: SASL_SSL
                  - name: sasl.jaas.config
                    value: sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='<Kafka API Key>' password='<Kafka API Secret>';
    UpdateLinkConfigRequest:
      content:
        application/json:
          example:
            value: '300000'
          schema:
            $ref: '#/components/schemas/UpdateLinkConfigRequestData'
      description: Link config value to update
    AlterLinkConfigBatchRequest:
      content:
        application/json:
          example:
            data:
              - name: cleanup.policy
                operation: DELETE
              - name: compression.type
                value: gzip
          schema:
            $ref: '#/components/schemas/AlterConfigBatchRequestData'
    CreateMirrorTopicRequest:
      description: 'Name and configs of the topics mirroring from and mirroring to. Note that Confluent Cloud allows only specific replication factor values. Because of that the replication factor field should either be omitted or it should use one of the allowed values (see https://docs.confluent.io/cloud/current/client-apps/optimizing/durability.html).'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/CreateMirrorTopicRequestData'
          examples:
            generic_example:
              description: Generic example of creating a mirror topic
              value:
                source_topic_name: topic-1
                configs:
                  - name: unclean.leader.election.enable
                    value: 'true'
                replication_factor: 1
            example_with_mirror_topic_name:
              description: Example using optional mirror_topic_name flag
              value:
                source_topic_name: topic-1
                mirror_topic_name: link1_topic-1
                configs:
                  - name: unclean.leader.election.enable
                    value: 'true'
                replication_factor: 3
    AlterMirrorsRequest:
      description: Mirror topics to be altered.
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/AlterMirrorsRequestData'
          examples:
            mirror_topic_names:
              description: Example using mirror topic names
              value:
                mirror_topic_names:
                  - topic-1
                  - topic-2
            mirror_topic_name_pattern:
              description: Example using mirror topic name pattern
              value:
                mirror_topic_name_pattern: .*
    RemoveBrokersRequest:
      content:
        application/json:
          example:
            broker_ids:
              - 1
              - 2
              - 3
          schema:
            $ref: '#/components/schemas/RemoveBrokersRequestData'
      description: Broker ids to remove
    BrokerReplicaExclusionBatchRequest:
      description: Alter Broker Replica Exclusions.
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/BrokerReplicaExclusionBatchRequestData'
          example:
            data:
              - broker_id: 1
                reason: The broker is to be removed.
              - broker_id: 2
                reason: The broker is to be removed.
  x-stackQL-resources:
    connectors:
      id: confluent.connect.connectors
      name: connectors
      title: Connectors
      methods:
        list_connectv1connectors:
          operation:
            $ref: '#/paths/~1connect~1v1~1environments~1{environment_id}~1clusters~1{kafka_cluster_id}~1connectors/get'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        create_connectv1connector:
          operation:
            $ref: '#/paths/~1connect~1v1~1environments~1{environment_id}~1clusters~1{kafka_cluster_id}~1connectors/post'
          response:
            mediaType: application/json
            openAPIDocKey: '201'
            schemaRef: '#/components/schemas/connect.v1.ConnectorWithOffsets'
        read_connectv1connector:
          operation:
            $ref: '#/paths/~1connect~1v1~1environments~1{environment_id}~1clusters~1{kafka_cluster_id}~1connectors~1{connector_name}/get'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
            schemaRef: '#/components/schemas/connect.v1.Connector'
        delete_connectv1connector:
          operation:
            $ref: '#/paths/~1connect~1v1~1environments~1{environment_id}~1clusters~1{kafka_cluster_id}~1connectors~1{connector_name}/delete'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
            schemaRef: '#/components/responses/connect.v1.OK'
        pause_connectv1connector:
          operation:
            $ref: '#/paths/~1connect~1v1~1environments~1{environment_id}~1clusters~1{kafka_cluster_id}~1connectors~1{connector_name}~1pause/put'
          response:
            mediaType: application/json
            openAPIDocKey: '202'
        resume_connectv1connector:
          operation:
            $ref: '#/paths/~1connect~1v1~1environments~1{environment_id}~1clusters~1{kafka_cluster_id}~1connectors~1{connector_name}~1resume/put'
          response:
            mediaType: application/json
            openAPIDocKey: '202'
      sqlVerbs:
        select:
          - $ref: '#/components/x-stackQL-resources/connectors/methods/read_connectv1connector'
          - $ref: '#/components/x-stackQL-resources/connectors/methods/list_connectv1connectors'
        insert:
          - $ref: '#/components/x-stackQL-resources/connectors/methods/create_connectv1connector'
        update: []
        replace: []
        delete:
          - $ref: '#/components/x-stackQL-resources/connectors/methods/delete_connectv1connector'
    connectors_with_expansions:
      id: confluent.connect.connectors_with_expansions
      name: connectors_with_expansions
      title: Connectors With Expansions
      methods:
        list_connectv1connectors_with_expansions:
          operation:
            $ref: '#/paths/~1connect~1v1~1environments~1{environment_id}~1clusters~1{kafka_cluster_id}~1connectors?expand=info,status,id/get'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
            schemaRef: '#/components/schemas/connect.v1.ConnectorExpansionMap'
      sqlVerbs:
        select:
          - $ref: '#/components/x-stackQL-resources/connectors_with_expansions/methods/list_connectv1connectors_with_expansions'
        insert: []
        update: []
        replace: []
        delete: []
    connector_config:
      id: confluent.connect.connector_config
      name: connector_config
      title: Connector Config
      methods:
        get_connectv1connector_config:
          operation:
            $ref: '#/paths/~1connect~1v1~1environments~1{environment_id}~1clusters~1{kafka_cluster_id}~1connectors~1{connector_name}~1config/get'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        create_or_update_connectv1connector_config:
          operation:
            $ref: '#/paths/~1connect~1v1~1environments~1{environment_id}~1clusters~1{kafka_cluster_id}~1connectors~1{connector_name}~1config/put'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
            schemaRef: '#/components/schemas/connect.v1.Connector'
      sqlVerbs:
        select:
          - $ref: '#/components/x-stackQL-resources/connector_config/methods/get_connectv1connector_config'
        insert:
          - $ref: '#/components/x-stackQL-resources/connector_config/methods/create_or_update_connectv1connector_config'
        update: []
        replace: []
        delete: []
    connector_status:
      id: confluent.connect.connector_status
      name: connector_status
      title: Connector Status
      methods:
        read_connectv1connector_status:
          operation:
            $ref: '#/paths/~1connect~1v1~1environments~1{environment_id}~1clusters~1{kafka_cluster_id}~1connectors~1{connector_name}~1status/get'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
      sqlVerbs:
        select:
          - $ref: '#/components/x-stackQL-resources/connector_status/methods/read_connectv1connector_status'
        insert: []
        update: []
        replace: []
        delete: []
    connector_tasks:
      id: confluent.connect.connector_tasks
      name: connector_tasks
      title: Connector Tasks
      methods:
        list_connectv1connector_tasks:
          operation:
            $ref: '#/paths/~1connect~1v1~1environments~1{environment_id}~1clusters~1{kafka_cluster_id}~1connectors~1{connector_name}~1tasks/get'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
            schemaRef: '#/components/schemas/connect.v1.Connectors'
      sqlVerbs:
        select:
          - $ref: '#/components/x-stackQL-resources/connector_tasks/methods/list_connectv1connector_tasks'
        insert: []
        update: []
        replace: []
        delete: []
    managed_connector_plugins:
      id: confluent.connect.managed_connector_plugins
      name: managed_connector_plugins
      title: Managed Connector Plugins
      methods:
        list_connectv1connector_plugins:
          operation:
            $ref: '#/paths/~1connect~1v1~1environments~1{environment_id}~1clusters~1{kafka_cluster_id}~1connector-plugins/get'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        validate_connectv1connector_plugin:
          operation:
            $ref: '#/paths/~1connect~1v1~1environments~1{environment_id}~1clusters~1{kafka_cluster_id}~1connector-plugins~1{plugin_name}~1config~1validate/put'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
      sqlVerbs:
        select:
          - $ref: '#/components/x-stackQL-resources/managed_connector_plugins/methods/list_connectv1connector_plugins'
        insert: []
        update: []
        replace: []
        delete: []
    connector_offsets:
      id: confluent.connect.connector_offsets
      name: connector_offsets
      title: Connector Offsets
      methods:
        get_connectv1connector_offsets:
          operation:
            $ref: '#/paths/~1connect~1v1~1environments~1{environment_id}~1clusters~1{kafka_cluster_id}~1connectors~1{connector_name}~1offsets/get'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
            schemaRef: '#/components/schemas/connect.v1.ConnectorOffsets'
      sqlVerbs:
        select:
          - $ref: '#/components/x-stackQL-resources/connector_offsets/methods/get_connectv1connector_offsets'
        insert: []
        update: []
        replace: []
        delete: []
    connector_offsets_requests:
      id: confluent.connect.connector_offsets_requests
      name: connector_offsets_requests
      title: Connector Offsets Requests
      methods:
        alter_connectv1connector_offsets_request:
          operation:
            $ref: '#/paths/~1connect~1v1~1environments~1{environment_id}~1clusters~1{kafka_cluster_id}~1connectors~1{connector_name}~1offsets~1request/post'
          response:
            mediaType: application/json
            openAPIDocKey: '202'
            schemaRef: '#/components/schemas/connect.v1.AlterOffsetRequestInfo'
        get_connectv1connector_offsets_request_status:
          operation:
            $ref: '#/paths/~1connect~1v1~1environments~1{environment_id}~1clusters~1{kafka_cluster_id}~1connectors~1{connector_name}~1offsets~1request~1status/get'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
            schemaRef: '#/components/schemas/connect.v1.AlterOffsetStatus'
      sqlVerbs:
        select:
          - $ref: '#/components/x-stackQL-resources/connector_offsets_requests/methods/get_connectv1connector_offsets_request_status'
        insert: []
        update: []
        replace: []
        delete: []
    custom_connector_plugins:
      id: confluent.connect.custom_connector_plugins
      name: custom_connector_plugins
      title: Custom Connector Plugins
      methods:
        list_connect_v1custom_connector_plugins:
          operation:
            $ref: '#/paths/~1connect~1v1~1custom-connector-plugins/get'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
            objectKey: $.data
        create_connect_v1custom_connector_plugin:
          operation:
            $ref: '#/paths/~1connect~1v1~1custom-connector-plugins/post'
          response:
            mediaType: application/json
            openAPIDocKey: '201'
        get_connect_v1custom_connector_plugin:
          operation:
            $ref: '#/paths/~1connect~1v1~1custom-connector-plugins~1{id}/get'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        update_connect_v1custom_connector_plugin:
          operation:
            $ref: '#/paths/~1connect~1v1~1custom-connector-plugins~1{id}/patch'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        delete_connect_v1custom_connector_plugin:
          operation:
            $ref: '#/paths/~1connect~1v1~1custom-connector-plugins~1{id}/delete'
          response:
            mediaType: application/json
            openAPIDocKey: '204'
      sqlVerbs:
        select:
          - $ref: '#/components/x-stackQL-resources/custom_connector_plugins/methods/get_connect_v1custom_connector_plugin'
          - $ref: '#/components/x-stackQL-resources/custom_connector_plugins/methods/list_connect_v1custom_connector_plugins'
        insert:
          - $ref: '#/components/x-stackQL-resources/custom_connector_plugins/methods/create_connect_v1custom_connector_plugin'
        update:
          - $ref: '#/components/x-stackQL-resources/custom_connector_plugins/methods/update_connect_v1custom_connector_plugin'
        replace: []
        delete:
          - $ref: '#/components/x-stackQL-resources/custom_connector_plugins/methods/delete_connect_v1custom_connector_plugin'
    presigned_urls:
      id: confluent.connect.presigned_urls
      name: presigned_urls
      title: Presigned Urls
      methods:
        presigned_upload_url_connect_v1presigned_url:
          operation:
            $ref: '#/paths/~1connect~1v1~1presigned-upload-url/post'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
      sqlVerbs:
        select: []
        insert: []
        update: []
        replace: []
        delete: []
paths:
  '/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors':
    get:
      operationId: listConnectv1Connectors
      description: |-
        [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Retrieve a list of "names" of the active connectors. You can then make a [read request](#operation/readConnectv1Connector) for a specific connector by name.
      summary: List of Connectors
      tags:
        - Connectors (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      parameters:
        - name: environment_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier of the environment this resource belongs to.
        - name: kafka_cluster_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier for the Kafka cluster.
      responses:
        '200':
          description: Connector.
          content:
            application/json:
              schema:
                type: array
                description: List of connector names
                items:
                  type: string
                  description: Connector name
              example:
                - MyGcsLogsBucketConnector
                - MyS3BucketConnector
                - MyDatagenConnector
        '401':
          $ref: '#/components/responses/connect.v1.UnauthenticatedError'
        '404':
          $ref: '#/components/responses/connect.v1.AccountNotFoundError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/connect.v1.DefaultSystemError'
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request GET \
              --url 'https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors' \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors")
              .get()
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors\"\n\n\treq, _ := http.NewRequest(\"GET\", url, nil)\n\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            headers = { 'Authorization': "Basic REPLACE_BASIC_AUTH" }

            conn.request("GET", "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors", headers=headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "GET",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors",
              "headers": {
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "GET");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors");
            var request = new RestRequest(Method.GET);
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            IRestResponse response = client.Execute(request);
    post:
      operationId: createConnectv1Connector
      description: |-
        [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Create a new connector. Returns the new connector information if successful.
      summary: Create a Connector
      tags:
        - Connectors (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      responses:
        '201':
          description: Created
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/connect.v1.ConnectorWithOffsets'
              example:
                name: MyGcsLogsBucketConnector
                config:
                  cloud.environment: prod
                  cloud.provider: aws
                  connector.class: GcsSink
                  data.format: BYTES
                  flush.size: '1000'
                  gcs.bucket.name: APILogsBucket
                  gcs.credentials.config: '****************'
                  kafka.api.key: '****************'
                  kafka.api.secret: '****************'
                  kafka.endpoint: 'SASL_SSL://pkc-xxxxx.us-west-2.aws.confluent.cloud:9092'
                  kafka.region: us-west-2
                  name: MyGcsLogsBucketConnector
                  tasks.max: '1'
                  time.interval: DAILY
                  topics: APILogsTopic
                tasks:
                  - connector: MyGcsLogsBucketConnector
                    task: 0
                type: sink
                offsets:
                  - partition:
                      kafka_partition: 0
                      kafka_topic: APILogsTopic
                    offset:
                      kafka_offset: 1000
          headers: {}
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                type: object
                properties:
                  code:
                    type: integer
                  message:
                    type: string
              example:
                error:
                  code: 400
                  message: Unauthorized
        '401':
          $ref: '#/components/responses/connect.v1.UnauthenticatedError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                type: object
                properties:
                  error_code:
                    type: integer
                  message:
                    type: string
              example:
                error_code: 500
                message: Failed to find any class that implements Connector and which name matches io.confluent.connect.<connector-class>...
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                name:
                  type: string
                  description: Name of the connector to create.
                config:
                  type: object
                  description: Configuration parameters for the connector. All values should be strings.
                  x-redact: true
                  required:
                    - connector.class
                    - name
                    - kafka.api.key
                    - kafka.api.secret
                  properties:
                    connector.class:
                      type: string
                      description: '\[Required for Managed Connector, Ignored for Custom Connector\] The connector class name, e.g., BigQuerySink, GcsSink, etc.'
                    name:
                      type: string
                      description: 'Name or alias of the class (plugin) for this connector. For custom connector, it must be the same as the name of the connector to create.'
                    kafka.api.key:
                      type: string
                      description: The kafka cluster api key.
                    kafka.api.secret:
                      type: string
                      description: The kafka cluster api secret key.
                      x-redact: true
                    confluent.connector.type:
                      type: string
                      description: |
                        \[Required for Custom Connector\] The connector type.
                      example: CUSTOM
                      default: MANAGED
                      x-extensible-enum:
                        - CUSTOM
                        - MANAGED
                    confluent.custom.plugin.id:
                      type: string
                      example: ccp-lq5m06
                      description: |
                        \[Required for Custom Connector\] The custom plugin id of custom connector, e.g., `ccp-lq5m06`
                    confluent.custom.connection.endpoints:
                      type: string
                      description: |
                        \[Optional for Custom Connector\] Egress endpoint(s) for the connector to use when attaching to the sink or source data system.
                    confluent.custom.schema.registry.auto:
                      type: string
                      description: |
                        \[Optional for Custom Connector\] Automatically add the required schema registry properties in a custom connector config if schema registry is enabled.
                      example: 'FALSE'
                      default: 'FALSE'
                      x-extensible-enum:
                        - 'TRUE'
                        - 'FALSE'
                  additionalProperties:
                    type: string
                    description: Other configuration parameters for the connector. All values should be strings. See the connector's docs for details.
                offsets:
                  $ref: '#/components/schemas/connect.v1.Offsets'
            examples:
              sink:
                value:
                  name: MyGcsLogsBucketConnector
                  config:
                    connector.class: GcsSink
                    data.format: BYTES
                    flush.size: '1000'
                    gcs.bucket.name: APILogsBucket
                    gcs.credentials.config: '****************'
                    kafka.api.key: '****************'
                    kafka.api.secret: '****************'
                    name: MyGcsLogsBucketConnector
                    tasks.max: '2'
                    time.interval: DAILY
                    topics: APILogsTopic
                  offsets:
                    - partition:
                        kafka_partition: 0
                        kafka_topic: APILogsTopic
                      offset:
                        kafka_offset: 1000
              source:
                value:
                  name: MySqlCdcSourceV2Connector_0
                  config:
                    connector.class: MySqlCdcSourceV2
                    output.data.format: JSON
                    flush.size: '1000'
                    database.hostname: 12.34.567.98
                    database.password: '****************'
                    database.port: '1234'
                    database.user: '****'
                    kafka.api.key: '****************'
                    kafka.api.secret: '****************'
                    name: MySqlCdcSourceV2Connector_0
                    tasks.max: '1'
                    time.interval: DAILY
                    topic.prefix: test
                  offsets:
                    - partition:
                        server: test
                      offset:
                        file: mysql-bin.000123
                        pos: 154
                        ts_sec: 1712907333
        description: ''
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request POST \
              --url 'https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors' \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH' \
              --header 'content-type: application/json' \
              --data '{"name":"string","config":{"connector.class":"string","name":"string","kafka.api.key":"string","kafka.api.secret":"string","confluent.connector.type":"CUSTOM","confluent.custom.plugin.id":"ccp-lq5m06","confluent.custom.connection.endpoints":"string","confluent.custom.schema.registry.auto":"FALSE","property1":"string","property2":"string"},"offsets":[{"partition":{},"offset":{}}]}'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            MediaType mediaType = MediaType.parse("application/json");
            RequestBody body = RequestBody.create(mediaType, "{\"name\":\"string\",\"config\":{\"connector.class\":\"string\",\"name\":\"string\",\"kafka.api.key\":\"string\",\"kafka.api.secret\":\"string\",\"confluent.connector.type\":\"CUSTOM\",\"confluent.custom.plugin.id\":\"ccp-lq5m06\",\"confluent.custom.connection.endpoints\":\"string\",\"confluent.custom.schema.registry.auto\":\"FALSE\",\"property1\":\"string\",\"property2\":\"string\"},\"offsets\":[{\"partition\":{},\"offset\":{}}]}");
            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors")
              .post(body)
              .addHeader("content-type", "application/json")
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors\"\n\n\tpayload := strings.NewReader(\"{\\\"name\\\":\\\"string\\\",\\\"config\\\":{\\\"connector.class\\\":\\\"string\\\",\\\"name\\\":\\\"string\\\",\\\"kafka.api.key\\\":\\\"string\\\",\\\"kafka.api.secret\\\":\\\"string\\\",\\\"confluent.connector.type\\\":\\\"CUSTOM\\\",\\\"confluent.custom.plugin.id\\\":\\\"ccp-lq5m06\\\",\\\"confluent.custom.connection.endpoints\\\":\\\"string\\\",\\\"confluent.custom.schema.registry.auto\\\":\\\"FALSE\\\",\\\"property1\\\":\\\"string\\\",\\\"property2\\\":\\\"string\\\"},\\\"offsets\\\":[{\\\"partition\\\":{},\\\"offset\\\":{}}]}\")\n\n\treq, _ := http.NewRequest(\"POST\", url, payload)\n\n\treq.Header.Add(\"content-type\", \"application/json\")\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            payload = "{\"name\":\"string\",\"config\":{\"connector.class\":\"string\",\"name\":\"string\",\"kafka.api.key\":\"string\",\"kafka.api.secret\":\"string\",\"confluent.connector.type\":\"CUSTOM\",\"confluent.custom.plugin.id\":\"ccp-lq5m06\",\"confluent.custom.connection.endpoints\":\"string\",\"confluent.custom.schema.registry.auto\":\"FALSE\",\"property1\":\"string\",\"property2\":\"string\"},\"offsets\":[{\"partition\":{},\"offset\":{}}]}"

            headers = {
                'content-type': "application/json",
                'Authorization': "Basic REPLACE_BASIC_AUTH"
                }

            conn.request("POST", "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors", payload, headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "POST",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors",
              "headers": {
                "content-type": "application/json",
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.write(JSON.stringify({
              name: 'string',
              config: {
                'connector.class': 'string',
                name: 'string',
                'kafka.api.key': 'string',
                'kafka.api.secret': 'string',
                'confluent.connector.type': 'CUSTOM',
                'confluent.custom.plugin.id': 'ccp-lq5m06',
                'confluent.custom.connection.endpoints': 'string',
                'confluent.custom.schema.registry.auto': 'FALSE',
                property1: 'string',
                property2: 'string'
              },
              offsets: [{partition: {}, offset: {}}]
            }));
            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "POST");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "content-type: application/json");
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            curl_easy_setopt(hnd, CURLOPT_POSTFIELDS, "{\"name\":\"string\",\"config\":{\"connector.class\":\"string\",\"name\":\"string\",\"kafka.api.key\":\"string\",\"kafka.api.secret\":\"string\",\"confluent.connector.type\":\"CUSTOM\",\"confluent.custom.plugin.id\":\"ccp-lq5m06\",\"confluent.custom.connection.endpoints\":\"string\",\"confluent.custom.schema.registry.auto\":\"FALSE\",\"property1\":\"string\",\"property2\":\"string\"},\"offsets\":[{\"partition\":{},\"offset\":{}}]}");

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors");
            var request = new RestRequest(Method.POST);
            request.AddHeader("content-type", "application/json");
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            request.AddParameter("application/json", "{\"name\":\"string\",\"config\":{\"connector.class\":\"string\",\"name\":\"string\",\"kafka.api.key\":\"string\",\"kafka.api.secret\":\"string\",\"confluent.connector.type\":\"CUSTOM\",\"confluent.custom.plugin.id\":\"ccp-lq5m06\",\"confluent.custom.connection.endpoints\":\"string\",\"confluent.custom.schema.registry.auto\":\"FALSE\",\"property1\":\"string\",\"property2\":\"string\"},\"offsets\":[{\"partition\":{},\"offset\":{}}]}", ParameterType.RequestBody);
            IRestResponse response = client.Execute(request);
      parameters:
        - name: environment_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier of the environment this resource belongs to.
        - name: kafka_cluster_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier for the Kafka cluster.
  '/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors?expand=info,status,id':
    get:
      operationId: listConnectv1ConnectorsWithExpansions
      description: |-
        [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Retrieve an object with the queried expansions of all connectors. Without `expand` query parameter, this list connectors endpoint will return a [list of only the connector names](#operation/listConnectv1Connectors).
      summary: List of Connectors with Expansions
      tags:
        - Connectors (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      responses:
        '200':
          description: Connector.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/connect.v1.ConnectorExpansionMap'
              example:
                MyGcsLogsBucketConnector:
                  id:
                    id: lcc-xxxxx
                    id_type: ID
                  info:
                    name: MyGcsLogsBucketConnector
                    config:
                      cloud.environment: prod
                      cloud.provider: aws
                      connector.class: GcsSink
                      data.format: BYTES
                      flush.size: '1000'
                      gcs.bucket.name: APILogsBucket
                      gcs.credentials.config: '****************'
                      kafka.api.key: '****************'
                      kafka.api.secret: '****************'
                      kafka.endpoint: 'SASL_SSL://pkc-xxxxx.us-west-2.aws.confluent.cloud:9092'
                      kafka.region: us-west-2
                      name: MyGcsLogsBucketConnector
                      tasks.max: '1'
                      time.interval: DAILY
                      topics: APILogsTopic
                      type: sink
                  status:
                    name: MyGcsLogsBucketConnector
                    connector:
                      state: PROVISIONING
                      worker_id: MyGcsLogsBucketConnector
                      trace: ''
                    tasks: []
                    type: sink
                MyS3BucketConnector:
                  id:
                    id: lcc-xxxxx
                    id_type: ID
                  info:
                    name: MyS3BucketConnector
                    config:
                      cloud.environment: prod
                      cloud.provider: aws
                      connector.class: S3Sink
                      data.format: BYTES
                      flush.size: '1000'
                      s3.bucket: APILogsBucket
                      aws.access.key.id: '************'
                      aws.secret.access.key: '**********'
                      kafka.api.key: '****************'
                      kafka.api.secret: '****************'
                      kafka.endpoint: 'SASL_SSL://pkc-xxxxx.us-west-2.aws.confluent.cloud:9092'
                      kafka.region: us-west-2
                      name: MyS3BucketConnector
                      tasks.max: '1'
                      time.interval: DAILY
                      topics: APILogsTopic
                      type: source
                  status:
                    name: MyS3BucketConnector
                    connector:
                      state: FAILED
                      worker_id: MyS3BucketConnector
                      trace: |
                        There were some errors with your configuration:
                        topics: Provided Kafka ApiKey is invalid
                        kafka.api.secret: Provided Kafka ApiKey is invalid
                    tasks: []
                    type: sink
                MyDatagenConnector:
                  id:
                    id: lcc-xxxxx
                    id_type: ID
                  info:
                    name: MyDatagenConnector
                    config:
                      cloud.environment: prod
                      cloud.provider: aws
                      connector.class: DatagenSource
                      data.format: BYTES
                      flush.size: '1000'
                      quickstart: ORDERS
                      kafka.api.key: '****************'
                      kafka.api.secret: '****************'
                      kafka.endpoint: 'SASL_SSL://pkc-xxxxx.us-west-2.aws.confluent.cloud:9092'
                      kafka.region: us-west-2
                      name: MyDatagenConnector
                      tasks.max: '1'
                      time.interval: DAILY
                      topics: APILogsTopic
                      type: source
                  status:
                    name: MyDatagenConnector
                    connector:
                      state: RUNNING
                      worker_id: MyDatagenConnector
                      trace: ''
                    tasks:
                      - id: 0
                        msg: ''
                        state: RUNNING
                        worker_id: MyDatagenConnector
                    type: source
        '401':
          $ref: '#/components/responses/connect.v1.UnauthenticatedError'
        '404':
          $ref: '#/components/responses/connect.v1.AccountNotFoundError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/connect.v1.DefaultSystemError'
      parameters:
        - name: environment_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier of the environment this resource belongs to.
        - name: kafka_cluster_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier for the Kafka cluster.
        - name: expand
          in: query
          description: |-
            - id : Returns metadata of each connector such as id and id type.
            - info : Returns metadata of each connector such as the configuration, task
            information, and type of connector.
            - status : Returns additional state information of each connector including their status and tasks.
          schema:
            type: string
            enum:
              - id
              - info
              - status
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request GET \
              --url 'https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors?expand=info,status,id' \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors?expand=info,status,id")
              .get()
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors?expand=info,status,id\"\n\n\treq, _ := http.NewRequest(\"GET\", url, nil)\n\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            headers = { 'Authorization': "Basic REPLACE_BASIC_AUTH" }

            conn.request("GET", "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors?expand=info,status,id", headers=headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "GET",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors?expand=info,status,id",
              "headers": {
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "GET");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors?expand=info,status,id");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors?expand=info,status,id");
            var request = new RestRequest(Method.GET);
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            IRestResponse response = client.Execute(request);
  '/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/config':
    get:
      operationId: getConnectv1ConnectorConfig
      description: |-
        [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Get the configuration for the connector.
      summary: Read a Connector Configuration
      tags:
        - Connectors (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      responses:
        '200':
          description: Connector.
          content:
            application/json:
              schema:
                type: object
                description: Configuration parameters for the connector.
                required:
                  - cloud.environment
                  - cloud.provider
                  - connector.class
                  - name
                  - kafka.endpoint
                  - kafka.region
                  - kafka.api.key
                  - kafka.api.secret
                properties:
                  cloud.environment:
                    type: string
                    description: The cloud environment type.
                  cloud.provider:
                    type: string
                    description: 'The cloud service provider, e.g. aws, azure, etc.'
                    x-extensible-enum:
                      - aws
                      - azure
                      - gcp
                  connector.class:
                    type: string
                    description: 'The connector class name. E.g. BigQuerySink, GcsSink, etc.'
                  name:
                    type: string
                    description: 'Name or alias of the class (plugin) for this connector. For Custom Connector, it must be the same as connector_name.'
                  kafka.endpoint:
                    type: string
                    description: The kafka cluster endpoint.
                  kafka.region:
                    type: string
                    description: The kafka cluster region.
                  kafka.api.key:
                    type: string
                    description: The kafka cluster api key.
                  kafka.api.secret:
                    type: string
                    description: The kafka cluster api secret key.
                    x-redact: true
                additionalProperties:
                  type: string
                  description: Other configuration parameters for the connector. See the connector's docs for the list of options.
              example:
                cloud.environment: prod
                cloud.provider: aws
                connector.class: GcsSink
                data.format: BYTES
                flush.size: '1000'
                gcs.bucket.name: APILogsBucket
                gcs.credentials.config: '****************'
                kafka.api.key: '****************'
                kafka.api.secret: '****************'
                kafka.endpoint: 'SASL_SSL://pkc-xxxxx.us-west-2.aws.confluent.cloud:9092'
                kafka.region: us-west-2
                name: MyGcsLogsBucketConnector
                tasks.max: '2'
                time.interval: DAILY
                topics: APILogsTopic
        '401':
          $ref: '#/components/responses/connect.v1.UnauthenticatedError'
        '404':
          $ref: '#/components/responses/connect.v1.AccountNotFoundError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/connect.v1.DefaultSystemError'
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request GET \
              --url 'https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/config' \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/config")
              .get()
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/config\"\n\n\treq, _ := http.NewRequest(\"GET\", url, nil)\n\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            headers = { 'Authorization': "Basic REPLACE_BASIC_AUTH" }

            conn.request("GET", "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/config", headers=headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "GET",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/config",
              "headers": {
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "GET");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/config");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/config");
            var request = new RestRequest(Method.GET);
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            IRestResponse response = client.Execute(request);
      parameters:
        - name: connector_name
          in: path
          schema:
            type: string
          required: true
          description: The unique name of the connector.
        - name: environment_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier of the environment this resource belongs to.
        - name: kafka_cluster_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier for the Kafka cluster.
    put:
      operationId: createOrUpdateConnectv1ConnectorConfig
      description: 'Create a new connector using the given configuration, or update the configuration for an existing connector. Returns information about the connector after the change has been made.'
      summary: Create or Update a Connector Configuration
      tags:
        - Connectors (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      requestBody:
        content:
          application/json:
            schema:
              type: object
              description: Configuration parameters for the connector.
              required:
                - connector.class
                - name
                - kafka.api.key
                - kafka.api.secret
              properties:
                connector.class:
                  type: string
                  description: '\[Required for Managed Connector, Ignored for Custom Connector\] The connector class name. E.g. BigQuerySink, GcsSink, etc.'
                name:
                  type: string
                  description: Name or alias of the class (plugin) for this connector.
                kafka.api.key:
                  type: string
                  description: The kafka cluster api key.
                kafka.api.secret:
                  type: string
                  description: The kafka cluster api secret key.
                  x-redact: true
                confluent.connector.type:
                  type: string
                  description: |
                    \[Required for Custom Connector\] The connector type.
                  example: CUSTOM
                  default: MANAGED
                  x-extensible-enum:
                    - CUSTOM
                    - MANAGED
                confluent.custom.plugin.id:
                  type: string
                  example: ccp-lq5m06
                  description: |
                    \[Required for Custom Connector\] The custom plugin id of custom connector, e.g., `ccp-lq5m06`
                confluent.custom.connection.endpoints:
                  type: string
                  description: |
                    \[Optional for Custom Connector\] Egress endpoint(s) for the connector to use when attaching to the sink or source data system.
                confluent.custom.schema.registry.auto:
                  type: string
                  description: |
                    \[Optional for Custom Connector\] Automatically add the required schema registry properties in a custom connector config if schema registry is enabled.
                  example: 'FALSE'
                  default: 'FALSE'
                  x-extensible-enum:
                    - 'TRUE'
                    - 'FALSE'
              additionalProperties:
                type: string
                description: Other configuration parameters for the connector. All values should be strings. See the connector's docs for details.
            example:
              connector.class: GcsSink
              data.format: BYTES
              flush.size: '1000'
              gcs.bucket.name: APILogsBucket
              gcs.credentials.config: '****************'
              kafka.api.key: '****************'
              kafka.api.secret: '****************'
              name: MyGcsLogsBucketConnector
              tasks.max: '2'
              time.interval: DAILY
              topics: APILogsTopic
        description: Configuration parameters for the connector. All values should be strings.
      responses:
        '200':
          description: Created
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/connect.v1.Connector'
              example:
                name: MyGcsLogsBucketConnector
                config:
                  cloud.environment: prod
                  cloud.provider: aws
                  connector.class: GcsSink
                  data.format: BYTES
                  flush.size: '1000'
                  gcs.bucket.name: APILogsBucket
                  gcs.credentials.config: '****************'
                  kafka.api.key: '****************'
                  kafka.api.secret: '****************'
                  kafka.endpoint: 'SASL_SSL://pkc-xxxxx.us-west-2.aws.confluent.cloud:9092'
                  kafka.region: us-west-2
                  name: MyGcsLogsBucketConnector
                  tasks.max: '2'
                  time.interval: DAILY
                  topics: APILogsTopic
                tasks:
                  - connector: MyGcsLogsBucketConnector
                    task: 0
                  - connector: MyGcsLogsBucketConnector
                    task: 1
                type: sink
        '400':
          $ref: '#/components/responses/connect.v1.BadRequestError'
        '401':
          $ref: '#/components/responses/connect.v1.UnauthenticatedError'
        '404':
          $ref: '#/components/responses/connect.v1.AccountNotFoundError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                type: object
                properties:
                  error_code:
                    type: integer
                  message:
                    type: string
              example:
                error_code: 500
                message: Failed to find any class that implements Connector and which name matches io.confluent.connect.<connector-class>...
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request PUT \
              --url 'https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/config' \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH' \
              --header 'content-type: application/json' \
              --data '{"connector.class":"string","name":"string","kafka.api.key":"string","kafka.api.secret":"string","confluent.connector.type":"CUSTOM","confluent.custom.plugin.id":"ccp-lq5m06","confluent.custom.connection.endpoints":"string","confluent.custom.schema.registry.auto":"FALSE","property1":"string","property2":"string"}'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            MediaType mediaType = MediaType.parse("application/json");
            RequestBody body = RequestBody.create(mediaType, "{\"connector.class\":\"string\",\"name\":\"string\",\"kafka.api.key\":\"string\",\"kafka.api.secret\":\"string\",\"confluent.connector.type\":\"CUSTOM\",\"confluent.custom.plugin.id\":\"ccp-lq5m06\",\"confluent.custom.connection.endpoints\":\"string\",\"confluent.custom.schema.registry.auto\":\"FALSE\",\"property1\":\"string\",\"property2\":\"string\"}");
            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/config")
              .put(body)
              .addHeader("content-type", "application/json")
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/config\"\n\n\tpayload := strings.NewReader(\"{\\\"connector.class\\\":\\\"string\\\",\\\"name\\\":\\\"string\\\",\\\"kafka.api.key\\\":\\\"string\\\",\\\"kafka.api.secret\\\":\\\"string\\\",\\\"confluent.connector.type\\\":\\\"CUSTOM\\\",\\\"confluent.custom.plugin.id\\\":\\\"ccp-lq5m06\\\",\\\"confluent.custom.connection.endpoints\\\":\\\"string\\\",\\\"confluent.custom.schema.registry.auto\\\":\\\"FALSE\\\",\\\"property1\\\":\\\"string\\\",\\\"property2\\\":\\\"string\\\"}\")\n\n\treq, _ := http.NewRequest(\"PUT\", url, payload)\n\n\treq.Header.Add(\"content-type\", \"application/json\")\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            payload = "{\"connector.class\":\"string\",\"name\":\"string\",\"kafka.api.key\":\"string\",\"kafka.api.secret\":\"string\",\"confluent.connector.type\":\"CUSTOM\",\"confluent.custom.plugin.id\":\"ccp-lq5m06\",\"confluent.custom.connection.endpoints\":\"string\",\"confluent.custom.schema.registry.auto\":\"FALSE\",\"property1\":\"string\",\"property2\":\"string\"}"

            headers = {
                'content-type': "application/json",
                'Authorization': "Basic REPLACE_BASIC_AUTH"
                }

            conn.request("PUT", "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/config", payload, headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "PUT",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/config",
              "headers": {
                "content-type": "application/json",
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.write(JSON.stringify({
              'connector.class': 'string',
              name: 'string',
              'kafka.api.key': 'string',
              'kafka.api.secret': 'string',
              'confluent.connector.type': 'CUSTOM',
              'confluent.custom.plugin.id': 'ccp-lq5m06',
              'confluent.custom.connection.endpoints': 'string',
              'confluent.custom.schema.registry.auto': 'FALSE',
              property1: 'string',
              property2: 'string'
            }));
            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "PUT");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/config");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "content-type: application/json");
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            curl_easy_setopt(hnd, CURLOPT_POSTFIELDS, "{\"connector.class\":\"string\",\"name\":\"string\",\"kafka.api.key\":\"string\",\"kafka.api.secret\":\"string\",\"confluent.connector.type\":\"CUSTOM\",\"confluent.custom.plugin.id\":\"ccp-lq5m06\",\"confluent.custom.connection.endpoints\":\"string\",\"confluent.custom.schema.registry.auto\":\"FALSE\",\"property1\":\"string\",\"property2\":\"string\"}");

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/config");
            var request = new RestRequest(Method.PUT);
            request.AddHeader("content-type", "application/json");
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            request.AddParameter("application/json", "{\"connector.class\":\"string\",\"name\":\"string\",\"kafka.api.key\":\"string\",\"kafka.api.secret\":\"string\",\"confluent.connector.type\":\"CUSTOM\",\"confluent.custom.plugin.id\":\"ccp-lq5m06\",\"confluent.custom.connection.endpoints\":\"string\",\"confluent.custom.schema.registry.auto\":\"FALSE\",\"property1\":\"string\",\"property2\":\"string\"}", ParameterType.RequestBody);
            IRestResponse response = client.Execute(request);
      parameters:
        - name: connector_name
          in: path
          schema:
            type: string
          required: true
          description: The unique name of the connector.
        - name: environment_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier of the environment this resource belongs to.
        - name: kafka_cluster_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier for the Kafka cluster.
  '/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}':
    get:
      operationId: readConnectv1Connector
      description: |-
        [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Get information about the connector.
      summary: Read a Connector
      tags:
        - Connectors (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      responses:
        '200':
          description: Connector.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/connect.v1.Connector'
              example:
                name: MyGcsLogsBucketConnector
                config:
                  cloud.environment: prod
                  cloud.provider: aws
                  connector.class: GcsSink
                  data.format: BYTES
                  flush.size: '1000'
                  gcs.bucket.name: APILogsBucket
                  gcs.credentials.config: '****************'
                  kafka.api.key: '****************'
                  kafka.api.secret: '****************'
                  kafka.endpoint: 'SASL_SSL://pkc-xxxxx.us-west-2.aws.confluent.cloud:9092'
                  kafka.region: us-west-2
                  name: MyGcsLogsBucketConnector
                  tasks.max: '1'
                  time.interval: DAILY
                  topics: APILogsTopic
                tasks:
                  - connector: MyGcsLogsBucketConnector
                    task: 0
                type: sink
        '401':
          $ref: '#/components/responses/connect.v1.UnauthenticatedError'
        '404':
          $ref: '#/components/responses/connect.v1.AccountNotFoundError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/connect.v1.DefaultSystemError'
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request GET \
              --url 'https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}' \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}")
              .get()
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}\"\n\n\treq, _ := http.NewRequest(\"GET\", url, nil)\n\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            headers = { 'Authorization': "Basic REPLACE_BASIC_AUTH" }

            conn.request("GET", "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}", headers=headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "GET",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}",
              "headers": {
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "GET");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}");
            var request = new RestRequest(Method.GET);
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            IRestResponse response = client.Execute(request);
      parameters:
        - name: connector_name
          in: path
          schema:
            type: string
          required: true
          description: The unique name of the connector.
        - name: environment_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier of the environment this resource belongs to.
        - name: kafka_cluster_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier for the Kafka cluster.
    delete:
      operationId: deleteConnectv1Connector
      description: |-
        [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Delete a connector. Halts all tasks and deletes the connector configuration.
      summary: Delete a Connector
      tags:
        - Connectors (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      responses:
        '200':
          $ref: '#/components/responses/connect.v1.OK'
        '401':
          $ref: '#/components/responses/connect.v1.UnauthenticatedError'
        '404':
          $ref: '#/components/responses/connect.v1.ResourceNotFoundError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/connect.v1.DefaultSystemError'
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request DELETE \
              --url 'https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}' \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}")
              .delete(null)
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}\"\n\n\treq, _ := http.NewRequest(\"DELETE\", url, nil)\n\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            headers = { 'Authorization': "Basic REPLACE_BASIC_AUTH" }

            conn.request("DELETE", "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}", headers=headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "DELETE",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}",
              "headers": {
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "DELETE");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}");
            var request = new RestRequest(Method.DELETE);
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            IRestResponse response = client.Execute(request);
      parameters:
        - name: connector_name
          in: path
          schema:
            type: string
          required: true
          description: The unique name of the connector.
        - name: environment_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier of the environment this resource belongs to.
        - name: kafka_cluster_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier for the Kafka cluster.
  '/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/pause':
    put:
      operationId: pauseConnectv1Connector
      description: |-
        [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Pause the connector and its tasks. Stops message processing until the connector is resumed. This call is asynchronous and the tasks will not transition to PAUSED state at the same time.
      summary: Pause a Connector
      tags:
        - Lifecycle (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      responses:
        '202':
          description: Accepted
        '401':
          $ref: '#/components/responses/connect.v1.UnauthenticatedError'
        '404':
          $ref: '#/components/responses/connect.v1.ResourceNotFoundError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/connect.v1.DefaultSystemError'
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request PUT \
              --url 'https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/pause' \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/pause")
              .put(null)
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/pause\"\n\n\treq, _ := http.NewRequest(\"PUT\", url, nil)\n\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            headers = { 'Authorization': "Basic REPLACE_BASIC_AUTH" }

            conn.request("PUT", "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/pause", headers=headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "PUT",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/pause",
              "headers": {
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "PUT");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/pause");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/pause");
            var request = new RestRequest(Method.PUT);
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            IRestResponse response = client.Execute(request);
      parameters:
        - name: connector_name
          in: path
          schema:
            type: string
          required: true
          description: The unique name of the connector.
        - name: environment_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier of the environment this resource belongs to.
        - name: kafka_cluster_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier for the Kafka cluster.
  '/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/resume':
    put:
      operationId: resumeConnectv1Connector
      description: |-
        [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Resume a paused connector or do nothing if the connector is not paused. This call is asynchronous and the tasks will not transition to RUNNING state at the same time.
      summary: Resume a Connector
      tags:
        - Lifecycle (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      responses:
        '202':
          description: Accepted
        '401':
          $ref: '#/components/responses/connect.v1.UnauthenticatedError'
        '404':
          $ref: '#/components/responses/connect.v1.ResourceNotFoundError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/connect.v1.DefaultSystemError'
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request PUT \
              --url 'https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/resume' \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/resume")
              .put(null)
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/resume\"\n\n\treq, _ := http.NewRequest(\"PUT\", url, nil)\n\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            headers = { 'Authorization': "Basic REPLACE_BASIC_AUTH" }

            conn.request("PUT", "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/resume", headers=headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "PUT",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/resume",
              "headers": {
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "PUT");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/resume");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/resume");
            var request = new RestRequest(Method.PUT);
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            IRestResponse response = client.Execute(request);
      parameters:
        - name: connector_name
          in: path
          schema:
            type: string
          required: true
          description: The unique name of the connector.
        - name: environment_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier of the environment this resource belongs to.
        - name: kafka_cluster_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier for the Kafka cluster.
  '/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/status':
    get:
      operationId: readConnectv1ConnectorStatus
      description: 'Get current status of the connector. This includes whether it is running, failed, or paused. Also includes which worker it is assigned to, error information if it has failed, and the state of all its tasks.'
      summary: Read a Connector Status
      tags:
        - Status (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      responses:
        '200':
          description: Connector.
          content:
            application/json:
              schema:
                type: object
                properties:
                  name:
                    type: string
                    description: The name of the connector.
                  type:
                    type: string
                    description: 'Type of connector, sink or source.'
                    enum:
                      - sink
                      - source
                  connector:
                    type: object
                    description: The map containing connector status.
                    required:
                      - state
                      - worker_id
                    properties:
                      state:
                        type: string
                        description: The state of the connector.
                        enum:
                          - NONE
                          - PROVISIONING
                          - RUNNING
                          - DEGRADED
                          - FAILED
                          - PAUSED
                          - DELETED
                      worker_id:
                        type: string
                        description: The worker ID of the connector.
                      trace:
                        type: string
                        description: The exception name in case of error.
                  tasks:
                    type: array
                    description: The map containing the task status.
                    items:
                      type: object
                      properties:
                        id:
                          type: integer
                          description: The ID of task.
                        state:
                          type: string
                          description: The state of the task.
                        worker_id:
                          type: string
                          description: The worker ID of the task.
                        msg:
                          type: string
                      required:
                        - id
                        - state
                        - worker_id
                required:
                  - name
                  - type
                  - connector
              example:
                name: MyGcsLogsBucketConnector
                connector:
                  state: PROVISIONING
                  worker_id: MyGcsLogsBucketConnector
                  trace: ''
                tasks: []
                type: source
        '401':
          $ref: '#/components/responses/connect.v1.UnauthenticatedError'
        '404':
          $ref: '#/components/responses/connect.v1.AccountNotFoundError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/connect.v1.DefaultSystemError'
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request GET \
              --url 'https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/status' \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/status")
              .get()
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/status\"\n\n\treq, _ := http.NewRequest(\"GET\", url, nil)\n\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            headers = { 'Authorization': "Basic REPLACE_BASIC_AUTH" }

            conn.request("GET", "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/status", headers=headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "GET",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/status",
              "headers": {
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "GET");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/status");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/status");
            var request = new RestRequest(Method.GET);
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            IRestResponse response = client.Execute(request);
      parameters:
        - name: connector_name
          in: path
          schema:
            type: string
          required: true
          description: The unique name of the connector.
        - name: environment_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier of the environment this resource belongs to.
        - name: kafka_cluster_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier for the Kafka cluster.
  '/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/tasks':
    get:
      operationId: listConnectv1ConnectorTasks
      description: |-
        [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Get a list of tasks currently running for the connector.
      summary: List of Connector Tasks
      tags:
        - Status (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      responses:
        '200':
          description: Connector Task.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/connect.v1.Connectors'
              example:
                - id:
                    connector: MyGcsLogsBucketConnector
                    task: 2
                  config:
                    cloud.environment: prod
                    cloud.provider: aws
                    connector.class: GcsSink
                    data.format: BYTES
                    flush.size: '1000'
                    gcs.bucket.name: APILogsBucket
                    gcs.credentials.config: '****************'
                    kafka.api.key: '****************'
                    kafka.api.secret: '****************'
                    kafka.endpoint: 'SASL_SSL://pkc-xxxxx.us-west-2.aws.confluent.cloud:9092'
                    kafka.region: us-west-2
                    name: MyGcsLogsBucketConnector
                    tasks.max: '2'
                    time.interval: DAILY
                    topics: APILogsTopic
        '401':
          $ref: '#/components/responses/connect.v1.UnauthenticatedError'
        '404':
          $ref: '#/components/responses/connect.v1.AccountNotFoundError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/connect.v1.DefaultSystemError'
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request GET \
              --url 'https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/tasks' \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/tasks")
              .get()
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/tasks\"\n\n\treq, _ := http.NewRequest(\"GET\", url, nil)\n\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            headers = { 'Authorization': "Basic REPLACE_BASIC_AUTH" }

            conn.request("GET", "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/tasks", headers=headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "GET",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/tasks",
              "headers": {
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "GET");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/tasks");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/tasks");
            var request = new RestRequest(Method.GET);
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            IRestResponse response = client.Execute(request);
      parameters:
        - name: connector_name
          in: path
          schema:
            type: string
          required: true
          description: The unique name of the connector.
        - name: environment_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier of the environment this resource belongs to.
        - name: kafka_cluster_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier for the Kafka cluster.
  '/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connector-plugins':
    get:
      operationId: listConnectv1ConnectorPlugins
      description: |-
        [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Return a list of Managed Connector plugins installed in the Kafka Connect cluster.
      summary: List of Managed Connector plugins
      tags:
        - Managed Connector Plugins (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      responses:
        '200':
          description: Connector Plugin.
          content:
            application/json:
              schema:
                type: array
                items:
                  type: object
                  properties:
                    class:
                      type: string
                      description: The connector class name. E.g. BigQuerySink.
                    type:
                      type: string
                      description: 'Type of connector, sink or source.'
                      enum:
                        - sink
                        - source
                    version:
                      type: string
                      description: The version string for the connector available.
                  required:
                    - class
                    - type
              example:
                - class: BigQuerySink
                  type: sink
                - class: KinesisSource
                  type: source
                  version: 0.1.0
                - class: PostgresSource
                  type: source
                  version: 0.1.0
                - class: S3_SINK
                  type: sink
                - class: GcsSink
                  type: sink
                  version: 0.2.0
        '401':
          $ref: '#/components/responses/connect.v1.UnauthenticatedError'
        '404':
          $ref: '#/components/responses/connect.v1.ResourceNotFoundError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/connect.v1.DefaultSystemError'
      parameters:
        - name: environment_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier of the environment this resource belongs to.
        - name: kafka_cluster_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier for the Kafka cluster.
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request GET \
              --url 'https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connector-plugins' \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connector-plugins")
              .get()
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connector-plugins\"\n\n\treq, _ := http.NewRequest(\"GET\", url, nil)\n\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            headers = { 'Authorization': "Basic REPLACE_BASIC_AUTH" }

            conn.request("GET", "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connector-plugins", headers=headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "GET",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connector-plugins",
              "headers": {
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "GET");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connector-plugins");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connector-plugins");
            var request = new RestRequest(Method.GET);
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            IRestResponse response = client.Execute(request);
  '/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connector-plugins/{plugin_name}/config/validate':
    put:
      operationId: validateConnectv1ConnectorPlugin
      description: |-
        [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Validate the provided configuration values against the configuration definition. This API performs per config validation and returns suggested values and validation error messages.
      summary: Validate a Managed Connector Plugin
      tags:
        - Managed Connector Plugins (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      responses:
        '200':
          description: Connector Plugin.
          content:
            application/json:
              schema:
                type: object
                properties:
                  name:
                    type: string
                    description: The class name of the connector plugin.
                  groups:
                    type: array
                    description: The list of groups used in configuration definitions.
                    items:
                      type: string
                  error_count:
                    type: integer
                    description: The total number of errors encountered during configuration validation.
                  configs:
                    type: array
                    items:
                      type: object
                      properties:
                        definition:
                          type: object
                          description: 'The definition for a config in the connector plugin, which includes the name, type, importance, etc.'
                          properties:
                            name:
                              type: string
                              description: The name of the configuration
                            type:
                              type: string
                              enum:
                                - NONE
                                - BOOLEAN
                                - INT
                                - SHORT
                                - LONG
                                - DOUBLE
                                - STRING
                                - LIST
                                - ENUM
                                - PASSWORD
                              description: The config types
                            required:
                              type: boolean
                              description: Whether this configuration is required
                            default_value:
                              type: string
                              description: Default value for this configuration
                            importance:
                              type: string
                              enum:
                                - NONE
                                - HIGH
                                - MEDIUM
                                - LOW
                              description: The importance level for a configuration
                            documentation:
                              type: string
                              description: The documentation for the configuration
                            group:
                              type: string
                              description: The UI group to which the configuration belongs to
                            width:
                              type: string
                              enum:
                                - NONE
                                - SHORT
                                - MEDIUM
                                - LONG
                              description: The width of a configuration value
                            display_name:
                              type: string
                            dependents:
                              type: array
                              description: Other configurations on which this configuration is dependent
                              items:
                                type: string
                            order:
                              type: integer
                              description: The order of configuration in specified group
                            alias:
                              type: string
                        value:
                          type: object
                          description: 'The current value for a config, which includes the name, value, recommended values, etc.'
                          properties:
                            name:
                              type: string
                              description: The name of the configuration
                            value:
                              type: string
                              description: The value for the configuration
                            recommended_values:
                              type: array
                              description: The list of valid values for the configuration
                              items:
                                type: string
                            errors:
                              type: array
                              description: 'Errors, if any, in the configuration value'
                              items:
                                type: string
                            visible:
                              type: boolean
                              description: |-
                                The visibility of the configuration. Based on the values of other configuration
                                fields, this visibility boolean value points out if the current field should be
                                visible or not.
                        metadata:
                          type: object
                          description: |-
                            Map of metadata details about the connector configuration, such as type of
                            input, etc.
              example:
                name: io.confluent.connect.gcs.GcsSinkConnector
                groups:
                  - Organize my data by...
                  - Which topics do you want to get data from?
                  - Messages
                  - How should we connect to your data?
                  - Google Cloud Storage details
                  - Kafka Cluster credentials
                  - Number of tasks for this connector
                error_count: 1
                configs:
                  - definition:
                      name: name
                      type: STRING
                      required: true
                      default_value: ''
                      importance: HIGH
                      documentation: Sets a name for your connector.
                      group: How should we connect to your data?
                      width: NONE
                      display_name: Connector name
                      dependents: []
                      order: 2
                      alias: ''
                    value:
                      name: name
                      value: '{{.logicalClusterId}}'
                      recommended_values: []
                      errors: []
                      visible: true
                    metadata: {}
                  - definition:
                      name: connector.class
                      type: STRING
                      required: true
                      default_value: ''
                      importance: HIGH
                      documentation: ''
                      group: How should we connect to your data?
                      width: NONE
                      display_name: Connector class
                      dependents: []
                      order: 1
                      alias: ''
                    value:
                      name: connector.class
                      value: io.confluent.connect.gcs.GcsSinkConnector
                      recommended_values: []
                      errors: []
                      visible: true
                    metadata: {}
                  - definition:
                      name: kafka.api.key
                      type: PASSWORD
                      required: true
                      default_value: ''
                      importance: HIGH
                      documentation: ''
                      group: Kafka Cluster credentials
                      width: NONE
                      display_name: Kafka API Key
                      dependents: []
                      order: 1
                      alias: ''
                    value:
                      name: kafka.api.key
                      value: ''
                      recommended_values: []
                      errors: []
                      visible: true
                    metadata: {}
                  - definition:
                      name: kafka.api.secret
                      type: PASSWORD
                      required: true
                      default_value: ''
                      importance: HIGH
                      documentation: ''
                      group: Kafka Cluster credentials
                      width: NONE
                      display_name: Kafka API Secret
                      dependents:
                        - kafka.api.key
                      order: 2
                      alias: ''
                    value:
                      name: kafka.api.secret
                      value: ''
                      recommended_values: []
                      errors: []
                      visible: true
                    metadata: {}
                  - definition:
                      name: topics
                      type: LIST
                      required: true
                      default_value: ''
                      importance: HIGH
                      documentation: Identifies the topic name or a comma-separated list of topic names.
                      group: Which topics do you want to get data from?
                      width: NONE
                      display_name: Topic names
                      dependents: []
                      order: 1
                      alias: ''
                    value:
                      name: topics
                      value: test1
                      recommended_values: []
                      errors: []
                      visible: true
                    metadata: {}
                  - definition:
                      name: data.format
                      type: STRING
                      required: true
                      default_value: ''
                      importance: HIGH
                      documentation: 'Sets the input/output message format. Valid entries are AVRO, JSON, or BYTES'
                      group: Messages
                      width: NONE
                      display_name: Message format
                      dependents: []
                      order: 1
                      alias: ''
                    value:
                      name: data.format
                      value: BYTES
                      recommended_values:
                        - BYTES
                        - JSON
                        - AVRO
                      errors: []
                      visible: true
                    metadata: {}
                  - definition:
                      name: gcs.credentials.config
                      type: PASSWORD
                      required: true
                      default_value: ''
                      importance: HIGH
                      documentation: Contents of the downloaded GCP service account JSON file.
                      group: Google Cloud Storage details
                      width: NONE
                      display_name: Google Cloud Storage credentials.
                      dependents: []
                      order: 1
                      alias: ''
                    value:
                      name: gcs.credentials.config
                      value: ''
                      recommended_values: []
                      errors: []
                      visible: true
                    metadata: {}
                  - definition:
                      name: gcs.bucket.name
                      type: STRING
                      required: true
                      default_value: ''
                      importance: HIGH
                      documentation: A Google Cloud Storage bucket must be in the same region as your Confluent Cloud cluster.
                      group: Google Cloud Storage details
                      width: NONE
                      display_name: Bucket name.
                      dependents: []
                      order: 2
                      alias: ''
                    value:
                      name: gcs.bucket.name
                      value: gmagare
                      recommended_values: []
                      errors: []
                      visible: true
                    metadata: {}
                  - definition:
                      name: time.interval
                      type: STRING
                      required: true
                      default_value: ''
                      importance: HIGH
                      documentation: Sets how your messages grouped in storage. Valid entries are DAILY or HOURLY.
                      group: Organize my data by...
                      width: NONE
                      display_name: Time interval
                      dependents: []
                      order: 1
                      alias: ''
                    value:
                      name: time.interval
                      value: DAILY
                      recommended_values:
                        - DAILY
                        - HOURLY
                      errors: []
                      visible: true
                    metadata: {}
                  - definition:
                      name: tasks.max
                      type: INT
                      required: true
                      default_value: ''
                      importance: HIGH
                      documentation: ''
                      group: Number of tasks for this connector
                      width: NONE
                      display_name: Tasks
                      dependents: []
                      order: 1
                      alias: ''
                    value:
                      name: tasks.max
                      value: '1'
                      recommended_values: []
                      errors: []
                      visible: true
                    metadata: {}
                  - definition:
                      name: flush.size
                      type: INT
                      required: true
                      default_value: '1000'
                      importance: HIGH
                      documentation: 'This value defaults to 1000. For example, if you use the default setting of 1000 and your topic has six partitions, files start to be created in the storage bucket after more than 1000 records exist in each partition. Note that the default value of 1000 can be increased if needed.'
                      group: Organize my data by...
                      width: NONE
                      display_name: Flush size
                      dependents: []
                      order: 2
                      alias: ''
                    value:
                      name: flush.size
                      value: '1'
                      recommended_values: []
                      errors:
                        - '"flush.size" should be greater than or equal to 1000'
                      visible: true
                    metadata: {}
        '401':
          $ref: '#/components/responses/connect.v1.UnauthenticatedError'
        '404':
          $ref: '#/components/responses/connect.v1.ResourceNotFoundError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/connect.v1.DefaultSystemError'
      requestBody:
        content:
          application/json:
            schema:
              type: object
              description: Configuration parameters for the connector. All values should be strings.
              additionalProperties:
                type: string
                description: Other configuration parameters for the connector. All values should be strings. See the connector's docs for the list of options.
            example:
              cloud.environment: prod
              cloud.provider: aws
              connector.class: GcsSink
              data.format: BYTES
              flush.size: '500'
              gcs.bucket.name: APILogsBucket
              gcs.credentials.config: '****************'
              kafka.api.key: '****************'
              kafka.api.secret: '****************'
              kafka.endpoint: 'SASL_SSL://pkc-xxxxx.us-west-2.aws.confluent.cloud:9092'
              kafka.region: us-west-2
              name: MyGcsLogsBucketConnector
              tasks.max: '2'
              time.interval: DAILY
              topics: APILogsTopic
        description: Configuration parameters for the connector. All values should be strings.
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request PUT \
              --url 'https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connector-plugins/{plugin_name}/config/validate' \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH' \
              --header 'content-type: application/json' \
              --data '{"property1":"string","property2":"string"}'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            MediaType mediaType = MediaType.parse("application/json");
            RequestBody body = RequestBody.create(mediaType, "{\"property1\":\"string\",\"property2\":\"string\"}");
            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connector-plugins/{plugin_name}/config/validate")
              .put(body)
              .addHeader("content-type", "application/json")
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connector-plugins/{plugin_name}/config/validate\"\n\n\tpayload := strings.NewReader(\"{\\\"property1\\\":\\\"string\\\",\\\"property2\\\":\\\"string\\\"}\")\n\n\treq, _ := http.NewRequest(\"PUT\", url, payload)\n\n\treq.Header.Add(\"content-type\", \"application/json\")\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            payload = "{\"property1\":\"string\",\"property2\":\"string\"}"

            headers = {
                'content-type': "application/json",
                'Authorization': "Basic REPLACE_BASIC_AUTH"
                }

            conn.request("PUT", "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connector-plugins/{plugin_name}/config/validate", payload, headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "PUT",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connector-plugins/{plugin_name}/config/validate",
              "headers": {
                "content-type": "application/json",
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.write(JSON.stringify({property1: 'string', property2: 'string'}));
            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "PUT");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connector-plugins/{plugin_name}/config/validate");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "content-type: application/json");
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            curl_easy_setopt(hnd, CURLOPT_POSTFIELDS, "{\"property1\":\"string\",\"property2\":\"string\"}");

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connector-plugins/{plugin_name}/config/validate");
            var request = new RestRequest(Method.PUT);
            request.AddHeader("content-type", "application/json");
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            request.AddParameter("application/json", "{\"property1\":\"string\",\"property2\":\"string\"}", ParameterType.RequestBody);
            IRestResponse response = client.Execute(request);
      parameters:
        - name: plugin_name
          in: path
          schema:
            type: string
          required: true
          description: The unique name of the connector plugin.
        - name: environment_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier of the environment this resource belongs to.
        - name: kafka_cluster_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier for the Kafka cluster.
  '/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets':
    get:
      operationId: getConnectv1ConnectorOffsets
      description: |-
        [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Get the current offsets for the connector. The offsets provide information on the point in the source system, 
        from which the connector is pulling in data. The offsets of a connector are continuously observed periodically and are queryable via this API.
      summary: Get a Connector Offsets
      tags:
        - Offsets (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      responses:
        '200':
          description: Connector Offsets.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/connect.v1.ConnectorOffsets'
              examples:
                sink:
                  value:
                    id: lcc-as341
                    name: MysqlSinkConnector
                    offsets:
                      - partition:
                          kafka_partition: 0
                          kafka_topic: topic_A
                        offset:
                          kafka_offset: 20032323
                      - partition:
                          kafka_partition: 1
                          kafka_topic: topic_B
                        offset:
                          kafka_offset: 20032322
                    metadata:
                      observed_at: '2024-02-20T15:14:19Z'
                source:
                  value:
                    id: lcc-21sdda
                    name: MysqlSourceConnector
                    offsets:
                      - partition:
                          protocol: 1
                          table: sourcedb.sourcetable
                        offset:
                          timestamp_nanos: 0
                          incrementing: 3
                          timestamp: 1699142400000
                    metadata:
                      observed_at: '2024-02-20T15:14:19Z'
        '400':
          $ref: '#/components/responses/connect.v1.BadRequestError'
        '401':
          $ref: '#/components/responses/connect.v1.UnauthenticatedError'
        '403':
          $ref: '#/components/responses/connect.v1.ForbiddenError'
        '404':
          $ref: '#/components/responses/connect.v1.ResourceNotFoundError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/connect.v1.DefaultSystemError'
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request GET \
              --url 'https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets' \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets")
              .get()
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets\"\n\n\treq, _ := http.NewRequest(\"GET\", url, nil)\n\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            headers = { 'Authorization': "Basic REPLACE_BASIC_AUTH" }

            conn.request("GET", "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets", headers=headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "GET",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets",
              "headers": {
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "GET");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets");
            var request = new RestRequest(Method.GET);
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            IRestResponse response = client.Execute(request);
      parameters:
        - name: connector_name
          in: path
          schema:
            type: string
          required: true
          description: The unique name of the connector.
        - name: environment_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier of the environment this resource belongs to.
        - name: kafka_cluster_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier for the Kafka cluster.
  '/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request':
    post:
      operationId: alterConnectv1ConnectorOffsetsRequest
      description: |-
        [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Request to alter the offsets of a connector. This supports the ability to PATCH/DELETE the offsets of a connector.
        Note, you will see momentary downtime as this will internally stop the connector, while the offsets are being altered.
        You can only make one alter offsets request at a time for a connector.
      summary: Request to Alter the Connector Offsets
      tags:
        - Offsets (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      responses:
        '202':
          description: Accepted
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/connect.v1.AlterOffsetRequestInfo'
              examples:
                patch:
                  value:
                    id: lcc-sa32er
                    name: MySinkConnector
                    offsets:
                      - partition:
                          kafka_partition: 0
                          kafka_topic: topic_A
                        offset:
                          kafka_offset: 1000
                    requested_at: '2024-02-20T15:14:19Z'
                    type: PATCH
                delete:
                  value:
                    id: lcc-234ds
                    name: MySourceConnector
                    offsets: []
                    requested_at: '2024-02-20T15:14:19Z'
                    type: DELETE
        '400':
          $ref: '#/components/responses/connect.v1.BadRequestError'
        '401':
          $ref: '#/components/responses/connect.v1.UnauthenticatedError'
        '403':
          $ref: '#/components/responses/connect.v1.ForbiddenError'
        '404':
          $ref: '#/components/responses/connect.v1.ResourceNotFoundError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/connect.v1.DefaultSystemError'
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/connect.v1.AlterOffsetRequest'
            examples:
              patch sink:
                value:
                  type: PATCH
                  offsets:
                    - partition:
                        kafka_partition: 0
                        kafka_topic: topic_A
                      offset:
                        kafka_offset: 1000
              patch source:
                value:
                  type: PATCH
                  offsets:
                    - partition:
                        protocol: 1
                        table: sourcedb.sourcetable
                      offset:
                        timestamp_nanos: 0
                        incrementing: 3
                        timestamp: 1699000000000
              delete:
                value:
                  type: DELETE
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request POST \
              --url 'https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request' \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH' \
              --header 'content-type: application/json' \
              --data '{"type":"PATCH","offsets":[{"partition":{},"offset":{}}]}'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            MediaType mediaType = MediaType.parse("application/json");
            RequestBody body = RequestBody.create(mediaType, "{\"type\":\"PATCH\",\"offsets\":[{\"partition\":{},\"offset\":{}}]}");
            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request")
              .post(body)
              .addHeader("content-type", "application/json")
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request\"\n\n\tpayload := strings.NewReader(\"{\\\"type\\\":\\\"PATCH\\\",\\\"offsets\\\":[{\\\"partition\\\":{},\\\"offset\\\":{}}]}\")\n\n\treq, _ := http.NewRequest(\"POST\", url, payload)\n\n\treq.Header.Add(\"content-type\", \"application/json\")\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            payload = "{\"type\":\"PATCH\",\"offsets\":[{\"partition\":{},\"offset\":{}}]}"

            headers = {
                'content-type': "application/json",
                'Authorization': "Basic REPLACE_BASIC_AUTH"
                }

            conn.request("POST", "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request", payload, headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "POST",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request",
              "headers": {
                "content-type": "application/json",
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.write(JSON.stringify({type: 'PATCH', offsets: [{partition: {}, offset: {}}]}));
            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "POST");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "content-type: application/json");
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            curl_easy_setopt(hnd, CURLOPT_POSTFIELDS, "{\"type\":\"PATCH\",\"offsets\":[{\"partition\":{},\"offset\":{}}]}");

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request");
            var request = new RestRequest(Method.POST);
            request.AddHeader("content-type", "application/json");
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            request.AddParameter("application/json", "{\"type\":\"PATCH\",\"offsets\":[{\"partition\":{},\"offset\":{}}]}", ParameterType.RequestBody);
            IRestResponse response = client.Execute(request);
      parameters:
        - name: connector_name
          in: path
          schema:
            type: string
          required: true
          description: The unique name of the connector.
        - name: environment_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier of the environment this resource belongs to.
        - name: kafka_cluster_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier for the Kafka cluster.
  '/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request/status':
    get:
      operationId: getConnectv1ConnectorOffsetsRequestStatus
      description: |-
        [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Get the status of the previous alter offset request.
      summary: Get the Status of Alter Offset Request
      tags:
        - Offsets (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      responses:
        '200':
          description: Connector Offsets Request Status.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/connect.v1.AlterOffsetStatus'
              examples:
                sink - pending patch operation:
                  value:
                    request:
                      id: lcc-sa32er
                      name: MySinkConnector
                      offsets:
                        - partition:
                            kafka_partition: 0
                            kafka_topic: topic_A
                          offset:
                            kafka_offset: 1000
                      requested_at: '2024-02-20T15:14:19Z'
                      type: PATCH
                    status:
                      phase: PENDING
                    applied_at: null
                source - applied patch operation:
                  value:
                    request:
                      id: lcc-x1sdfs
                      name: MySourceConnector
                      offsets:
                        - partition:
                            protocol: 1
                            table: sourcedb.sourcetable
                          offset:
                            timestamp_nanos: 0
                            incrementing: 3
                            timestamp: 1699000000000
                      requested_at: '2024-02-20T15:14:19Z'
                      type: PATCH
                    status:
                      phase: APPLIED
                      message: 'The Connect framework-managed offsets for this connector have been altered successfully. However, if this connector manages offsets externally, they will need to be altered manually in the system that the connector uses.'
                    previous_offsets:
                      - partition:
                          protocol: 1
                          table: sourcedb.sourcetable
                        offset:
                          timestamp_nanos: 0
                          incrementing: 2
                          timestamp: 1698329479943
                    applied_at: '2024-02-20T15:14:20+0000'
                delete:
                  value:
                    request:
                      id: lcc-234ds
                      name: MySourceConnector
                      offsets: []
                      requested_at: '2024-02-20T15:14:19Z'
                      type: DELETE
                    status:
                      phase: APPLIED
                      message: 'The Connect framework-managed offsets for this connector have been reset successfully. However, if this connector manages offsets externally, they will need to be reset manually in the system that the connector uses.'
                    previous_offsets:
                      - partition:
                          protocol: 1
                          table: sourcedb.sourcetable
                        offset:
                          timestamp_nanos: 0
                          incrementing: 2
                          timestamp: 1698329479943
                    applied_at: '2024-02-20T15:14:20Z'
        '400':
          $ref: '#/components/responses/connect.v1.BadRequestError'
        '401':
          $ref: '#/components/responses/connect.v1.UnauthenticatedError'
        '403':
          $ref: '#/components/responses/connect.v1.ForbiddenError'
        '404':
          $ref: '#/components/responses/connect.v1.ResourceNotFoundError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/connect.v1.DefaultSystemError'
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request GET \
              --url 'https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request/status' \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request/status")
              .get()
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request/status\"\n\n\treq, _ := http.NewRequest(\"GET\", url, nil)\n\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            headers = { 'Authorization': "Basic REPLACE_BASIC_AUTH" }

            conn.request("GET", "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request/status", headers=headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "GET",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request/status",
              "headers": {
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "GET");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request/status");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request/status");
            var request = new RestRequest(Method.GET);
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            IRestResponse response = client.Execute(request);
      parameters:
        - name: connector_name
          in: path
          schema:
            type: string
          required: true
          description: The unique name of the connector.
        - name: environment_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier of the environment this resource belongs to.
        - name: kafka_cluster_id
          in: path
          schema:
            type: string
          required: true
          description: The unique identifier for the Kafka cluster.
  /connect/v1/custom-connector-plugins:
    get:
      operationId: listConnectV1CustomConnectorPlugins
      summary: List of Custom Connector Plugins
      description: |
        [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Retrieve a sorted, filtered, paginated list of all custom connector plugins.

        If no `cloud` filter is specified, returns custom connector plugins from all clouds.
      parameters:
        - name: cloud
          in: query
          required: false
          schema:
            $ref: '#/components/schemas/SearchFilter'
          example: AWS
          description: Filter the results by exact match for cloud.
        - name: page_size
          in: query
          required: false
          schema:
            type: integer
            default: 10
            maximum: 100
            x-max-page-items: 500
          description: A pagination size for collection requests.
        - name: page_token
          in: query
          required: false
          schema:
            type: string
            maxLength: 255
          description: An opaque pagination token for collection requests.
      tags:
        - Custom Connector Plugins (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      responses:
        '200':
          description: Custom Connector Plugin.
          content:
            application/json:
              schema:
                allOf:
                  - $ref: '#/components/schemas/connect.v1.CustomConnectorPluginList'
          headers:
            X-Request-Id:
              schema:
                type: string
              description: The unique identifier for the API request.
            X-RateLimit-Limit:
              schema:
                type: integer
              description: The maximum number of requests you're permitted to make per time period.
            X-RateLimit-Remaining:
              schema:
                type: integer
              description: The number of requests remaining in the current rate limit window.
            X-RateLimit-Reset:
              schema:
                type: integer
              description: |-
                The relative time in seconds until the current rate-limit window resets.  
                  
                **Important:** This differs from Github and Twitter's same-named header which uses UTC epoch seconds. We use relative time to avoid client/server time synchronization issues.
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/UnauthenticatedError'
        '403':
          $ref: '#/components/responses/UnauthorizedError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/DefaultSystemError'
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request GET \
              --url 'https://api.confluent.cloud/connect/v1/custom-connector-plugins?cloud=AWS' \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/custom-connector-plugins?cloud=AWS")
              .get()
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/custom-connector-plugins?cloud=AWS\"\n\n\treq, _ := http.NewRequest(\"GET\", url, nil)\n\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            headers = { 'Authorization': "Basic REPLACE_BASIC_AUTH" }

            conn.request("GET", "/connect/v1/custom-connector-plugins?cloud=AWS", headers=headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "GET",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/custom-connector-plugins?cloud=AWS",
              "headers": {
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "GET");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/custom-connector-plugins?cloud=AWS");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/custom-connector-plugins?cloud=AWS");
            var request = new RestRequest(Method.GET);
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            IRestResponse response = client.Execute(request);
    post:
      operationId: createConnectV1CustomConnectorPlugin
      summary: Create a Custom Connector Plugin
      description: |-
        [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Make a request to create a custom connector plugin.
      tags:
        - Custom Connector Plugins (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      requestBody:
        content:
          application/json:
            schema:
              allOf:
                - $ref: '#/components/schemas/connect.v1.CustomConnectorPlugin'
                - type: object
                  required:
                    - display_name
                    - connector_class
                    - connector_type
                    - upload_source
      responses:
        '201':
          description: A Custom Connector Plugin was created.
          headers:
            X-Request-Id:
              schema:
                type: string
              description: The unique identifier for the API request.
            X-RateLimit-Limit:
              schema:
                type: integer
              description: The maximum number of requests you're permitted to make per time period.
            X-RateLimit-Remaining:
              schema:
                type: integer
              description: The number of requests remaining in the current rate limit window.
            X-RateLimit-Reset:
              schema:
                type: integer
              description: |-
                The relative time in seconds until the current rate-limit window resets.  
                  
                **Important:** This differs from Github and Twitter's same-named header which uses UTC epoch seconds. We use relative time to avoid client/server time synchronization issues.
            Location:
              schema:
                type: string
                format: uri
                example: 'https://api.confluent.cloud/connect/v1/custom-connector-plugins/{id}'
              description: CustomConnectorPlugin resource uri
          content:
            application/json:
              schema:
                allOf:
                  - $ref: '#/components/schemas/connect.v1.CustomConnectorPlugin'
                  - type: object
                    required:
                      - display_name
                      - connector_class
                      - connector_type
                      - upload_source
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/UnauthenticatedError'
        '403':
          $ref: '#/components/responses/UnauthorizedError'
        '409':
          $ref: '#/components/responses/ConflictError'
        '422':
          $ref: '#/components/responses/ValidationError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/DefaultSystemError'
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request POST \
              --url https://api.confluent.cloud/connect/v1/custom-connector-plugins \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH' \
              --header 'content-type: application/json' \
              --data '{"display_name":"string","description":"string","documentation_link":"https://github.com/confluentinc/kafka-connect-datagen","connector_class":"io.confluent.kafka.connect.datagen.DatagenConnector","connector_type":"SOURCE","cloud":"AWS","sensitive_config_properties":["passwords","keys","tokens"],"upload_source":{"location":"PRESIGNED_URL_LOCATION","upload_id":"e53bb2e8-8de3-49fa-9fb1-4e3fd9a16b66"}}'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            MediaType mediaType = MediaType.parse("application/json");
            RequestBody body = RequestBody.create(mediaType, "{\"display_name\":\"string\",\"description\":\"string\",\"documentation_link\":\"https://github.com/confluentinc/kafka-connect-datagen\",\"connector_class\":\"io.confluent.kafka.connect.datagen.DatagenConnector\",\"connector_type\":\"SOURCE\",\"cloud\":\"AWS\",\"sensitive_config_properties\":[\"passwords\",\"keys\",\"tokens\"],\"upload_source\":{\"location\":\"PRESIGNED_URL_LOCATION\",\"upload_id\":\"e53bb2e8-8de3-49fa-9fb1-4e3fd9a16b66\"}}");
            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/custom-connector-plugins")
              .post(body)
              .addHeader("content-type", "application/json")
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/custom-connector-plugins\"\n\n\tpayload := strings.NewReader(\"{\\\"display_name\\\":\\\"string\\\",\\\"description\\\":\\\"string\\\",\\\"documentation_link\\\":\\\"https://github.com/confluentinc/kafka-connect-datagen\\\",\\\"connector_class\\\":\\\"io.confluent.kafka.connect.datagen.DatagenConnector\\\",\\\"connector_type\\\":\\\"SOURCE\\\",\\\"cloud\\\":\\\"AWS\\\",\\\"sensitive_config_properties\\\":[\\\"passwords\\\",\\\"keys\\\",\\\"tokens\\\"],\\\"upload_source\\\":{\\\"location\\\":\\\"PRESIGNED_URL_LOCATION\\\",\\\"upload_id\\\":\\\"e53bb2e8-8de3-49fa-9fb1-4e3fd9a16b66\\\"}}\")\n\n\treq, _ := http.NewRequest(\"POST\", url, payload)\n\n\treq.Header.Add(\"content-type\", \"application/json\")\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            payload = "{\"display_name\":\"string\",\"description\":\"string\",\"documentation_link\":\"https://github.com/confluentinc/kafka-connect-datagen\",\"connector_class\":\"io.confluent.kafka.connect.datagen.DatagenConnector\",\"connector_type\":\"SOURCE\",\"cloud\":\"AWS\",\"sensitive_config_properties\":[\"passwords\",\"keys\",\"tokens\"],\"upload_source\":{\"location\":\"PRESIGNED_URL_LOCATION\",\"upload_id\":\"e53bb2e8-8de3-49fa-9fb1-4e3fd9a16b66\"}}"

            headers = {
                'content-type': "application/json",
                'Authorization': "Basic REPLACE_BASIC_AUTH"
                }

            conn.request("POST", "/connect/v1/custom-connector-plugins", payload, headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "POST",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/custom-connector-plugins",
              "headers": {
                "content-type": "application/json",
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.write(JSON.stringify({
              display_name: 'string',
              description: 'string',
              documentation_link: 'https://github.com/confluentinc/kafka-connect-datagen',
              connector_class: 'io.confluent.kafka.connect.datagen.DatagenConnector',
              connector_type: 'SOURCE',
              cloud: 'AWS',
              sensitive_config_properties: ['passwords', 'keys', 'tokens'],
              upload_source: {
                location: 'PRESIGNED_URL_LOCATION',
                upload_id: 'e53bb2e8-8de3-49fa-9fb1-4e3fd9a16b66'
              }
            }));
            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "POST");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/custom-connector-plugins");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "content-type: application/json");
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            curl_easy_setopt(hnd, CURLOPT_POSTFIELDS, "{\"display_name\":\"string\",\"description\":\"string\",\"documentation_link\":\"https://github.com/confluentinc/kafka-connect-datagen\",\"connector_class\":\"io.confluent.kafka.connect.datagen.DatagenConnector\",\"connector_type\":\"SOURCE\",\"cloud\":\"AWS\",\"sensitive_config_properties\":[\"passwords\",\"keys\",\"tokens\"],\"upload_source\":{\"location\":\"PRESIGNED_URL_LOCATION\",\"upload_id\":\"e53bb2e8-8de3-49fa-9fb1-4e3fd9a16b66\"}}");

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/custom-connector-plugins");
            var request = new RestRequest(Method.POST);
            request.AddHeader("content-type", "application/json");
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            request.AddParameter("application/json", "{\"display_name\":\"string\",\"description\":\"string\",\"documentation_link\":\"https://github.com/confluentinc/kafka-connect-datagen\",\"connector_class\":\"io.confluent.kafka.connect.datagen.DatagenConnector\",\"connector_type\":\"SOURCE\",\"cloud\":\"AWS\",\"sensitive_config_properties\":[\"passwords\",\"keys\",\"tokens\"],\"upload_source\":{\"location\":\"PRESIGNED_URL_LOCATION\",\"upload_id\":\"e53bb2e8-8de3-49fa-9fb1-4e3fd9a16b66\"}}", ParameterType.RequestBody);
            IRestResponse response = client.Execute(request);
  '/connect/v1/custom-connector-plugins/{id}':
    get:
      operationId: getConnectV1CustomConnectorPlugin
      summary: Read a Custom Connector Plugin
      description: |-
        [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Make a request to read a custom connector plugin.
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
          description: The unique identifier for the custom connector plugin.
      tags:
        - Custom Connector Plugins (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      responses:
        '200':
          description: Custom Connector Plugin.
          content:
            application/json:
              schema:
                allOf:
                  - $ref: '#/components/schemas/connect.v1.CustomConnectorPlugin'
                  - type: object
                    required:
                      - api_version
                      - kind
                      - id
                      - display_name
                      - connector_class
                      - connector_type
                      - upload_source
          headers:
            X-Request-Id:
              schema:
                type: string
              description: The unique identifier for the API request.
            X-RateLimit-Limit:
              schema:
                type: integer
              description: The maximum number of requests you're permitted to make per time period.
            X-RateLimit-Remaining:
              schema:
                type: integer
              description: The number of requests remaining in the current rate limit window.
            X-RateLimit-Reset:
              schema:
                type: integer
              description: |-
                The relative time in seconds until the current rate-limit window resets.  
                  
                **Important:** This differs from Github and Twitter's same-named header which uses UTC epoch seconds. We use relative time to avoid client/server time synchronization issues.
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/UnauthenticatedError'
        '403':
          $ref: '#/components/responses/UnauthorizedError'
        '404':
          $ref: '#/components/responses/NotFoundError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/DefaultSystemError'
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request GET \
              --url 'https://api.confluent.cloud/connect/v1/custom-connector-plugins/{id}' \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/custom-connector-plugins/{id}")
              .get()
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/custom-connector-plugins/{id}\"\n\n\treq, _ := http.NewRequest(\"GET\", url, nil)\n\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            headers = { 'Authorization': "Basic REPLACE_BASIC_AUTH" }

            conn.request("GET", "/connect/v1/custom-connector-plugins/{id}", headers=headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "GET",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/custom-connector-plugins/{id}",
              "headers": {
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "GET");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/custom-connector-plugins/{id}");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/custom-connector-plugins/{id}");
            var request = new RestRequest(Method.GET);
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            IRestResponse response = client.Execute(request);
    patch:
      operationId: updateConnectV1CustomConnectorPlugin
      summary: Update a Custom Connector Plugin
      description: |+
        [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Make a request to update a custom connector plugin.

      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
          description: The unique identifier for the custom connector plugin.
      tags:
        - Custom Connector Plugins (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/connect.v1.CustomConnectorPluginUpdate'
      responses:
        '200':
          description: Custom Connector Plugin.
          content:
            application/json:
              schema:
                allOf:
                  - $ref: '#/components/schemas/connect.v1.CustomConnectorPlugin'
                  - type: object
                    required:
                      - api_version
                      - kind
                      - id
                      - display_name
                      - connector_class
                      - connector_type
                      - upload_source
          headers:
            X-Request-Id:
              schema:
                type: string
              description: The unique identifier for the API request.
            X-RateLimit-Limit:
              schema:
                type: integer
              description: The maximum number of requests you're permitted to make per time period.
            X-RateLimit-Remaining:
              schema:
                type: integer
              description: The number of requests remaining in the current rate limit window.
            X-RateLimit-Reset:
              schema:
                type: integer
              description: |-
                The relative time in seconds until the current rate-limit window resets.  
                  
                **Important:** This differs from Github and Twitter's same-named header which uses UTC epoch seconds. We use relative time to avoid client/server time synchronization issues.
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/UnauthenticatedError'
        '403':
          $ref: '#/components/responses/UnauthorizedError'
        '404':
          $ref: '#/components/responses/NotFoundError'
        '409':
          $ref: '#/components/responses/ConflictError'
        '422':
          $ref: '#/components/responses/ValidationError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/DefaultSystemError'
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request PATCH \
              --url 'https://api.confluent.cloud/connect/v1/custom-connector-plugins/{id}' \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH' \
              --header 'content-type: application/json' \
              --data '{"display_name":"string","description":"string","documentation_link":"https://github.com/confluentinc/kafka-connect-datagen","connector_class":"io.confluent.kafka.connect.datagen.DatagenConnector","connector_type":"SOURCE","cloud":"AWS","sensitive_config_properties":["passwords","keys","tokens"],"upload_source":{"location":"PRESIGNED_URL_LOCATION","upload_id":"e53bb2e8-8de3-49fa-9fb1-4e3fd9a16b66"}}'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            MediaType mediaType = MediaType.parse("application/json");
            RequestBody body = RequestBody.create(mediaType, "{\"display_name\":\"string\",\"description\":\"string\",\"documentation_link\":\"https://github.com/confluentinc/kafka-connect-datagen\",\"connector_class\":\"io.confluent.kafka.connect.datagen.DatagenConnector\",\"connector_type\":\"SOURCE\",\"cloud\":\"AWS\",\"sensitive_config_properties\":[\"passwords\",\"keys\",\"tokens\"],\"upload_source\":{\"location\":\"PRESIGNED_URL_LOCATION\",\"upload_id\":\"e53bb2e8-8de3-49fa-9fb1-4e3fd9a16b66\"}}");
            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/custom-connector-plugins/{id}")
              .patch(body)
              .addHeader("content-type", "application/json")
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/custom-connector-plugins/{id}\"\n\n\tpayload := strings.NewReader(\"{\\\"display_name\\\":\\\"string\\\",\\\"description\\\":\\\"string\\\",\\\"documentation_link\\\":\\\"https://github.com/confluentinc/kafka-connect-datagen\\\",\\\"connector_class\\\":\\\"io.confluent.kafka.connect.datagen.DatagenConnector\\\",\\\"connector_type\\\":\\\"SOURCE\\\",\\\"cloud\\\":\\\"AWS\\\",\\\"sensitive_config_properties\\\":[\\\"passwords\\\",\\\"keys\\\",\\\"tokens\\\"],\\\"upload_source\\\":{\\\"location\\\":\\\"PRESIGNED_URL_LOCATION\\\",\\\"upload_id\\\":\\\"e53bb2e8-8de3-49fa-9fb1-4e3fd9a16b66\\\"}}\")\n\n\treq, _ := http.NewRequest(\"PATCH\", url, payload)\n\n\treq.Header.Add(\"content-type\", \"application/json\")\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            payload = "{\"display_name\":\"string\",\"description\":\"string\",\"documentation_link\":\"https://github.com/confluentinc/kafka-connect-datagen\",\"connector_class\":\"io.confluent.kafka.connect.datagen.DatagenConnector\",\"connector_type\":\"SOURCE\",\"cloud\":\"AWS\",\"sensitive_config_properties\":[\"passwords\",\"keys\",\"tokens\"],\"upload_source\":{\"location\":\"PRESIGNED_URL_LOCATION\",\"upload_id\":\"e53bb2e8-8de3-49fa-9fb1-4e3fd9a16b66\"}}"

            headers = {
                'content-type': "application/json",
                'Authorization': "Basic REPLACE_BASIC_AUTH"
                }

            conn.request("PATCH", "/connect/v1/custom-connector-plugins/{id}", payload, headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "PATCH",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/custom-connector-plugins/{id}",
              "headers": {
                "content-type": "application/json",
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.write(JSON.stringify({
              display_name: 'string',
              description: 'string',
              documentation_link: 'https://github.com/confluentinc/kafka-connect-datagen',
              connector_class: 'io.confluent.kafka.connect.datagen.DatagenConnector',
              connector_type: 'SOURCE',
              cloud: 'AWS',
              sensitive_config_properties: ['passwords', 'keys', 'tokens'],
              upload_source: {
                location: 'PRESIGNED_URL_LOCATION',
                upload_id: 'e53bb2e8-8de3-49fa-9fb1-4e3fd9a16b66'
              }
            }));
            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "PATCH");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/custom-connector-plugins/{id}");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "content-type: application/json");
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            curl_easy_setopt(hnd, CURLOPT_POSTFIELDS, "{\"display_name\":\"string\",\"description\":\"string\",\"documentation_link\":\"https://github.com/confluentinc/kafka-connect-datagen\",\"connector_class\":\"io.confluent.kafka.connect.datagen.DatagenConnector\",\"connector_type\":\"SOURCE\",\"cloud\":\"AWS\",\"sensitive_config_properties\":[\"passwords\",\"keys\",\"tokens\"],\"upload_source\":{\"location\":\"PRESIGNED_URL_LOCATION\",\"upload_id\":\"e53bb2e8-8de3-49fa-9fb1-4e3fd9a16b66\"}}");

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/custom-connector-plugins/{id}");
            var request = new RestRequest(Method.PATCH);
            request.AddHeader("content-type", "application/json");
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            request.AddParameter("application/json", "{\"display_name\":\"string\",\"description\":\"string\",\"documentation_link\":\"https://github.com/confluentinc/kafka-connect-datagen\",\"connector_class\":\"io.confluent.kafka.connect.datagen.DatagenConnector\",\"connector_type\":\"SOURCE\",\"cloud\":\"AWS\",\"sensitive_config_properties\":[\"passwords\",\"keys\",\"tokens\"],\"upload_source\":{\"location\":\"PRESIGNED_URL_LOCATION\",\"upload_id\":\"e53bb2e8-8de3-49fa-9fb1-4e3fd9a16b66\"}}", ParameterType.RequestBody);
            IRestResponse response = client.Execute(request);
    delete:
      operationId: deleteConnectV1CustomConnectorPlugin
      summary: Delete a Custom Connector Plugin
      description: |-
        [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Make a request to delete a custom connector plugin.
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
          description: The unique identifier for the custom connector plugin.
      tags:
        - Custom Connector Plugins (connect/v1)
      security:
        - cloud-api-key: []
        - confluent-sts-access-token: []
      responses:
        '204':
          description: A Custom Connector Plugin is being deleted.
          headers:
            X-Request-Id:
              schema:
                type: string
              description: The unique identifier for the API request.
            X-RateLimit-Limit:
              schema:
                type: integer
              description: The maximum number of requests you're permitted to make per time period.
            X-RateLimit-Remaining:
              schema:
                type: integer
              description: The number of requests remaining in the current rate limit window.
            X-RateLimit-Reset:
              schema:
                type: integer
              description: |-
                The relative time in seconds until the current rate-limit window resets.  
                  
                **Important:** This differs from Github and Twitter's same-named header which uses UTC epoch seconds. We use relative time to avoid client/server time synchronization issues.
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/UnauthenticatedError'
        '403':
          $ref: '#/components/responses/UnauthorizedError'
        '404':
          $ref: '#/components/responses/NotFoundError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/DefaultSystemError'
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request DELETE \
              --url 'https://api.confluent.cloud/connect/v1/custom-connector-plugins/{id}' \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/custom-connector-plugins/{id}")
              .delete(null)
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/custom-connector-plugins/{id}\"\n\n\treq, _ := http.NewRequest(\"DELETE\", url, nil)\n\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            headers = { 'Authorization': "Basic REPLACE_BASIC_AUTH" }

            conn.request("DELETE", "/connect/v1/custom-connector-plugins/{id}", headers=headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "DELETE",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/custom-connector-plugins/{id}",
              "headers": {
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "DELETE");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/custom-connector-plugins/{id}");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/custom-connector-plugins/{id}");
            var request = new RestRequest(Method.DELETE);
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            IRestResponse response = client.Execute(request);
  /connect/v1/presigned-upload-url:
    post:
      summary: Request a presigned upload URL for a new Custom Connector Plugin.
      description: |-
        [![General Availability](https://img.shields.io/badge/Lifecycle%20Stage-General%20Availability-%2345c6e8)](#section/Versioning/API-Lifecycle-Policy)

        Request a presigned upload URL to upload a Custom Connector Plugin archive.
      requestBody:
        content:
          application/json:
            schema:
              allOf:
                - $ref: '#/components/schemas/connect.v1.PresignedUrlRequest'
                - type: object
                  required:
                    - content_format
      x-name: connect.v1.PresignedUrl
      operationId: presigned-upload-urlConnectV1PresignedUrl
      tags:
        - Presigned Urls (connect/v1)
      security:
        - cloud-api-key: []
      responses:
        '200':
          description: Presigned Url.
          content:
            application/json:
              schema:
                allOf:
                  - $ref: '#/components/schemas/connect.v1.PresignedUrl'
                  - type: object
                    required:
                      - api_version
                      - kind
          headers:
            X-Request-Id:
              schema:
                type: string
              description: The unique identifier for the API request.
            X-RateLimit-Limit:
              schema:
                type: integer
              description: The maximum number of requests you're permitted to make per time period.
            X-RateLimit-Remaining:
              schema:
                type: integer
              description: The number of requests remaining in the current rate limit window.
            X-RateLimit-Reset:
              schema:
                type: integer
              description: |-
                The relative time in seconds until the current rate-limit window resets.  
                  
                **Important:** This differs from Github and Twitter's same-named header which uses UTC epoch seconds. We use relative time to avoid client/server time synchronization issues.
        '400':
          $ref: '#/components/responses/BadRequestError'
        '401':
          $ref: '#/components/responses/UnauthenticatedError'
        '403':
          $ref: '#/components/responses/UnauthorizedError'
        '404':
          $ref: '#/components/responses/NotFoundError'
        '429':
          $ref: '#/components/responses/RateLimitError'
        '500':
          $ref: '#/components/responses/DefaultSystemError'
      x-codeSamples:
        - lang: Shell
          source: |-
            curl --request POST \
              --url https://api.confluent.cloud/connect/v1/presigned-upload-url \
              --header 'Authorization: Basic REPLACE_BASIC_AUTH' \
              --header 'content-type: application/json' \
              --data '{"content_format":"ZIP","cloud":"AWS"}'
        - lang: Java
          source: |-
            OkHttpClient client = new OkHttpClient();

            MediaType mediaType = MediaType.parse("application/json");
            RequestBody body = RequestBody.create(mediaType, "{\"content_format\":\"ZIP\",\"cloud\":\"AWS\"}");
            Request request = new Request.Builder()
              .url("https://api.confluent.cloud/connect/v1/presigned-upload-url")
              .post(body)
              .addHeader("content-type", "application/json")
              .addHeader("Authorization", "Basic REPLACE_BASIC_AUTH")
              .build();

            Response response = client.newCall(request).execute();
        - lang: Go
          source: "package main\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n\t\"net/http\"\n\t\"io/ioutil\"\n)\n\nfunc main() {\n\n\turl := \"https://api.confluent.cloud/connect/v1/presigned-upload-url\"\n\n\tpayload := strings.NewReader(\"{\\\"content_format\\\":\\\"ZIP\\\",\\\"cloud\\\":\\\"AWS\\\"}\")\n\n\treq, _ := http.NewRequest(\"POST\", url, payload)\n\n\treq.Header.Add(\"content-type\", \"application/json\")\n\treq.Header.Add(\"Authorization\", \"Basic REPLACE_BASIC_AUTH\")\n\n\tres, _ := http.DefaultClient.Do(req)\n\n\tdefer res.Body.Close()\n\tbody, _ := ioutil.ReadAll(res.Body)\n\n\tfmt.Println(res)\n\tfmt.Println(string(body))\n\n}"
        - lang: Python
          source: |-
            import http.client

            conn = http.client.HTTPSConnection("api.confluent.cloud")

            payload = "{\"content_format\":\"ZIP\",\"cloud\":\"AWS\"}"

            headers = {
                'content-type': "application/json",
                'Authorization': "Basic REPLACE_BASIC_AUTH"
                }

            conn.request("POST", "/connect/v1/presigned-upload-url", payload, headers)

            res = conn.getresponse()
            data = res.read()

            print(data.decode("utf-8"))
        - lang: Node
          source: |-
            const http = require("https");

            const options = {
              "method": "POST",
              "hostname": "api.confluent.cloud",
              "port": null,
              "path": "/connect/v1/presigned-upload-url",
              "headers": {
                "content-type": "application/json",
                "Authorization": "Basic REPLACE_BASIC_AUTH"
              }
            };

            const req = http.request(options, function (res) {
              const chunks = [];

              res.on("data", function (chunk) {
                chunks.push(chunk);
              });

              res.on("end", function () {
                const body = Buffer.concat(chunks);
                console.log(body.toString());
              });
            });

            req.write(JSON.stringify({content_format: 'ZIP', cloud: 'AWS'}));
            req.end();
        - lang: C
          source: |-
            CURL *hnd = curl_easy_init();

            curl_easy_setopt(hnd, CURLOPT_CUSTOMREQUEST, "POST");
            curl_easy_setopt(hnd, CURLOPT_URL, "https://api.confluent.cloud/connect/v1/presigned-upload-url");

            struct curl_slist *headers = NULL;
            headers = curl_slist_append(headers, "content-type: application/json");
            headers = curl_slist_append(headers, "Authorization: Basic REPLACE_BASIC_AUTH");
            curl_easy_setopt(hnd, CURLOPT_HTTPHEADER, headers);

            curl_easy_setopt(hnd, CURLOPT_POSTFIELDS, "{\"content_format\":\"ZIP\",\"cloud\":\"AWS\"}");

            CURLcode ret = curl_easy_perform(hnd);
        - lang: C#
          source: |-
            var client = new RestClient("https://api.confluent.cloud/connect/v1/presigned-upload-url");
            var request = new RestRequest(Method.POST);
            request.AddHeader("content-type", "application/json");
            request.AddHeader("Authorization", "Basic REPLACE_BASIC_AUTH");
            request.AddParameter("application/json", "{\"content_format\":\"ZIP\",\"cloud\":\"AWS\"}", ParameterType.RequestBody);
            IRestResponse response = client.Execute(request);
