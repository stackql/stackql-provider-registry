openapi: 3.1.0
info:
  contact:
    name: StackQL Studios
    url: https://github.com/stackql/google-discovery-to-openapi
    email: info@stackql.io
  title: Cloud Speech-to-Text API
  description: Converts audio to text by applying powerful neural network models.
  version: v2
  x-discovery-doc-revision: '20251106'
  x-generated-date: '2025-12-10'
externalDocs:
  url: https://cloud.google.com/speech-to-text/docs/quickstart-protocol
servers:
  - url: https://speech.googleapis.com
components:
  securitySchemes:
    Oauth2:
      type: oauth2
      description: Oauth 2.0 implicit authentication
      flows:
        implicit:
          authorizationUrl: https://accounts.google.com/o/oauth2/auth
          scopes: &ref_0
            https://www.googleapis.com/auth/cloud-platform: >-
              See, edit, configure, and delete your Google Cloud data and see
              the email address for your Google Account.
    Oauth2c:
      type: oauth2
      description: Oauth 2.0 authorization code authentication
      flows:
        authorizationCode:
          authorizationUrl: https://accounts.google.com/o/oauth2/auth
          tokenUrl: https://accounts.google.com/o/oauth2/token
          scopes: *ref_0
  schemas:
    ListOperationsResponse:
      id: ListOperationsResponse
      description: The response message for Operations.ListOperations.
      type: object
      properties:
        operations:
          description: >-
            A list of operations that matches the specified filter in the
            request.
          type: array
          items:
            $ref: '#/components/schemas/Operation'
        nextPageToken:
          description: The standard List next-page token.
          type: string
        unreachable:
          description: >-
            Unordered list. Unreachable resources. Populated when the request
            sets `ListOperationsRequest.return_partial_success` and reads across
            collections e.g. when attempting to list all resources across all
            supported locations.
          type: array
          items:
            type: string
    Operation:
      id: Operation
      description: >-
        This resource represents a long-running operation that is the result of
        a network API call.
      type: object
      properties:
        name:
          description: >-
            The server-assigned name, which is only unique within the same
            service that originally returns it. If you use the default HTTP
            mapping, the `name` should be a resource name ending with
            `operations/{unique_id}`.
          type: string
        metadata:
          description: >-
            Service-specific metadata associated with the operation. It
            typically contains progress information and common metadata such as
            create time. Some services might not provide such metadata. Any
            method that returns a long-running operation should document the
            metadata type, if any.
          type: object
          additionalProperties:
            type: any
            description: Properties of the object. Contains field @type with type URL.
        done:
          description: >-
            If the value is `false`, it means the operation is still in
            progress. If `true`, the operation is completed, and either `error`
            or `response` is available.
          type: boolean
        error:
          description: >-
            The error result of the operation in case of failure or
            cancellation.
          $ref: '#/components/schemas/Status'
        response:
          description: >-
            The normal, successful response of the operation. If the original
            method returns no data on success, such as `Delete`, the response is
            `google.protobuf.Empty`. If the original method is standard
            `Get`/`Create`/`Update`, the response should be the resource. For
            other methods, the response should have the type `XxxResponse`,
            where `Xxx` is the original method name. For example, if the
            original method name is `TakeSnapshot()`, the inferred response type
            is `TakeSnapshotResponse`.
          type: object
          additionalProperties:
            type: any
            description: Properties of the object. Contains field @type with type URL.
    Status:
      id: Status
      description: >-
        The `Status` type defines a logical error model that is suitable for
        different programming environments, including REST APIs and RPC APIs. It
        is used by [gRPC](https://github.com/grpc). Each `Status` message
        contains three pieces of data: error code, error message, and error
        details. You can find out more about this error model and how to work
        with it in the [API Design
        Guide](https://cloud.google.com/apis/design/errors).
      type: object
      properties:
        code:
          description: The status code, which should be an enum value of google.rpc.Code.
          type: integer
          format: int32
        message:
          description: >-
            A developer-facing error message, which should be in English. Any
            user-facing error message should be localized and sent in the
            google.rpc.Status.details field, or localized by the client.
          type: string
        details:
          description: >-
            A list of messages that carry the error details. There is a common
            set of message types for APIs to use.
          type: array
          items:
            type: object
            additionalProperties:
              type: any
              description: Properties of the object. Contains field @type with type URL.
    ListLocationsResponse:
      id: ListLocationsResponse
      description: The response message for Locations.ListLocations.
      type: object
      properties:
        locations:
          description: >-
            A list of locations that matches the specified filter in the
            request.
          type: array
          items:
            $ref: '#/components/schemas/Location'
        nextPageToken:
          description: The standard List next-page token.
          type: string
    Location:
      id: Location
      description: A resource that represents a Google Cloud location.
      type: object
      properties:
        name:
          description: >-
            Resource name for the location, which may vary between
            implementations. For example:
            `"projects/example-project/locations/us-east1"`
          type: string
        locationId:
          description: 'The canonical id for this location. For example: `"us-east1"`.'
          type: string
        displayName:
          description: >-
            The friendly name for this location, typically a nearby city name.
            For example, "Tokyo".
          type: string
        labels:
          description: >-
            Cross-service attributes for the location. For example
            {"cloud.googleapis.com/region": "us-east1"}
          type: object
          additionalProperties:
            type: string
        metadata:
          description: >-
            Service-specific metadata. For example the available capacity at the
            given location.
          type: object
          additionalProperties:
            type: any
            description: Properties of the object. Contains field @type with type URL.
    Recognizer:
      id: Recognizer
      description: A Recognizer message. Stores recognition configuration and metadata.
      type: object
      properties:
        name:
          description: >-
            Output only. Identifier. The resource name of the Recognizer.
            Format:
            `projects/{project}/locations/{location}/recognizers/{recognizer}`.
          readOnly: true
          type: string
        uid:
          description: Output only. System-assigned unique identifier for the Recognizer.
          readOnly: true
          type: string
        displayName:
          description: >-
            User-settable, human-readable name for the Recognizer. Must be 63
            characters or less.
          type: string
        model:
          description: >-
            Optional. This field is now deprecated. Prefer the `model` field in
            the `RecognitionConfig` message. Which model to use for recognition
            requests. Select the model best suited to your domain to get best
            results. Guidance for choosing which model to use can be found in
            the [Transcription Models
            Documentation](https://cloud.google.com/speech-to-text/v2/docs/transcription-model)
            and the models supported in each region can be found in the [Table
            Of Supported
            Models](https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages).
          deprecated: true
          type: string
        languageCodes:
          description: >-
            Optional. This field is now deprecated. Prefer the `language_codes`
            field in the `RecognitionConfig` message. The language of the
            supplied audio as a
            [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
            Supported languages for each model are listed in the [Table of
            Supported
            Models](https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages).
            If additional languages are provided, recognition result will
            contain recognition in the most likely language detected. The
            recognition result will include the language tag of the language
            detected in the audio. When you create or update a Recognizer, these
            values are stored in normalized BCP-47 form. For example, "en-us" is
            stored as "en-US".
          deprecated: true
          type: array
          items:
            type: string
        defaultRecognitionConfig:
          description: >-
            Default configuration to use for requests with this Recognizer. This
            can be overwritten by inline configuration in the
            RecognizeRequest.config field.
          $ref: '#/components/schemas/RecognitionConfig'
        annotations:
          description: >-
            Allows users to store small amounts of arbitrary data. Both the key
            and the value must be 63 characters or less each. At most 100
            annotations.
          type: object
          additionalProperties:
            type: string
        state:
          description: Output only. The Recognizer lifecycle state.
          readOnly: true
          type: string
          enumDescriptions:
            - The default value. This value is used if the state is omitted.
            - The Recognizer is active and ready for use.
            - This Recognizer has been deleted.
          enum:
            - STATE_UNSPECIFIED
            - ACTIVE
            - DELETED
        createTime:
          description: Output only. Creation time.
          readOnly: true
          type: string
          format: google-datetime
        updateTime:
          description: Output only. The most recent time this Recognizer was modified.
          readOnly: true
          type: string
          format: google-datetime
        deleteTime:
          description: >-
            Output only. The time at which this Recognizer was requested for
            deletion.
          readOnly: true
          type: string
          format: google-datetime
        expireTime:
          description: Output only. The time at which this Recognizer will be purged.
          readOnly: true
          type: string
          format: google-datetime
        etag:
          description: >-
            Output only. This checksum is computed by the server based on the
            value of other fields. This may be sent on update, undelete, and
            delete requests to ensure the client has an up-to-date value before
            proceeding.
          readOnly: true
          type: string
        reconciling:
          description: >-
            Output only. Whether or not this Recognizer is in the process of
            being updated.
          readOnly: true
          type: boolean
        kmsKeyName:
          description: >-
            Output only. The [KMS key
            name](https://cloud.google.com/kms/docs/resource-hierarchy#keys)
            with which the Recognizer is encrypted. The expected format is
            `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
          readOnly: true
          type: string
        kmsKeyVersionName:
          description: >-
            Output only. The [KMS key version
            name](https://cloud.google.com/kms/docs/resource-hierarchy#key_versions)
            with which the Recognizer is encrypted. The expected format is
            `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}`.
          readOnly: true
          type: string
    RecognitionConfig:
      id: RecognitionConfig
      description: >-
        Provides information to the Recognizer that specifies how to process the
        recognition request.
      type: object
      properties:
        autoDecodingConfig:
          description: >-
            Automatically detect decoding parameters. Preferred for supported
            formats.
          $ref: '#/components/schemas/AutoDetectDecodingConfig'
        explicitDecodingConfig:
          description: >-
            Explicitly specified decoding parameters. Required if using
            headerless PCM audio (linear16, mulaw, alaw).
          $ref: '#/components/schemas/ExplicitDecodingConfig'
        model:
          description: >-
            Optional. Which model to use for recognition requests. Select the
            model best suited to your domain to get best results. Guidance for
            choosing which model to use can be found in the [Transcription
            Models
            Documentation](https://cloud.google.com/speech-to-text/v2/docs/transcription-model)
            and the models supported in each region can be found in the [Table
            Of Supported
            Models](https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages).
          type: string
        languageCodes:
          description: >-
            Optional. The language of the supplied audio as a
            [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
            Language tags are normalized to BCP-47 before they are used eg
            "en-us" becomes "en-US". Supported languages for each model are
            listed in the [Table of Supported
            Models](https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages).
            If additional languages are provided, recognition result will
            contain recognition in the most likely language detected. The
            recognition result will include the language tag of the language
            detected in the audio.
          type: array
          items:
            type: string
        features:
          description: Speech recognition features to enable.
          $ref: '#/components/schemas/RecognitionFeatures'
        adaptation:
          description: >-
            Speech adaptation context that weights recognizer predictions for
            specific words and phrases.
          $ref: '#/components/schemas/SpeechAdaptation'
        transcriptNormalization:
          description: >-
            Optional. Use transcription normalization to automatically replace
            parts of the transcript with phrases of your choosing. For
            StreamingRecognize, this normalization only applies to stable
            partial transcripts (stability > 0.8) and final transcripts.
          $ref: '#/components/schemas/TranscriptNormalization'
        translationConfig:
          description: >-
            Optional. Optional configuration used to automatically run
            translation on the given audio to the desired language for supported
            models.
          $ref: '#/components/schemas/TranslationConfig'
        denoiserConfig:
          description: >-
            Optional. Optional denoiser config. May not be supported for all
            models and may have no effect.
          $ref: '#/components/schemas/DenoiserConfig'
    AutoDetectDecodingConfig:
      id: AutoDetectDecodingConfig
      description: >-
        Automatically detected decoding parameters. Supported for the following
        encodings: * WAV_LINEAR16: 16-bit signed little-endian PCM samples in a
        WAV container. * WAV_MULAW: 8-bit companded mulaw samples in a WAV
        container. * WAV_ALAW: 8-bit companded alaw samples in a WAV container.
        * RFC4867_5_AMR: AMR frames with an rfc4867.5 header. * RFC4867_5_AMRWB:
        AMR-WB frames with an rfc4867.5 header. * FLAC: FLAC frames in the
        "native FLAC" container format. * MP3: MPEG audio frames with optional
        (ignored) ID3 metadata. * OGG_OPUS: Opus audio frames in an Ogg
        container. * WEBM_OPUS: Opus audio frames in a WebM container. *
        MP4_AAC: AAC audio frames in an MP4 container. * M4A_AAC: AAC audio
        frames in an M4A container. * MOV_AAC: AAC audio frames in an MOV
        container.
      type: object
      properties: {}
    ExplicitDecodingConfig:
      id: ExplicitDecodingConfig
      description: Explicitly specified decoding parameters.
      type: object
      properties:
        encoding:
          description: Required. Encoding of the audio data sent for recognition.
          type: string
          enumDescriptions:
            - Default value. This value is unused.
            - Headerless 16-bit signed little-endian PCM samples.
            - Headerless 8-bit companded mulaw samples.
            - Headerless 8-bit companded alaw samples.
            - AMR frames with an rfc4867.5 header.
            - AMR-WB frames with an rfc4867.5 header.
            - FLAC frames in the "native FLAC" container format.
            - MPEG audio frames with optional (ignored) ID3 metadata.
            - Opus audio frames in an Ogg container.
            - Opus audio frames in a WebM container.
            - AAC audio frames in an MP4 container.
            - AAC audio frames in an M4A container.
            - AAC audio frames in an MOV container.
          enum:
            - AUDIO_ENCODING_UNSPECIFIED
            - LINEAR16
            - MULAW
            - ALAW
            - AMR
            - AMR_WB
            - FLAC
            - MP3
            - OGG_OPUS
            - WEBM_OPUS
            - MP4_AAC
            - M4A_AAC
            - MOV_AAC
        sampleRateHertz:
          description: >-
            Optional. Sample rate in Hertz of the audio data sent for
            recognition. Valid values are: 8000-48000, and 16000 is optimal. For
            best results, set the sampling rate of the audio source to 16000 Hz.
            If that's not possible, use the native sample rate of the audio
            source (instead of resampling). Note that this field is marked as
            OPTIONAL for backward compatibility reasons. It is (and has always
            been) effectively REQUIRED.
          type: integer
          format: int32
        audioChannelCount:
          description: >-
            Optional. Number of channels present in the audio data sent for
            recognition. Note that this field is marked as OPTIONAL for backward
            compatibility reasons. It is (and has always been) effectively
            REQUIRED. The maximum allowed value is 8.
          type: integer
          format: int32
    RecognitionFeatures:
      id: RecognitionFeatures
      description: Available recognition features.
      type: object
      properties:
        profanityFilter:
          description: >-
            If set to `true`, the server will attempt to filter out profanities,
            replacing all but the initial character in each filtered word with
            asterisks, for instance, "f***". If set to `false` or omitted,
            profanities won't be filtered out.
          type: boolean
        enableWordTimeOffsets:
          description: >-
            If `true`, the top result includes a list of words and the start and
            end time offsets (timestamps) for those words. If `false`, no
            word-level time offset information is returned. The default is
            `false`.
          type: boolean
        enableWordConfidence:
          description: >-
            If `true`, the top result includes a list of words and the
            confidence for those words. If `false`, no word-level confidence
            information is returned. The default is `false`.
          type: boolean
        enableAutomaticPunctuation:
          description: >-
            If `true`, adds punctuation to recognition result hypotheses. This
            feature is only available in select languages. The default `false`
            value does not add punctuation to result hypotheses.
          type: boolean
        enableSpokenPunctuation:
          description: >-
            The spoken punctuation behavior for the call. If `true`, replaces
            spoken punctuation with the corresponding symbols in the request.
            For example, "how are you question mark" becomes "how are you?". See
            https://cloud.google.com/speech-to-text/docs/spoken-punctuation for
            support. If `false`, spoken punctuation is not replaced.
          type: boolean
        enableSpokenEmojis:
          description: >-
            The spoken emoji behavior for the call. If `true`, adds spoken emoji
            formatting for the request. This will replace spoken emojis with the
            corresponding Unicode symbols in the final transcript. If `false`,
            spoken emojis are not replaced.
          type: boolean
        multiChannelMode:
          description: Mode for recognizing multi-channel audio.
          type: string
          enumDescriptions:
            - >-
              Default value for the multi-channel mode. If the audio contains
              multiple channels, only the first channel will be transcribed;
              other channels will be ignored.
            - >-
              If selected, each channel in the provided audio is transcribed
              independently. This cannot be selected if the selected model is
              `latest_short`.
          enum:
            - MULTI_CHANNEL_MODE_UNSPECIFIED
            - SEPARATE_RECOGNITION_PER_CHANNEL
        diarizationConfig:
          description: >-
            Configuration to enable speaker diarization. To enable diarization,
            set this field to an empty SpeakerDiarizationConfig message.
          $ref: '#/components/schemas/SpeakerDiarizationConfig'
        maxAlternatives:
          description: >-
            Maximum number of recognition hypotheses to be returned. The server
            may return fewer than `max_alternatives`. Valid values are `0`-`30`.
            A value of `0` or `1` will return a maximum of one. If omitted, will
            return a maximum of one.
          type: integer
          format: int32
    SpeakerDiarizationConfig:
      id: SpeakerDiarizationConfig
      description: Configuration to enable speaker diarization.
      type: object
      properties:
        minSpeakerCount:
          description: >-
            Optional. The system automatically determines the number of
            speakers. This value is not currently used.
          type: integer
          format: int32
        maxSpeakerCount:
          description: >-
            Optional. The system automatically determines the number of
            speakers. This value is not currently used.
          type: integer
          format: int32
    SpeechAdaptation:
      id: SpeechAdaptation
      description: >-
        Provides "hints" to the speech recognizer to favor specific words and
        phrases in the results. PhraseSets can be specified as an inline
        resource, or a reference to an existing PhraseSet resource.
      type: object
      properties:
        phraseSets:
          description: A list of inline or referenced PhraseSets.
          type: array
          items:
            $ref: '#/components/schemas/AdaptationPhraseSet'
        customClasses:
          description: >-
            A list of inline CustomClasses. Existing CustomClass resources can
            be referenced directly in a PhraseSet.
          type: array
          items:
            $ref: '#/components/schemas/CustomClass'
    AdaptationPhraseSet:
      id: AdaptationPhraseSet
      description: >-
        A biasing PhraseSet, which can be either a string referencing the name
        of an existing PhraseSets resource, or an inline definition of a
        PhraseSet.
      type: object
      properties:
        phraseSet:
          description: >-
            The name of an existing PhraseSet resource. The user must have read
            access to the resource and it must not be deleted.
          type: string
        inlinePhraseSet:
          description: An inline defined PhraseSet.
          $ref: '#/components/schemas/PhraseSet'
    PhraseSet:
      id: PhraseSet
      description: >-
        PhraseSet for biasing in speech recognition. A PhraseSet is used to
        provide "hints" to the speech recognizer to favor specific words and
        phrases in the results.
      type: object
      properties:
        name:
          description: >-
            Output only. Identifier. The resource name of the PhraseSet. Format:
            `projects/{project}/locations/{location}/phraseSets/{phrase_set}`.
          readOnly: true
          type: string
        uid:
          description: Output only. System-assigned unique identifier for the PhraseSet.
          readOnly: true
          type: string
        phrases:
          description: A list of word and phrases.
          type: array
          items:
            $ref: '#/components/schemas/Phrase'
        boost:
          description: >-
            Hint Boost. Positive value will increase the probability that a
            specific phrase will be recognized over other similar sounding
            phrases. The higher the boost, the higher the chance of false
            positive recognition as well. Valid `boost` values are between 0
            (exclusive) and 20. We recommend using a binary search approach to
            finding the optimal value for your use case as well as adding
            phrases both with and without boost to your requests.
          type: number
          format: float
        displayName:
          description: >-
            User-settable, human-readable name for the PhraseSet. Must be 63
            characters or less.
          type: string
        state:
          description: Output only. The PhraseSet lifecycle state.
          readOnly: true
          type: string
          enumDescriptions:
            - >-
              Unspecified state. This is only used/useful for distinguishing
              unset values.
            - The normal and active state.
            - This PhraseSet has been deleted.
          enum:
            - STATE_UNSPECIFIED
            - ACTIVE
            - DELETED
        createTime:
          description: Output only. Creation time.
          readOnly: true
          type: string
          format: google-datetime
        updateTime:
          description: Output only. The most recent time this resource was modified.
          readOnly: true
          type: string
          format: google-datetime
        deleteTime:
          description: >-
            Output only. The time at which this resource was requested for
            deletion.
          readOnly: true
          type: string
          format: google-datetime
        expireTime:
          description: Output only. The time at which this resource will be purged.
          readOnly: true
          type: string
          format: google-datetime
        annotations:
          description: >-
            Allows users to store small amounts of arbitrary data. Both the key
            and the value must be 63 characters or less each. At most 100
            annotations.
          type: object
          additionalProperties:
            type: string
        etag:
          description: >-
            Output only. This checksum is computed by the server based on the
            value of other fields. This may be sent on update, undelete, and
            delete requests to ensure the client has an up-to-date value before
            proceeding.
          readOnly: true
          type: string
        reconciling:
          description: >-
            Output only. Whether or not this PhraseSet is in the process of
            being updated.
          readOnly: true
          type: boolean
        kmsKeyName:
          description: >-
            Output only. The [KMS key
            name](https://cloud.google.com/kms/docs/resource-hierarchy#keys)
            with which the PhraseSet is encrypted. The expected format is
            `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
          readOnly: true
          type: string
        kmsKeyVersionName:
          description: >-
            Output only. The [KMS key version
            name](https://cloud.google.com/kms/docs/resource-hierarchy#key_versions)
            with which the PhraseSet is encrypted. The expected format is
            `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}`.
          readOnly: true
          type: string
    Phrase:
      id: Phrase
      description: >-
        A Phrase contains words and phrase "hints" so that the speech
        recognition is more likely to recognize them. This can be used to
        improve the accuracy for specific words and phrases, for example, if
        specific commands are typically spoken by the user. This can also be
        used to add additional words to the vocabulary of the recognizer. List
        items can also include CustomClass references containing groups of words
        that represent common concepts that occur in natural language.
      type: object
      properties:
        value:
          description: The phrase itself.
          type: string
        boost:
          description: >-
            Hint Boost. Overrides the boost set at the phrase set level.
            Positive value will increase the probability that a specific phrase
            will be recognized over other similar sounding phrases. The higher
            the boost, the higher the chance of false positive recognition as
            well. Negative boost values would correspond to anti-biasing.
            Anti-biasing is not enabled, so negative boost values will return an
            error. Boost values must be between 0 and 20. Any values outside
            that range will return an error. We recommend using a binary search
            approach to finding the optimal value for your use case as well as
            adding phrases both with and without boost to your requests.
          type: number
          format: float
    CustomClass:
      id: CustomClass
      description: >-
        CustomClass for biasing in speech recognition. Used to define a set of
        words or phrases that represents a common concept or theme likely to
        appear in your audio, for example a list of passenger ship names.
      type: object
      properties:
        name:
          description: >-
            Output only. Identifier. The resource name of the CustomClass.
            Format:
            `projects/{project}/locations/{location}/customClasses/{custom_class}`.
          readOnly: true
          type: string
        uid:
          description: Output only. System-assigned unique identifier for the CustomClass.
          readOnly: true
          type: string
        displayName:
          description: >-
            Optional. User-settable, human-readable name for the CustomClass.
            Must be 63 characters or less.
          type: string
        items:
          description: A collection of class items.
          type: array
          items:
            $ref: '#/components/schemas/ClassItem'
        state:
          description: Output only. The CustomClass lifecycle state.
          readOnly: true
          type: string
          enumDescriptions:
            - >-
              Unspecified state. This is only used/useful for distinguishing
              unset values.
            - The normal and active state.
            - This CustomClass has been deleted.
          enum:
            - STATE_UNSPECIFIED
            - ACTIVE
            - DELETED
        createTime:
          description: Output only. Creation time.
          readOnly: true
          type: string
          format: google-datetime
        updateTime:
          description: Output only. The most recent time this resource was modified.
          readOnly: true
          type: string
          format: google-datetime
        deleteTime:
          description: >-
            Output only. The time at which this resource was requested for
            deletion.
          readOnly: true
          type: string
          format: google-datetime
        expireTime:
          description: Output only. The time at which this resource will be purged.
          readOnly: true
          type: string
          format: google-datetime
        annotations:
          description: >-
            Optional. Allows users to store small amounts of arbitrary data.
            Both the key and the value must be 63 characters or less each. At
            most 100 annotations.
          type: object
          additionalProperties:
            type: string
        etag:
          description: >-
            Output only. This checksum is computed by the server based on the
            value of other fields. This may be sent on update, undelete, and
            delete requests to ensure the client has an up-to-date value before
            proceeding.
          readOnly: true
          type: string
        reconciling:
          description: >-
            Output only. Whether or not this CustomClass is in the process of
            being updated.
          readOnly: true
          type: boolean
        kmsKeyName:
          description: >-
            Output only. The [KMS key
            name](https://cloud.google.com/kms/docs/resource-hierarchy#keys)
            with which the CustomClass is encrypted. The expected format is
            `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
          readOnly: true
          type: string
        kmsKeyVersionName:
          description: >-
            Output only. The [KMS key version
            name](https://cloud.google.com/kms/docs/resource-hierarchy#key_versions)
            with which the CustomClass is encrypted. The expected format is
            `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}`.
          readOnly: true
          type: string
    ClassItem:
      id: ClassItem
      description: An item of the class.
      type: object
      properties:
        value:
          description: The class item's value.
          type: string
    TranscriptNormalization:
      id: TranscriptNormalization
      description: >-
        Transcription normalization configuration. Use transcription
        normalization to automatically replace parts of the transcript with
        phrases of your choosing. For StreamingRecognize, this normalization
        only applies to stable partial transcripts (stability > 0.8) and final
        transcripts.
      type: object
      properties:
        entries:
          description: >-
            A list of replacement entries. We will perform replacement with one
            entry at a time. For example, the second entry in ["cat" => "dog",
            "mountain cat" => "mountain dog"] will never be applied because we
            will always process the first entry before it. At most 100 entries.
          type: array
          items:
            $ref: '#/components/schemas/Entry'
    Entry:
      id: Entry
      description: A single replacement configuration.
      type: object
      properties:
        search:
          description: What to replace. Max length is 100 characters.
          type: string
        replace:
          description: What to replace with. Max length is 100 characters.
          type: string
        caseSensitive:
          description: Whether the search is case sensitive.
          type: boolean
    TranslationConfig:
      id: TranslationConfig
      description: >-
        Translation configuration. Use to translate the given audio into text
        for the desired language.
      type: object
      properties:
        targetLanguage:
          description: Required. The language code to translate to.
          type: string
    DenoiserConfig:
      id: DenoiserConfig
      description: >-
        Denoiser config. May not be supported for all models and may have no
        effect.
      type: object
      properties:
        denoiseAudio:
          description: Denoise audio before sending to the transcription model.
          type: boolean
        snrThreshold:
          description: >-
            Signal-to-Noise Ratio (SNR) threshold for the denoiser. Here SNR
            means the loudness of the speech signal. Audio with an SNR below
            this threshold, meaning the speech is too quiet, will be prevented
            from being sent to the transcription model. If snr_threshold=0, no
            filtering will be applied.
          type: number
          format: float
    ListRecognizersResponse:
      id: ListRecognizersResponse
      description: Response message for the ListRecognizers method.
      type: object
      properties:
        recognizers:
          description: The list of requested Recognizers.
          type: array
          items:
            $ref: '#/components/schemas/Recognizer'
        nextPageToken:
          description: >-
            A token, which can be sent as page_token to retrieve the next page.
            If this field is omitted, there are no subsequent pages. This token
            expires after 72 hours.
          type: string
    UndeleteRecognizerRequest:
      id: UndeleteRecognizerRequest
      description: Request message for the UndeleteRecognizer method.
      type: object
      properties:
        name:
          description: >-
            Required. The name of the Recognizer to undelete. Format:
            `projects/{project}/locations/{location}/recognizers/{recognizer}`
          type: string
        validateOnly:
          description: >-
            If set, validate the request and preview the undeleted Recognizer,
            but do not actually undelete it.
          type: boolean
        etag:
          description: >-
            This checksum is computed by the server based on the value of other
            fields. This may be sent on update, undelete, and delete requests to
            ensure the client has an up-to-date value before proceeding.
          type: string
    RecognizeRequest:
      id: RecognizeRequest
      description: >-
        Request message for the Recognize method. Either `content` or `uri` must
        be supplied. Supplying both or neither returns INVALID_ARGUMENT. See
        [content
        limits](https://cloud.google.com/speech-to-text/quotas#content).
      type: object
      properties:
        config:
          description: >-
            Features and audio metadata to use for the Automatic Speech
            Recognition. This field in combination with the config_mask field
            can be used to override parts of the default_recognition_config of
            the Recognizer resource.
          $ref: '#/components/schemas/RecognitionConfig'
        configMask:
          description: >-
            The list of fields in config that override the values in the
            default_recognition_config of the recognizer during this recognition
            request. If no mask is provided, all non-default valued fields in
            config override the values in the recognizer for this recognition
            request. If a mask is provided, only the fields listed in the mask
            override the config in the recognizer for this recognition request.
            If a wildcard (`*`) is provided, config completely overrides and
            replaces the config in the recognizer for this recognition request.
          type: string
          format: google-fieldmask
        content:
          description: >-
            The audio data bytes encoded as specified in RecognitionConfig. As
            with all bytes fields, proto buffers use a pure binary
            representation, whereas JSON representations use base64.
          type: string
          format: byte
        uri:
          description: >-
            URI that points to a file that contains audio data bytes as
            specified in RecognitionConfig. The file must not be compressed (for
            example, gzip). Currently, only Google Cloud Storage URIs are
            supported, which must be specified in the following format:
            `gs://bucket_name/object_name` (other URI formats return
            INVALID_ARGUMENT). For more information, see [Request
            URIs](https://cloud.google.com/storage/docs/reference-uris).
          type: string
    RecognizeResponse:
      id: RecognizeResponse
      description: Response message for the Recognize method.
      type: object
      properties:
        results:
          description: >-
            Sequential list of transcription results corresponding to sequential
            portions of audio.
          type: array
          items:
            $ref: '#/components/schemas/SpeechRecognitionResult'
        metadata:
          description: Metadata about the recognition.
          $ref: '#/components/schemas/RecognitionResponseMetadata'
    SpeechRecognitionResult:
      id: SpeechRecognitionResult
      description: A speech recognition result corresponding to a portion of the audio.
      type: object
      properties:
        alternatives:
          description: >-
            May contain one or more recognition hypotheses. These alternatives
            are ordered in terms of accuracy, with the top (first) alternative
            being the most probable, as ranked by the recognizer.
          type: array
          items:
            $ref: '#/components/schemas/SpeechRecognitionAlternative'
        channelTag:
          description: >-
            For multi-channel audio, this is the channel number corresponding to
            the recognized result for the audio from that channel. For
            `audio_channel_count` = `N`, its output values can range from `1` to
            `N`.
          type: integer
          format: int32
        resultEndOffset:
          description: >-
            Time offset of the end of this result relative to the beginning of
            the audio.
          type: string
          format: google-duration
        languageCode:
          description: >-
            Output only. The
            [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag
            of the language in this result. This language code was detected to
            have the most likelihood of being spoken in the audio.
          readOnly: true
          type: string
    SpeechRecognitionAlternative:
      id: SpeechRecognitionAlternative
      description: Alternative hypotheses (a.k.a. n-best list).
      type: object
      properties:
        transcript:
          description: Transcript text representing the words that the user spoke.
          type: string
        confidence:
          description: >-
            The confidence estimate between 0.0 and 1.0. A higher number
            indicates an estimated greater likelihood that the recognized words
            are correct. This field is set only for the top alternative of a
            non-streaming result or, of a streaming result where is_final is set
            to `true`. This field is not guaranteed to be accurate and users
            should not rely on it to be always provided. The default of 0.0 is a
            sentinel value indicating `confidence` was not set.
          type: number
          format: float
        words:
          description: >-
            A list of word-specific information for each recognized word. When
            the SpeakerDiarizationConfig is set, you will see all the words from
            the beginning of the audio.
          type: array
          items:
            $ref: '#/components/schemas/WordInfo'
    WordInfo:
      id: WordInfo
      description: Word-specific information for recognized words.
      type: object
      properties:
        startOffset:
          description: >-
            Time offset relative to the beginning of the audio, and
            corresponding to the start of the spoken word. This field is only
            set if enable_word_time_offsets is `true` and only in the top
            hypothesis. This is an experimental feature and the accuracy of the
            time offset can vary.
          type: string
          format: google-duration
        endOffset:
          description: >-
            Time offset relative to the beginning of the audio, and
            corresponding to the end of the spoken word. This field is only set
            if enable_word_time_offsets is `true` and only in the top
            hypothesis. This is an experimental feature and the accuracy of the
            time offset can vary.
          type: string
          format: google-duration
        word:
          description: The word corresponding to this set of information.
          type: string
        confidence:
          description: >-
            The confidence estimate between 0.0 and 1.0. A higher number
            indicates an estimated greater likelihood that the recognized words
            are correct. This field is set only for the top alternative of a
            non-streaming result or, of a streaming result where is_final is set
            to `true`. This field is not guaranteed to be accurate and users
            should not rely on it to be always provided. The default of 0.0 is a
            sentinel value indicating `confidence` was not set.
          type: number
          format: float
        speakerLabel:
          description: >-
            A distinct label is assigned for every speaker within the audio.
            This field specifies which one of those speakers was detected to
            have spoken this word. `speaker_label` is set if
            SpeakerDiarizationConfig is given and only in the top alternative.
          type: string
    RecognitionResponseMetadata:
      id: RecognitionResponseMetadata
      description: Metadata about the recognition request and response.
      type: object
      properties:
        requestId:
          description: Global request identifier auto-generated by the API.
          type: string
        totalBilledDuration:
          description: When available, billed audio seconds for the corresponding request.
          type: string
          format: google-duration
    BatchRecognizeRequest:
      id: BatchRecognizeRequest
      description: Request message for the BatchRecognize method.
      type: object
      properties:
        recognizer:
          description: >-
            Required. The name of the Recognizer to use during recognition. The
            expected format is
            `projects/{project}/locations/{location}/recognizers/{recognizer}`.
            The {recognizer} segment may be set to `_` to use an empty implicit
            Recognizer.
          type: string
        config:
          description: >-
            Features and audio metadata to use for the Automatic Speech
            Recognition. This field in combination with the config_mask field
            can be used to override parts of the default_recognition_config of
            the Recognizer resource.
          $ref: '#/components/schemas/RecognitionConfig'
        configMask:
          description: >-
            The list of fields in config that override the values in the
            default_recognition_config of the recognizer during this recognition
            request. If no mask is provided, all given fields in config override
            the values in the recognizer for this recognition request. If a mask
            is provided, only the fields listed in the mask override the config
            in the recognizer for this recognition request. If a wildcard (`*`)
            is provided, config completely overrides and replaces the config in
            the recognizer for this recognition request.
          type: string
          format: google-fieldmask
        files:
          description: >-
            Audio files with file metadata for ASR. The maximum number of files
            allowed to be specified is 15.
          type: array
          items:
            $ref: '#/components/schemas/BatchRecognizeFileMetadata'
        recognitionOutputConfig:
          description: >-
            Configuration options for where to output the transcripts of each
            file.
          $ref: '#/components/schemas/RecognitionOutputConfig'
        processingStrategy:
          description: Processing strategy to use for this request.
          type: string
          enumDescriptions:
            - >-
              Default value for the processing strategy. The request is
              processed as soon as its received.
            - >-
              If selected, processes the request during lower utilization
              periods for a price discount. The request is fulfilled within 24
              hours.
          enum:
            - PROCESSING_STRATEGY_UNSPECIFIED
            - DYNAMIC_BATCHING
    BatchRecognizeFileMetadata:
      id: BatchRecognizeFileMetadata
      description: Metadata about a single file in a batch for BatchRecognize.
      type: object
      properties:
        uri:
          description: Cloud Storage URI for the audio file.
          type: string
        config:
          description: >-
            Features and audio metadata to use for the Automatic Speech
            Recognition. This field in combination with the config_mask field
            can be used to override parts of the default_recognition_config of
            the Recognizer resource as well as the config at the request level.
          $ref: '#/components/schemas/RecognitionConfig'
        configMask:
          description: >-
            The list of fields in config that override the values in the
            default_recognition_config of the recognizer during this recognition
            request. If no mask is provided, all non-default valued fields in
            config override the values in the recognizer for this recognition
            request. If a mask is provided, only the fields listed in the mask
            override the config in the recognizer for this recognition request.
            If a wildcard (`*`) is provided, config completely overrides and
            replaces the config in the recognizer for this recognition request.
          type: string
          format: google-fieldmask
    RecognitionOutputConfig:
      id: RecognitionOutputConfig
      description: Configuration options for the output(s) of recognition.
      type: object
      properties:
        gcsOutputConfig:
          description: >-
            If this message is populated, recognition results are written to the
            provided Google Cloud Storage URI.
          $ref: '#/components/schemas/GcsOutputConfig'
        inlineResponseConfig:
          description: >-
            If this message is populated, recognition results are provided in
            the BatchRecognizeResponse message of the Operation when completed.
            This is only supported when calling BatchRecognize with just one
            audio file.
          $ref: '#/components/schemas/InlineOutputConfig'
        outputFormatConfig:
          description: >-
            Optional. Configuration for the format of the results stored to
            `output`. If unspecified transcripts will be written in the `NATIVE`
            format only.
          $ref: '#/components/schemas/OutputFormatConfig'
    GcsOutputConfig:
      id: GcsOutputConfig
      description: Output configurations for Cloud Storage.
      type: object
      properties:
        uri:
          description: >-
            The Cloud Storage URI prefix with which recognition results will be
            written.
          type: string
    InlineOutputConfig:
      id: InlineOutputConfig
      description: Output configurations for inline response.
      type: object
      properties: {}
    OutputFormatConfig:
      id: OutputFormatConfig
      description: Configuration for the format of the results stored to `output`.
      type: object
      properties:
        native:
          description: >-
            Configuration for the native output format. If this field is set or
            if no other output format field is set, then transcripts will be
            written to the sink in the native format.
          $ref: '#/components/schemas/NativeOutputFileFormatConfig'
        vtt:
          description: >-
            Configuration for the VTT output format. If this field is set, then
            transcripts will be written to the sink in the VTT format.
          $ref: '#/components/schemas/VttOutputFileFormatConfig'
        srt:
          description: >-
            Configuration for the SRT output format. If this field is set, then
            transcripts will be written to the sink in the SRT format.
          $ref: '#/components/schemas/SrtOutputFileFormatConfig'
    NativeOutputFileFormatConfig:
      id: NativeOutputFileFormatConfig
      description: Output configurations for serialized `BatchRecognizeResults` protos.
      type: object
      properties: {}
    VttOutputFileFormatConfig:
      id: VttOutputFileFormatConfig
      description: >-
        Output configurations for [WebVTT](https://www.w3.org/TR/webvtt1/)
        formatted subtitle file.
      type: object
      properties: {}
    SrtOutputFileFormatConfig:
      id: SrtOutputFileFormatConfig
      description: >-
        Output configurations [SubRip
        Text](https://www.matroska.org/technical/subtitles.html#srt-subtitles)
        formatted subtitle file.
      type: object
      properties: {}
    Config:
      id: Config
      description: >-
        Message representing the config for the Speech-to-Text API. This
        includes an optional [KMS
        key](https://cloud.google.com/kms/docs/resource-hierarchy#keys) with
        which incoming data will be encrypted.
      type: object
      properties:
        name:
          description: >-
            Output only. Identifier. The name of the config resource. There is
            exactly one config resource per project per location. The expected
            format is `projects/{project}/locations/{location}/config`.
          readOnly: true
          type: string
        kmsKeyName:
          description: >-
            Optional. An optional [KMS key
            name](https://cloud.google.com/kms/docs/resource-hierarchy#keys)
            that if present, will be used to encrypt Speech-to-Text resources
            at-rest. Updating this key will not encrypt existing resources using
            this key; only new resources will be encrypted using this key. The
            expected format is
            `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
          type: string
        updateTime:
          description: Output only. The most recent time this resource was modified.
          readOnly: true
          type: string
          format: google-datetime
    ListCustomClassesResponse:
      id: ListCustomClassesResponse
      description: Response message for the ListCustomClasses method.
      type: object
      properties:
        customClasses:
          description: The list of requested CustomClasses.
          type: array
          items:
            $ref: '#/components/schemas/CustomClass'
        nextPageToken:
          description: >-
            A token, which can be sent as page_token to retrieve the next page.
            If this field is omitted, there are no subsequent pages. This token
            expires after 72 hours.
          type: string
    UndeleteCustomClassRequest:
      id: UndeleteCustomClassRequest
      description: Request message for the UndeleteCustomClass method.
      type: object
      properties:
        name:
          description: >-
            Required. The name of the CustomClass to undelete. Format:
            `projects/{project}/locations/{location}/customClasses/{custom_class}`
          type: string
        validateOnly:
          description: >-
            If set, validate the request and preview the undeleted CustomClass,
            but do not actually undelete it.
          type: boolean
        etag:
          description: >-
            This checksum is computed by the server based on the value of other
            fields. This may be sent on update, undelete, and delete requests to
            ensure the client has an up-to-date value before proceeding.
          type: string
    ListPhraseSetsResponse:
      id: ListPhraseSetsResponse
      description: Response message for the ListPhraseSets method.
      type: object
      properties:
        phraseSets:
          description: The list of requested PhraseSets.
          type: array
          items:
            $ref: '#/components/schemas/PhraseSet'
        nextPageToken:
          description: >-
            A token, which can be sent as page_token to retrieve the next page.
            If this field is omitted, there are no subsequent pages. This token
            expires after 72 hours.
          type: string
    UndeletePhraseSetRequest:
      id: UndeletePhraseSetRequest
      description: Request message for the UndeletePhraseSet method.
      type: object
      properties:
        name:
          description: >-
            Required. The name of the PhraseSet to undelete. Format:
            `projects/{project}/locations/{location}/phraseSets/{phrase_set}`
          type: string
        validateOnly:
          description: >-
            If set, validate the request and preview the undeleted PhraseSet,
            but do not actually undelete it.
          type: boolean
        etag:
          description: >-
            This checksum is computed by the server based on the value of other
            fields. This may be sent on update, undelete, and delete requests to
            ensure the client has an up-to-date value before proceeding.
          type: string
    OperationMetadata:
      id: OperationMetadata
      description: Represents the metadata of a long-running operation.
      type: object
      properties:
        createTime:
          description: The time the operation was created.
          type: string
          format: google-datetime
        updateTime:
          description: The time the operation was last updated.
          type: string
          format: google-datetime
        resource:
          description: The resource path for the target of the operation.
          type: string
        method:
          description: The method that triggered the operation.
          type: string
        kmsKeyName:
          description: >-
            The [KMS key
            name](https://cloud.google.com/kms/docs/resource-hierarchy#keys)
            with which the content of the Operation is encrypted. The expected
            format is
            `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
          type: string
        kmsKeyVersionName:
          description: >-
            The [KMS key version
            name](https://cloud.google.com/kms/docs/resource-hierarchy#key_versions)
            with which content of the Operation is encrypted. The expected
            format is
            `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}`.
          type: string
        batchRecognizeRequest:
          description: The BatchRecognizeRequest that spawned the Operation.
          $ref: '#/components/schemas/BatchRecognizeRequest'
        createRecognizerRequest:
          description: The CreateRecognizerRequest that spawned the Operation.
          $ref: '#/components/schemas/CreateRecognizerRequest'
        updateRecognizerRequest:
          description: The UpdateRecognizerRequest that spawned the Operation.
          $ref: '#/components/schemas/UpdateRecognizerRequest'
        deleteRecognizerRequest:
          description: The DeleteRecognizerRequest that spawned the Operation.
          $ref: '#/components/schemas/DeleteRecognizerRequest'
        undeleteRecognizerRequest:
          description: The UndeleteRecognizerRequest that spawned the Operation.
          $ref: '#/components/schemas/UndeleteRecognizerRequest'
        createCustomClassRequest:
          description: The CreateCustomClassRequest that spawned the Operation.
          $ref: '#/components/schemas/CreateCustomClassRequest'
        updateCustomClassRequest:
          description: The UpdateCustomClassRequest that spawned the Operation.
          $ref: '#/components/schemas/UpdateCustomClassRequest'
        deleteCustomClassRequest:
          description: The DeleteCustomClassRequest that spawned the Operation.
          $ref: '#/components/schemas/DeleteCustomClassRequest'
        undeleteCustomClassRequest:
          description: The UndeleteCustomClassRequest that spawned the Operation.
          $ref: '#/components/schemas/UndeleteCustomClassRequest'
        createPhraseSetRequest:
          description: The CreatePhraseSetRequest that spawned the Operation.
          $ref: '#/components/schemas/CreatePhraseSetRequest'
        updatePhraseSetRequest:
          description: The UpdatePhraseSetRequest that spawned the Operation.
          $ref: '#/components/schemas/UpdatePhraseSetRequest'
        deletePhraseSetRequest:
          description: The DeletePhraseSetRequest that spawned the Operation.
          $ref: '#/components/schemas/DeletePhraseSetRequest'
        undeletePhraseSetRequest:
          description: The UndeletePhraseSetRequest that spawned the Operation.
          $ref: '#/components/schemas/UndeletePhraseSetRequest'
        updateConfigRequest:
          description: The UpdateConfigRequest that spawned the Operation.
          deprecated: true
          $ref: '#/components/schemas/UpdateConfigRequest'
        progressPercent:
          description: >-
            The percent progress of the Operation. Values can range from 0-100.
            If the value is 100, then the operation is finished.
          type: integer
          format: int32
        batchRecognizeMetadata:
          description: Metadata specific to the BatchRecognize method.
          $ref: '#/components/schemas/BatchRecognizeMetadata'
    CreateRecognizerRequest:
      id: CreateRecognizerRequest
      description: Request message for the CreateRecognizer method.
      type: object
      properties:
        recognizer:
          description: Required. The Recognizer to create.
          $ref: '#/components/schemas/Recognizer'
        validateOnly:
          description: >-
            If set, validate the request and preview the Recognizer, but do not
            actually create it.
          type: boolean
        recognizerId:
          description: >-
            The ID to use for the Recognizer, which will become the final
            component of the Recognizer's resource name. This value should be
            4-63 characters, and valid characters are /a-z-/.
          type: string
        parent:
          description: >-
            Required. The project and location where this Recognizer will be
            created. The expected format is
            `projects/{project}/locations/{location}`.
          type: string
    UpdateRecognizerRequest:
      id: UpdateRecognizerRequest
      description: Request message for the UpdateRecognizer method.
      type: object
      properties:
        recognizer:
          description: >-
            Required. The Recognizer to update. The Recognizer's `name` field is
            used to identify the Recognizer to update. Format:
            `projects/{project}/locations/{location}/recognizers/{recognizer}`.
          $ref: '#/components/schemas/Recognizer'
        updateMask:
          description: >-
            The list of fields to update. If empty, all non-default valued
            fields are considered for update. Use `*` to update the entire
            Recognizer resource.
          type: string
          format: google-fieldmask
        validateOnly:
          description: >-
            If set, validate the request and preview the updated Recognizer, but
            do not actually update it.
          type: boolean
    DeleteRecognizerRequest:
      id: DeleteRecognizerRequest
      description: Request message for the DeleteRecognizer method.
      type: object
      properties:
        name:
          description: >-
            Required. The name of the Recognizer to delete. Format:
            `projects/{project}/locations/{location}/recognizers/{recognizer}`
          type: string
        validateOnly:
          description: >-
            If set, validate the request and preview the deleted Recognizer, but
            do not actually delete it.
          type: boolean
        allowMissing:
          description: >-
            If set to true, and the Recognizer is not found, the request will
            succeed and be a no-op (no Operation is recorded in this case).
          type: boolean
        etag:
          description: >-
            This checksum is computed by the server based on the value of other
            fields. This may be sent on update, undelete, and delete requests to
            ensure the client has an up-to-date value before proceeding.
          type: string
    CreateCustomClassRequest:
      id: CreateCustomClassRequest
      description: Request message for the CreateCustomClass method.
      type: object
      properties:
        customClass:
          description: Required. The CustomClass to create.
          $ref: '#/components/schemas/CustomClass'
        validateOnly:
          description: >-
            If set, validate the request and preview the CustomClass, but do not
            actually create it.
          type: boolean
        customClassId:
          description: >-
            The ID to use for the CustomClass, which will become the final
            component of the CustomClass's resource name. This value should be
            4-63 characters, and valid characters are /a-z-/.
          type: string
        parent:
          description: >-
            Required. The project and location where this CustomClass will be
            created. The expected format is
            `projects/{project}/locations/{location}`.
          type: string
    UpdateCustomClassRequest:
      id: UpdateCustomClassRequest
      description: Request message for the UpdateCustomClass method.
      type: object
      properties:
        customClass:
          description: >-
            Required. The CustomClass to update. The CustomClass's `name` field
            is used to identify the CustomClass to update. Format:
            `projects/{project}/locations/{location}/customClasses/{custom_class}`.
          $ref: '#/components/schemas/CustomClass'
        updateMask:
          description: >-
            The list of fields to be updated. If empty, all fields are
            considered for update.
          type: string
          format: google-fieldmask
        validateOnly:
          description: >-
            If set, validate the request and preview the updated CustomClass,
            but do not actually update it.
          type: boolean
    DeleteCustomClassRequest:
      id: DeleteCustomClassRequest
      description: Request message for the DeleteCustomClass method.
      type: object
      properties:
        name:
          description: >-
            Required. The name of the CustomClass to delete. Format:
            `projects/{project}/locations/{location}/customClasses/{custom_class}`
          type: string
        validateOnly:
          description: >-
            If set, validate the request and preview the deleted CustomClass,
            but do not actually delete it.
          type: boolean
        allowMissing:
          description: >-
            If set to true, and the CustomClass is not found, the request will
            succeed and be a no-op (no Operation is recorded in this case).
          type: boolean
        etag:
          description: >-
            This checksum is computed by the server based on the value of other
            fields. This may be sent on update, undelete, and delete requests to
            ensure the client has an up-to-date value before proceeding.
          type: string
    CreatePhraseSetRequest:
      id: CreatePhraseSetRequest
      description: Request message for the CreatePhraseSet method.
      type: object
      properties:
        phraseSet:
          description: Required. The PhraseSet to create.
          $ref: '#/components/schemas/PhraseSet'
        validateOnly:
          description: >-
            If set, validate the request and preview the PhraseSet, but do not
            actually create it.
          type: boolean
        phraseSetId:
          description: >-
            The ID to use for the PhraseSet, which will become the final
            component of the PhraseSet's resource name. This value should be
            4-63 characters, and valid characters are /a-z-/.
          type: string
        parent:
          description: >-
            Required. The project and location where this PhraseSet will be
            created. The expected format is
            `projects/{project}/locations/{location}`.
          type: string
    UpdatePhraseSetRequest:
      id: UpdatePhraseSetRequest
      description: Request message for the UpdatePhraseSet method.
      type: object
      properties:
        phraseSet:
          description: >-
            Required. The PhraseSet to update. The PhraseSet's `name` field is
            used to identify the PhraseSet to update. Format:
            `projects/{project}/locations/{location}/phraseSets/{phrase_set}`.
          $ref: '#/components/schemas/PhraseSet'
        updateMask:
          description: >-
            The list of fields to update. If empty, all non-default valued
            fields are considered for update. Use `*` to update the entire
            PhraseSet resource.
          type: string
          format: google-fieldmask
        validateOnly:
          description: >-
            If set, validate the request and preview the updated PhraseSet, but
            do not actually update it.
          type: boolean
    DeletePhraseSetRequest:
      id: DeletePhraseSetRequest
      description: Request message for the DeletePhraseSet method.
      type: object
      properties:
        name:
          description: >-
            Required. The name of the PhraseSet to delete. Format:
            `projects/{project}/locations/{location}/phraseSets/{phrase_set}`
          type: string
        validateOnly:
          description: >-
            If set, validate the request and preview the deleted PhraseSet, but
            do not actually delete it.
          type: boolean
        allowMissing:
          description: >-
            If set to true, and the PhraseSet is not found, the request will
            succeed and be a no-op (no Operation is recorded in this case).
          type: boolean
        etag:
          description: >-
            This checksum is computed by the server based on the value of other
            fields. This may be sent on update, undelete, and delete requests to
            ensure the client has an up-to-date value before proceeding.
          type: string
    UpdateConfigRequest:
      id: UpdateConfigRequest
      description: Request message for the UpdateConfig method.
      type: object
      properties:
        config:
          description: >-
            Required. The config to update. The config's `name` field is used to
            identify the config to be updated. The expected format is
            `projects/{project}/locations/{location}/config`.
          $ref: '#/components/schemas/Config'
        updateMask:
          description: The list of fields to be updated.
          type: string
          format: google-fieldmask
    BatchRecognizeMetadata:
      id: BatchRecognizeMetadata
      description: Operation metadata for BatchRecognize.
      type: object
      properties:
        transcriptionMetadata:
          description: >-
            Map from provided filename to the transcription metadata for that
            file.
          type: object
          additionalProperties:
            $ref: '#/components/schemas/BatchRecognizeTranscriptionMetadata'
    BatchRecognizeTranscriptionMetadata:
      id: BatchRecognizeTranscriptionMetadata
      description: >-
        Metadata about transcription for a single file (for example, progress
        percent).
      type: object
      properties:
        progressPercent:
          description: How much of the file has been transcribed so far.
          type: integer
          format: int32
        error:
          description: Error if one was encountered.
          $ref: '#/components/schemas/Status'
        uri:
          description: The Cloud Storage URI to which recognition results will be written.
          type: string
    LocationsMetadata:
      id: LocationsMetadata
      description: >-
        Main metadata for the Locations API for STT V2. Currently this is just
        the metadata about locales, models, and features
      type: object
      properties:
        languages:
          description: >-
            Information about available locales, models, and features
            represented in the hierarchical structure of locales -> models ->
            features
          $ref: '#/components/schemas/LanguageMetadata'
        accessMetadata:
          description: Information about access metadata for the region and given project.
          $ref: '#/components/schemas/AccessMetadata'
    LanguageMetadata:
      id: LanguageMetadata
      description: >-
        The metadata about locales available in a given region. Currently this
        is just the models that are available for each locale
      type: object
      properties:
        models:
          description: Map of locale (language code) -> models
          type: object
          additionalProperties:
            $ref: '#/components/schemas/ModelMetadata'
    ModelMetadata:
      id: ModelMetadata
      description: >-
        The metadata about the models in a given region for a specific locale.
        Currently this is just the features of the model
      type: object
      properties:
        modelFeatures:
          description: Map of the model name -> features of that model
          type: object
          additionalProperties:
            $ref: '#/components/schemas/ModelFeatures'
    ModelFeatures:
      id: ModelFeatures
      description: Represents the collection of features belonging to a model
      type: object
      properties:
        modelFeature:
          description: Repeated field that contains all features of the model
          type: array
          items:
            $ref: '#/components/schemas/ModelFeature'
    ModelFeature:
      id: ModelFeature
      description: >-
        Represents a singular feature of a model. If the feature is
        `recognizer`, the release_state of the feature represents the
        release_state of the model
      type: object
      properties:
        feature:
          description: 'The name of the feature (Note: the feature can be `recognizer`)'
          type: string
        releaseState:
          description: The release state of the feature
          type: string
    AccessMetadata:
      id: AccessMetadata
      description: >-
        The access metadata for a particular region. This can be applied if the
        org policy for the given project disallows a particular region.
      type: object
      properties:
        constraintType:
          description: Describes the different types of constraints that are applied.
          type: string
          enumDescriptions:
            - Unspecified constraint applied.
            - The project's org policy disallows the given region.
          enum:
            - CONSTRAINT_TYPE_UNSPECIFIED
            - RESOURCE_LOCATIONS_ORG_POLICY_CREATE_CONSTRAINT
    StreamingRecognitionResult:
      id: StreamingRecognitionResult
      description: >-
        A streaming speech recognition result corresponding to a portion of the
        audio that is currently being processed.
      type: object
      properties:
        alternatives:
          description: >-
            May contain one or more recognition hypotheses. These alternatives
            are ordered in terms of accuracy, with the top (first) alternative
            being the most probable, as ranked by the recognizer.
          type: array
          items:
            $ref: '#/components/schemas/SpeechRecognitionAlternative'
        isFinal:
          description: >-
            If `false`, this StreamingRecognitionResult represents an interim
            result that may change. If `true`, this is the final time the speech
            service will return this particular StreamingRecognitionResult, the
            recognizer will not return any further hypotheses for this portion
            of the transcript and corresponding audio.
          type: boolean
        stability:
          description: >-
            An estimate of the likelihood that the recognizer will not change
            its guess about this interim result. Values range from 0.0
            (completely unstable) to 1.0 (completely stable). This field is only
            provided for interim results (is_final=`false`). The default of 0.0
            is a sentinel value indicating `stability` was not set.
          type: number
          format: float
        resultEndOffset:
          description: >-
            Time offset of the end of this result relative to the beginning of
            the audio.
          type: string
          format: google-duration
        channelTag:
          description: >-
            For multi-channel audio, this is the channel number corresponding to
            the recognized result for the audio from that channel. For
            `audio_channel_count` = `N`, its output values can range from `1` to
            `N`.
          type: integer
          format: int32
        languageCode:
          description: >-
            Output only. The
            [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag
            of the language in this result. This language code was detected to
            have the most likelihood of being spoken in the audio.
          readOnly: true
          type: string
    BatchRecognizeResponse:
      id: BatchRecognizeResponse
      description: >-
        Response message for BatchRecognize that is packaged into a longrunning
        Operation.
      type: object
      properties:
        results:
          description: Map from filename to the final result for that file.
          type: object
          additionalProperties:
            $ref: '#/components/schemas/BatchRecognizeFileResult'
        totalBilledDuration:
          description: When available, billed audio seconds for the corresponding request.
          type: string
          format: google-duration
    BatchRecognizeFileResult:
      id: BatchRecognizeFileResult
      description: Final results for a single file.
      type: object
      properties:
        error:
          description: Error if one was encountered.
          $ref: '#/components/schemas/Status'
        metadata:
          $ref: '#/components/schemas/RecognitionResponseMetadata'
        cloudStorageResult:
          description: >-
            Recognition results written to Cloud Storage. This is populated only
            when GcsOutputConfig is set in the RecognitionOutputConfig.
          $ref: '#/components/schemas/CloudStorageResult'
        inlineResult:
          description: >-
            Recognition results. This is populated only when InlineOutputConfig
            is set in the RecognitionOutputConfig.
          $ref: '#/components/schemas/InlineResult'
        uri:
          description: Deprecated. Use `cloud_storage_result.native_format_uri` instead.
          deprecated: true
          type: string
        transcript:
          description: Deprecated. Use `inline_result.transcript` instead.
          deprecated: true
          $ref: '#/components/schemas/BatchRecognizeResults'
    CloudStorageResult:
      id: CloudStorageResult
      description: Final results written to Cloud Storage.
      type: object
      properties:
        uri:
          description: The Cloud Storage URI to which recognition results were written.
          type: string
        vttFormatUri:
          description: >-
            The Cloud Storage URI to which recognition results were written as
            VTT formatted captions. This is populated only when `VTT` output is
            requested.
          type: string
        srtFormatUri:
          description: >-
            The Cloud Storage URI to which recognition results were written as
            SRT formatted captions. This is populated only when `SRT` output is
            requested.
          type: string
    InlineResult:
      id: InlineResult
      description: Final results returned inline in the recognition response.
      type: object
      properties:
        transcript:
          description: The transcript for the audio file.
          $ref: '#/components/schemas/BatchRecognizeResults'
        vttCaptions:
          description: >-
            The transcript for the audio file as VTT formatted captions. This is
            populated only when `VTT` output is requested.
          type: string
        srtCaptions:
          description: >-
            The transcript for the audio file as SRT formatted captions. This is
            populated only when `SRT` output is requested.
          type: string
    BatchRecognizeResults:
      id: BatchRecognizeResults
      description: >-
        Output type for Cloud Storage of BatchRecognize transcripts. Though this
        proto isn't returned in this API anywhere, the Cloud Storage transcripts
        will be this proto serialized and should be parsed as such.
      type: object
      properties:
        results:
          description: >-
            Sequential list of transcription results corresponding to sequential
            portions of audio.
          type: array
          items:
            $ref: '#/components/schemas/SpeechRecognitionResult'
        metadata:
          description: Metadata about the recognition.
          $ref: '#/components/schemas/RecognitionResponseMetadata'
  parameters:
    access_token:
      description: OAuth access token.
      in: query
      name: access_token
      schema:
        type: string
    alt:
      description: Data format for response.
      in: query
      name: alt
      schema:
        type: string
        enum:
          - json
          - media
          - proto
    callback:
      description: JSONP
      in: query
      name: callback
      schema:
        type: string
    fields:
      description: Selector specifying which fields to include in a partial response.
      in: query
      name: fields
      schema:
        type: string
    key:
      description: >-
        API key. Your API key identifies your project and provides you with API
        access, quota, and reports. Required unless you provide an OAuth 2.0
        token.
      in: query
      name: key
      schema:
        type: string
    oauth_token:
      description: OAuth 2.0 token for the current user.
      in: query
      name: oauth_token
      schema:
        type: string
    prettyPrint:
      description: Returns response with indentations and line breaks.
      in: query
      name: prettyPrint
      schema:
        type: boolean
    quotaUser:
      description: >-
        Available to use for quota purposes for server-side applications. Can be
        any arbitrary string assigned to a user, but should not exceed 40
        characters.
      in: query
      name: quotaUser
      schema:
        type: string
    upload_protocol:
      description: Upload protocol for media (e.g. "raw", "multipart").
      in: query
      name: upload_protocol
      schema:
        type: string
    uploadType:
      description: Legacy upload protocol for media (e.g. "media", "multipart").
      in: query
      name: uploadType
      schema:
        type: string
    _.xgafv:
      description: V1 error format.
      in: query
      name: $.xgafv
      schema:
        type: string
        enum:
          - '1'
          - '2'
  x-stackQL-resources:
    locations:
      id: google.speechv2.locations
      name: locations
      title: Locations
      methods:
        list:
          operation:
            $ref: '#/paths/~1v2~1projects~1{projectsId}~1locations/get'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
            objectKey: $.locations
        get:
          operation:
            $ref: '#/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}/get'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
      sqlVerbs:
        select:
          - $ref: '#/components/x-stackQL-resources/locations/methods/get'
          - $ref: '#/components/x-stackQL-resources/locations/methods/list'
        insert: []
        update: []
        replace: []
        delete: []
    operations:
      id: google.speechv2.operations
      name: operations
      title: Operations
      methods:
        list:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1operations/get
          response:
            mediaType: application/json
            openAPIDocKey: '200'
            objectKey: $.operations
        get:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1operations~1{operationsId}/get
          response:
            mediaType: application/json
            openAPIDocKey: '200'
      sqlVerbs:
        select:
          - $ref: '#/components/x-stackQL-resources/operations/methods/get'
          - $ref: '#/components/x-stackQL-resources/operations/methods/list'
        insert: []
        update: []
        replace: []
        delete: []
    recognizers:
      id: google.speechv2.recognizers
      name: recognizers
      title: Recognizers
      methods:
        create:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1recognizers/post
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        list:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1recognizers/get
          response:
            mediaType: application/json
            openAPIDocKey: '200'
            objectKey: $.recognizers
        get:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1recognizers~1{recognizersId}/get
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        patch:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1recognizers~1{recognizersId}/patch
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        delete:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1recognizers~1{recognizersId}/delete
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        undelete:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1recognizers~1{recognizersId}:undelete/post
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        recognize:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1recognizers~1{recognizersId}:recognize/post
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        batch_recognize:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1recognizers~1{recognizersId}:batchRecognize/post
          response:
            mediaType: application/json
            openAPIDocKey: '200'
      sqlVerbs:
        select:
          - $ref: '#/components/x-stackQL-resources/recognizers/methods/get'
          - $ref: '#/components/x-stackQL-resources/recognizers/methods/list'
        insert:
          - $ref: '#/components/x-stackQL-resources/recognizers/methods/create'
        update:
          - $ref: '#/components/x-stackQL-resources/recognizers/methods/patch'
        replace: []
        delete:
          - $ref: '#/components/x-stackQL-resources/recognizers/methods/delete'
    config:
      id: google.speechv2.config
      name: config
      title: Config
      methods:
        get:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1config/get
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        update:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1config/patch
          response:
            mediaType: application/json
            openAPIDocKey: '200'
      sqlVerbs:
        select:
          - $ref: '#/components/x-stackQL-resources/config/methods/get'
        insert: []
        update:
          - $ref: '#/components/x-stackQL-resources/config/methods/update'
        replace: []
        delete: []
    custom_classes:
      id: google.speechv2.custom_classes
      name: custom_classes
      title: Custom_classes
      methods:
        create:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1customClasses/post
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        list:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1customClasses/get
          response:
            mediaType: application/json
            openAPIDocKey: '200'
            objectKey: $.customClasses
        get:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1customClasses~1{customClassesId}/get
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        patch:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1customClasses~1{customClassesId}/patch
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        delete:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1customClasses~1{customClassesId}/delete
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        undelete:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1customClasses~1{customClassesId}:undelete/post
          response:
            mediaType: application/json
            openAPIDocKey: '200'
      sqlVerbs:
        select:
          - $ref: '#/components/x-stackQL-resources/custom_classes/methods/get'
          - $ref: '#/components/x-stackQL-resources/custom_classes/methods/list'
        insert:
          - $ref: '#/components/x-stackQL-resources/custom_classes/methods/create'
        update:
          - $ref: '#/components/x-stackQL-resources/custom_classes/methods/patch'
        replace: []
        delete:
          - $ref: '#/components/x-stackQL-resources/custom_classes/methods/delete'
    phrase_sets:
      id: google.speechv2.phrase_sets
      name: phrase_sets
      title: Phrase_sets
      methods:
        create:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1phraseSets/post
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        list:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1phraseSets/get
          response:
            mediaType: application/json
            openAPIDocKey: '200'
            objectKey: $.phraseSets
        get:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1phraseSets~1{phraseSetsId}/get
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        patch:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1phraseSets~1{phraseSetsId}/patch
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        delete:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1phraseSets~1{phraseSetsId}/delete
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        undelete:
          operation:
            $ref: >-
              #/paths/~1v2~1projects~1{projectsId}~1locations~1{locationsId}~1phraseSets~1{phraseSetsId}:undelete/post
          response:
            mediaType: application/json
            openAPIDocKey: '200'
      sqlVerbs:
        select:
          - $ref: '#/components/x-stackQL-resources/phrase_sets/methods/get'
          - $ref: '#/components/x-stackQL-resources/phrase_sets/methods/list'
        insert:
          - $ref: '#/components/x-stackQL-resources/phrase_sets/methods/create'
        update:
          - $ref: '#/components/x-stackQL-resources/phrase_sets/methods/patch'
        replace: []
        delete:
          - $ref: '#/components/x-stackQL-resources/phrase_sets/methods/delete'
paths:
  /v2/projects/{projectsId}/locations:
    parameters: &ref_1
      - $ref: '#/components/parameters/access_token'
      - $ref: '#/components/parameters/alt'
      - $ref: '#/components/parameters/callback'
      - $ref: '#/components/parameters/fields'
      - $ref: '#/components/parameters/key'
      - $ref: '#/components/parameters/oauth_token'
      - $ref: '#/components/parameters/prettyPrint'
      - $ref: '#/components/parameters/quotaUser'
      - $ref: '#/components/parameters/upload_protocol'
      - $ref: '#/components/parameters/uploadType'
      - $ref: '#/components/parameters/_.xgafv'
    get:
      description: Lists information about the supported locations for this service.
      operationId: speech.projects.locations.list
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListLocationsResponse'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: query
          name: filter
          schema:
            type: string
        - in: query
          name: pageSize
          schema:
            type: integer
            format: int32
        - in: query
          name: pageToken
          schema:
            type: string
        - in: query
          name: extraLocationTypes
          schema:
            type: string
  /v2/projects/{projectsId}/locations/{locationsId}:
    parameters: *ref_1
    get:
      description: Gets information about a location.
      operationId: speech.projects.locations.get
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Location'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
  /v2/projects/{projectsId}/locations/{locationsId}/operations:
    parameters: *ref_1
    get:
      description: >-
        Lists operations that match the specified filter in the request. If the
        server doesn't support this method, it returns `UNIMPLEMENTED`.
      operationId: speech.projects.locations.operations.list
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListOperationsResponse'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: query
          name: filter
          schema:
            type: string
        - in: query
          name: pageSize
          schema:
            type: integer
            format: int32
        - in: query
          name: pageToken
          schema:
            type: string
        - in: query
          name: returnPartialSuccess
          schema:
            type: boolean
  /v2/projects/{projectsId}/locations/{locationsId}/operations/{operationsId}:
    parameters: *ref_1
    get:
      description: >-
        Gets the latest state of a long-running operation. Clients can use this
        method to poll the operation result at intervals as recommended by the
        API service.
      operationId: speech.projects.locations.operations.get
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: path
          name: operationsId
          required: true
          schema:
            type: string
  /v2/projects/{projectsId}/locations/{locationsId}/recognizers:
    parameters: *ref_1
    post:
      description: Creates a Recognizer.
      operationId: speech.projects.locations.recognizers.create
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/Recognizer'
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: query
          name: validateOnly
          schema:
            type: boolean
        - in: query
          name: recognizerId
          schema:
            type: string
    get:
      description: Lists Recognizers.
      operationId: speech.projects.locations.recognizers.list
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListRecognizersResponse'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: query
          name: pageSize
          schema:
            type: integer
            format: int32
        - in: query
          name: pageToken
          schema:
            type: string
        - in: query
          name: showDeleted
          schema:
            type: boolean
  /v2/projects/{projectsId}/locations/{locationsId}/recognizers/{recognizersId}:
    parameters: *ref_1
    get:
      description: >-
        Returns the requested Recognizer. Fails with NOT_FOUND if the requested
        Recognizer doesn't exist.
      operationId: speech.projects.locations.recognizers.get
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Recognizer'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: path
          name: recognizersId
          required: true
          schema:
            type: string
    patch:
      description: Updates the Recognizer.
      operationId: speech.projects.locations.recognizers.patch
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/Recognizer'
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: path
          name: recognizersId
          required: true
          schema:
            type: string
        - in: query
          name: updateMask
          schema:
            type: string
            format: google-fieldmask
        - in: query
          name: validateOnly
          schema:
            type: boolean
    delete:
      description: Deletes the Recognizer.
      operationId: speech.projects.locations.recognizers.delete
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: path
          name: recognizersId
          required: true
          schema:
            type: string
        - in: query
          name: validateOnly
          schema:
            type: boolean
        - in: query
          name: allowMissing
          schema:
            type: boolean
        - in: query
          name: etag
          schema:
            type: string
  /v2/projects/{projectsId}/locations/{locationsId}/recognizers/{recognizersId}:undelete:
    parameters: *ref_1
    post:
      description: Undeletes the Recognizer.
      operationId: speech.projects.locations.recognizers.undelete
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UndeleteRecognizerRequest'
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: path
          name: recognizersId
          required: true
          schema:
            type: string
  /v2/projects/{projectsId}/locations/{locationsId}/recognizers/{recognizersId}:recognize:
    parameters: *ref_1
    post:
      description: >-
        Performs synchronous Speech recognition: receive results after all audio
        has been sent and processed.
      operationId: speech.projects.locations.recognizers.recognize
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/RecognizeRequest'
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RecognizeResponse'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: path
          name: recognizersId
          required: true
          schema:
            type: string
  /v2/projects/{projectsId}/locations/{locationsId}/recognizers/{recognizersId}:batchRecognize:
    parameters: *ref_1
    post:
      description: >-
        Performs batch asynchronous speech recognition: send a request with N
        audio files and receive a long running operation that can be polled to
        see when the transcriptions are finished.
      operationId: speech.projects.locations.recognizers.batchRecognize
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/BatchRecognizeRequest'
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: path
          name: recognizersId
          required: true
          schema:
            type: string
  /v2/projects/{projectsId}/locations/{locationsId}/config:
    parameters: *ref_1
    get:
      description: Returns the requested Config.
      operationId: speech.projects.locations.config.get
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Config'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
    patch:
      description: Updates the Config.
      operationId: speech.projects.locations.config.update
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/Config'
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Config'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: query
          name: updateMask
          schema:
            type: string
            format: google-fieldmask
  /v2/projects/{projectsId}/locations/{locationsId}/customClasses:
    parameters: *ref_1
    post:
      description: Creates a CustomClass.
      operationId: speech.projects.locations.customClasses.create
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CustomClass'
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: query
          name: validateOnly
          schema:
            type: boolean
        - in: query
          name: customClassId
          schema:
            type: string
    get:
      description: Lists CustomClasses.
      operationId: speech.projects.locations.customClasses.list
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListCustomClassesResponse'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: query
          name: pageSize
          schema:
            type: integer
            format: int32
        - in: query
          name: pageToken
          schema:
            type: string
        - in: query
          name: showDeleted
          schema:
            type: boolean
  /v2/projects/{projectsId}/locations/{locationsId}/customClasses/{customClassesId}:
    parameters: *ref_1
    get:
      description: Returns the requested CustomClass.
      operationId: speech.projects.locations.customClasses.get
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CustomClass'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: path
          name: customClassesId
          required: true
          schema:
            type: string
    patch:
      description: Updates the CustomClass.
      operationId: speech.projects.locations.customClasses.patch
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CustomClass'
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: path
          name: customClassesId
          required: true
          schema:
            type: string
        - in: query
          name: updateMask
          schema:
            type: string
            format: google-fieldmask
        - in: query
          name: validateOnly
          schema:
            type: boolean
    delete:
      description: Deletes the CustomClass.
      operationId: speech.projects.locations.customClasses.delete
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: path
          name: customClassesId
          required: true
          schema:
            type: string
        - in: query
          name: validateOnly
          schema:
            type: boolean
        - in: query
          name: allowMissing
          schema:
            type: boolean
        - in: query
          name: etag
          schema:
            type: string
  /v2/projects/{projectsId}/locations/{locationsId}/customClasses/{customClassesId}:undelete:
    parameters: *ref_1
    post:
      description: Undeletes the CustomClass.
      operationId: speech.projects.locations.customClasses.undelete
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UndeleteCustomClassRequest'
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: path
          name: customClassesId
          required: true
          schema:
            type: string
  /v2/projects/{projectsId}/locations/{locationsId}/phraseSets:
    parameters: *ref_1
    post:
      description: Creates a PhraseSet.
      operationId: speech.projects.locations.phraseSets.create
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/PhraseSet'
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: query
          name: validateOnly
          schema:
            type: boolean
        - in: query
          name: phraseSetId
          schema:
            type: string
    get:
      description: Lists PhraseSets.
      operationId: speech.projects.locations.phraseSets.list
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListPhraseSetsResponse'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: query
          name: pageSize
          schema:
            type: integer
            format: int32
        - in: query
          name: pageToken
          schema:
            type: string
        - in: query
          name: showDeleted
          schema:
            type: boolean
  /v2/projects/{projectsId}/locations/{locationsId}/phraseSets/{phraseSetsId}:
    parameters: *ref_1
    get:
      description: Returns the requested PhraseSet.
      operationId: speech.projects.locations.phraseSets.get
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/PhraseSet'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: path
          name: phraseSetsId
          required: true
          schema:
            type: string
    patch:
      description: Updates the PhraseSet.
      operationId: speech.projects.locations.phraseSets.patch
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/PhraseSet'
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: path
          name: phraseSetsId
          required: true
          schema:
            type: string
        - in: query
          name: updateMask
          schema:
            type: string
            format: google-fieldmask
        - in: query
          name: validateOnly
          schema:
            type: boolean
    delete:
      description: Deletes the PhraseSet.
      operationId: speech.projects.locations.phraseSets.delete
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: path
          name: phraseSetsId
          required: true
          schema:
            type: string
        - in: query
          name: validateOnly
          schema:
            type: boolean
        - in: query
          name: allowMissing
          schema:
            type: boolean
        - in: query
          name: etag
          schema:
            type: string
  /v2/projects/{projectsId}/locations/{locationsId}/phraseSets/{phraseSetsId}:undelete:
    parameters: *ref_1
    post:
      description: Undeletes the PhraseSet.
      operationId: speech.projects.locations.phraseSets.undelete
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UndeletePhraseSetRequest'
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      parameters:
        - in: path
          name: projectsId
          required: true
          schema:
            type: string
        - in: path
          name: locationsId
          required: true
          schema:
            type: string
        - in: path
          name: phraseSetsId
          required: true
          schema:
            type: string
