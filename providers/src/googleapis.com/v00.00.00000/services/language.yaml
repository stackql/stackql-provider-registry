openapi: 3.1.0
info:
  contact:
    name: StackQL Studios
    url: https://github.com/stackql/google-discovery-to-openapi
    email: info@stackql.io
  title: Cloud Natural Language API
  description: >-
    Provides natural language understanding technologies, such as sentiment
    analysis, entity recognition, entity sentiment analysis, and other text
    annotations, to developers.
  version: v2
  x-discovery-doc-revision: '20251207'
  x-generated-date: '2025-12-10'
externalDocs:
  url: https://cloud.google.com/natural-language/
servers:
  - url: https://language.googleapis.com
components:
  securitySchemes:
    Oauth2:
      type: oauth2
      description: Oauth 2.0 implicit authentication
      flows:
        implicit:
          authorizationUrl: https://accounts.google.com/o/oauth2/auth
          scopes: &ref_0
            https://www.googleapis.com/auth/cloud-platform: >-
              See, edit, configure, and delete your Google Cloud data and see
              the email address for your Google Account.
            https://www.googleapis.com/auth/cloud-language: >-
              Apply machine learning models to reveal the structure and meaning
              of text
    Oauth2c:
      type: oauth2
      description: Oauth 2.0 authorization code authentication
      flows:
        authorizationCode:
          authorizationUrl: https://accounts.google.com/o/oauth2/auth
          tokenUrl: https://accounts.google.com/o/oauth2/token
          scopes: *ref_0
  schemas:
    XPSFloat64StatsHistogramBucket:
      description: A bucket of a histogram.
      type: object
      id: XPSFloat64StatsHistogramBucket
      properties:
        min:
          description: The minimum value of the bucket, inclusive.
          format: double
          type: number
        count:
          format: int64
          description: >-
            The number of data values that are in the bucket, i.e. are between
            min and max values.
          type: string
        max:
          format: double
          description: >-
            The maximum value of the bucket, exclusive unless max =
            `"Infinity"`, in which case it's inclusive.
          type: number
    XPSResponseExplanationMetadataOutputMetadata:
      properties:
        outputTensorName:
          description: Name of the output tensor. Only needed in train response.
          type: string
      description: Metadata of the prediction output to be explained.
      id: XPSResponseExplanationMetadataOutputMetadata
      type: object
    XPSPreprocessResponse:
      properties:
        tablesPreprocessResponse:
          $ref: '#/components/schemas/XPSTablesPreprocessResponse'
        translationPreprocessResp:
          $ref: '#/components/schemas/XPSTranslationPreprocessResponse'
        speechPreprocessResp:
          $ref: '#/components/schemas/XPSSpeechPreprocessResponse'
        outputExampleSet:
          description: >-
            Preprocessed examples, that are to be imported into AutoML storage.
            This should point to RecordIO file(s) of PreprocessedExample
            messages. The PreprocessedExample.mvp_training_data-s returned here
            are later verbatim passed to Train() call in
            TrainExample.mvp_training_data.
          $ref: '#/components/schemas/XPSExampleSet'
      id: XPSPreprocessResponse
      type: object
    XPSTablesClassificationMetricsCurveMetrics:
      properties:
        value:
          type: string
          description: >-
            The CATEGORY row value (for ARRAY unnested) the curve metrics are
            for.
        aucRoc:
          description: The area under receiver operating characteristic curve.
          type: number
          format: double
        confidenceMetricsEntries:
          description: >-
            Metrics that have confidence thresholds. Precision-recall curve and
            ROC curve can be derived from them.
          type: array
          items:
            $ref: '#/components/schemas/XPSTablesConfidenceMetricsEntry'
        logLoss:
          format: double
          type: number
          description: The Log loss metric.
        aucPr:
          description: The area under the precision-recall curve.
          format: double
          type: number
        positionThreshold:
          format: int32
          description: The position threshold value used to compute the metrics.
          type: integer
      id: XPSTablesClassificationMetricsCurveMetrics
      description: Metrics curve data point for a single value.
      type: object
    XPSVideoActionRecognitionTrainResponse:
      properties:
        modelArtifactSpec:
          $ref: '#/components/schemas/XPSVideoModelArtifactSpec'
          description: '## The fields below are only populated under uCAIP request scope.'
        trainCostNodeSeconds:
          type: string
          format: int64
          description: >-
            The actual train cost of creating this model, expressed in node
            seconds, i.e. 3,600 value in this field means 1 node hour.
      type: object
      id: XPSVideoActionRecognitionTrainResponse
    Sentiment:
      properties:
        score:
          type: number
          description: >-
            Sentiment score between -1.0 (negative sentiment) and 1.0 (positive
            sentiment).
          format: float
        magnitude:
          description: >-
            A non-negative number in the [0, +inf] range, which represents the
            absolute magnitude of sentiment regardless of score (positive or
            negative).
          type: number
          format: float
      type: object
      id: Sentiment
      description: >-
        Represents the feeling associated with the entire text or entities in
        the text.
    AnalyzeSentimentRequest:
      description: The sentiment analysis request message.
      type: object
      id: AnalyzeSentimentRequest
      properties:
        encodingType:
          description: The encoding type used by the API to calculate sentence offsets.
          enumDescriptions:
            - >-
              If `EncodingType` is not specified, encoding-dependent information
              (such as `begin_offset`) will be set at `-1`.
            - >-
              Encoding-dependent information (such as `begin_offset`) is
              calculated based on the UTF-8 encoding of the input. C++ and Go
              are examples of languages that use this encoding natively.
            - >-
              Encoding-dependent information (such as `begin_offset`) is
              calculated based on the UTF-16 encoding of the input. Java and
              JavaScript are examples of languages that use this encoding
              natively.
            - >-
              Encoding-dependent information (such as `begin_offset`) is
              calculated based on the UTF-32 encoding of the input. Python is an
              example of a language that uses this encoding natively.
          enum:
            - NONE
            - UTF8
            - UTF16
            - UTF32
          type: string
        document:
          $ref: '#/components/schemas/Document'
          description: Required. Input document.
    XPSSpeechPreprocessStats:
      id: XPSSpeechPreprocessStats
      properties:
        testSentencesCount:
          format: int32
          description: The number of sentences in the test data set.
          type: integer
        dataErrors:
          description: Different types of data errors and the counts associated with them.
          items:
            $ref: '#/components/schemas/XPSDataErrors'
          type: array
        trainWordsCount:
          type: integer
          description: The number of words in the training data set.
          format: int32
        trainSentencesCount:
          type: integer
          description: The number of sentences in the training data set.
          format: int32
        testExamplesCount:
          type: integer
          description: The number of examples labelled as TEST by Speech xps server.
          format: int32
        numMachineTranscribedExamples:
          type: integer
          format: int32
          description: The number of rows marked as MACHINE_TRANSCRIBED
        numLogsExamples:
          type: integer
          format: int32
          description: The number of samples found in the previously recorded logs data.
        testWordsCount:
          type: integer
          description: The number of words in the test data set.
          format: int32
        numHumanLabeledExamples:
          description: The number of rows marked HUMAN_LABELLED
          format: int32
          type: integer
        trainExamplesCount:
          description: The number of examples labeled as TRAIN by Speech xps server.
          format: int32
          type: integer
      type: object
    XPSVideoObjectTrackingTrainResponse:
      type: object
      properties:
        modelArtifactSpec:
          $ref: '#/components/schemas/XPSVideoModelArtifactSpec'
          description: '## The fields below are only populated under uCAIP request scope.'
        trainCostNodeSeconds:
          format: int64
          description: >-
            The actual train cost of creating this model, expressed in node
            seconds, i.e. 3,600 value in this field means 1 node hour.
          type: string
        exportModelSpec:
          description: Populated for AutoML request only.
          $ref: '#/components/schemas/XPSVideoExportModelSpec'
      id: XPSVideoObjectTrackingTrainResponse
    XPSTfLiteFormat:
      type: object
      description: >-
        LINT.IfChange A model format used for mobile and IoT devices. See
        https://www.tensorflow.org/lite.
      id: XPSTfLiteFormat
      properties: {}
    XPSConfusionMatrixRow:
      type: object
      id: XPSConfusionMatrixRow
      properties:
        exampleCount:
          items:
            type: integer
            format: int32
          description: >-
            Value of the specific cell in the confusion matrix. The number of
            values each row has (i.e. the length of the row) is equal to the
            length of the annotation_spec_id_token field.
          type: array
        count:
          items:
            type: string
            format: int64
          type: array
          description: >-
            Same as above except intended to represent other counts (for e.g.
            for segmentation this is pixel count). NOTE(params): Only
            example_count or count is set (oneoff does not support repeated
            fields unless they are embedded inside another message).
      description: A row in the confusion matrix.
    Sentence:
      id: Sentence
      properties:
        text:
          description: The sentence text.
          $ref: '#/components/schemas/TextSpan'
        sentiment:
          $ref: '#/components/schemas/Sentiment'
          description: >-
            For calls to AnalyzeSentiment or if
            AnnotateTextRequest.Features.extract_document_sentiment is set to
            true, this field will contain the sentiment for the sentence.
      description: Represents a sentence in the input document.
      type: object
    XPSSpeechEvaluationMetrics:
      type: object
      id: XPSSpeechEvaluationMetrics
      properties:
        subModelEvaluationMetrics:
          type: array
          description: Evaluation metrics for all submodels contained in this model.
          items:
            $ref: >-
              #/components/schemas/XPSSpeechEvaluationMetricsSubModelEvaluationMetric
    XPSReportingMetrics:
      properties:
        metricEntries:
          items:
            $ref: '#/components/schemas/XPSMetricEntry'
          description: >-
            One entry per metric name. The values must be aggregated per metric
            name.
          type: array
        effectiveTrainingDuration:
          format: google-duration
          description: >-
            The effective time training used. If set, this is used for quota
            management and billing. Deprecated. AutoML BE doesn't use this.
            Don't set.
          deprecated: true
          type: string
      type: object
      id: XPSReportingMetrics
    XPSXpsOperationMetadata:
      properties:
        videoBatchPredictOperationMetadata:
          $ref: '#/components/schemas/XPSVideoBatchPredictOperationMetadata'
        videoTrainingOperationMetadata:
          $ref: '#/components/schemas/XPSVideoTrainingOperationMetadata'
        tablesTrainingOperationMetadata:
          $ref: '#/components/schemas/XPSTablesTrainingOperationMetadata'
        exampleCount:
          format: int64
          type: string
          description: >-
            Optional. XPS server can opt to provide example count of the long
            running operation (e.g. training, data importing, batch prediction).
        visionTrainingOperationMetadata:
          $ref: '#/components/schemas/XPSVisionTrainingOperationMetadata'
        reportingMetrics:
          description: >-
            Metrics for the operation. By the time the operation is terminated
            (whether succeeded or failed) as returned from XPS, AutoML BE
            assumes the metrics are finalized. AutoML BE transparently posts the
            metrics to Chemist if it's not empty, regardless of the response
            content or error type. If user is supposed to be charged in case of
            cancellation/error, this field should be set. In the case where the
            type of LRO doesn't require any billing, this field should be left
            unset.
          $ref: '#/components/schemas/XPSReportingMetrics'
      id: XPSXpsOperationMetadata
      type: object
    XPSVideoActionMetricsEntryConfidenceMetricsEntry:
      properties:
        precision:
          format: float
          type: number
          description: Output only. Precision for the given confidence threshold.
        f1Score:
          format: float
          description: Output only. The harmonic mean of recall and precision.
          type: number
        confidenceThreshold:
          type: number
          format: float
          description: >-
            Output only. The confidence threshold value used to compute the
            metrics.
        recall:
          type: number
          description: Output only. Recall for the given confidence threshold.
          format: float
      id: XPSVideoActionMetricsEntryConfidenceMetricsEntry
      description: Metrics for a single confidence threshold.
      type: object
    XPSMetricEntryLabel:
      type: object
      id: XPSMetricEntryLabel
      properties:
        labelName:
          type: string
          description: The name of the label.
        labelValue:
          description: The value of the label.
          type: string
    XPSImageSegmentationEvaluationMetrics:
      type: object
      properties:
        confidenceMetricsEntries:
          items:
            $ref: >-
              #/components/schemas/XPSImageSegmentationEvaluationMetricsConfidenceMetricsEntry
          description: >-
            Metrics that have confidence thresholds. Precision-recall curve can
            be derived from it.
          type: array
      description: 'Model evaluation metrics for image segmentation problems. Next tag: 4.'
      id: XPSImageSegmentationEvaluationMetrics
    XPSTableSpec:
      type: object
      properties:
        validRowCount:
          format: int64
          description: The number of valid rows.
          type: string
        columnSpecs:
          type: object
          additionalProperties:
            $ref: '#/components/schemas/XPSColumnSpec'
          description: Mapping from column id to column spec.
        timeColumnId:
          description: The id of the time column.
          format: int32
          type: integer
        rowCount:
          format: int64
          type: string
          description: The number of rows in the table.
        importedDataSizeInBytes:
          format: int64
          type: string
          description: The total size of imported data of the table.
      id: XPSTableSpec
    XPSVideoModelArtifactSpec:
      id: XPSVideoModelArtifactSpec
      type: object
      properties:
        servingArtifact:
          $ref: '#/components/schemas/XPSModelArtifactItem'
          description: >-
            The default model binary file used for serving (e.g. batch predict)
            via public Cloud AI Platform API.
        exportArtifact:
          type: array
          description: The model binary files in different formats for model export.
          items:
            $ref: '#/components/schemas/XPSModelArtifactItem'
    XPSTfSavedModelFormat:
      description: A tensorflow model format in SavedModel format.
      id: XPSTfSavedModelFormat
      type: object
      properties: {}
    XPSVideoActionRecognitionEvaluationMetrics:
      type: object
      id: XPSVideoActionRecognitionEvaluationMetrics
      properties:
        videoActionMetricsEntries:
          description: >-
            Output only. The metric entries for precision window lengths:
            1s,2s,3s,4s, 5s.
          type: array
          items:
            $ref: '#/components/schemas/XPSVideoActionMetricsEntry'
        evaluatedActionCount:
          format: int32
          type: integer
          description: >-
            Output only. The number of ground truth actions used to create this
            evaluation.
      description: Model evaluation metrics for video action recognition.
    XPSDockerFormat:
      description: >-
        A model format used for Docker containers. Use the params field to
        customize the container. The container is verified to work correctly on
        ubuntu 16.04 operating system.
      id: XPSDockerFormat
      type: object
      properties:
        gpuArchitecture:
          description: >-
            Optional. Additional gpu information describing the requirements for
            the to be exported model files.
          enum:
            - GPU_ARCHITECTURE_UNSPECIFIED
            - GPU_ARCHITECTURE_NVIDIA
          enumDescriptions:
            - ''
            - ''
          type: string
        cpuArchitecture:
          enumDescriptions:
            - ''
            - ''
          enum:
            - CPU_ARCHITECTURE_UNSPECIFIED
            - CPU_ARCHITECTURE_X86_64
          type: string
          description: >-
            Optional. Additional cpu information describing the requirements for
            the to be exported model files.
    XPSXraiAttribution:
      properties:
        stepCount:
          type: integer
          description: >-
            The number of steps for approximating the path integral. A good
            value to start is 50 and gradually increase until the sum to diff
            property is met within the desired error range. Valid range of its
            value is [1, 100], inclusively.
          format: int32
      type: object
      deprecated: true
      description: >-
        An explanation method that redistributes Integrated Gradients
        attributions to segmented regions, taking advantage of the model's fully
        differentiable structure. Refer to this paper for more details:
        https://arxiv.org/abs/1906.02825 Only supports image Models (modality is
        IMAGE).
      id: XPSXraiAttribution
    XPSTablesConfidenceMetricsEntry:
      id: XPSTablesConfidenceMetricsEntry
      properties:
        falsePositiveCount:
          type: string
          format: int64
          description: False positive count.
        trueNegativeCount:
          format: int64
          description: True negative count.
          type: string
        falseNegativeCount:
          description: False negative count.
          type: string
          format: int64
        falsePositiveRate:
          type: number
          description: 'FPR = #false positives / (#false positives + #true negatives)'
          format: double
        confidenceThreshold:
          format: double
          description: The confidence threshold value used to compute the metrics.
          type: number
        truePositiveCount:
          format: int64
          type: string
          description: True positive count.
        recall:
          format: double
          description: 'Recall = #true positives / (#true positives + #false negatives).'
          type: number
        truePositiveRate:
          type: number
          format: double
          description: 'TPR = #true positives / (#true positives + #false negatvies)'
        f1Score:
          description: >-
            The harmonic mean of recall and precision. (2 * precision * recall)
            / (precision + recall)
          type: number
          format: double
        precision:
          format: double
          type: number
          description: 'Precision = #true positives / (#true positives + #false positives).'
      description: Metrics for a single confidence threshold.
      type: object
    XPSVisionTrainingOperationMetadata:
      properties:
        explanationUsage:
          $ref: '#/components/schemas/InfraUsage'
          description: >-
            Aggregated infra usage within certain time period, for billing
            report purpose if XAI is enable in training request.
      id: XPSVisionTrainingOperationMetadata
      type: object
      deprecated: true
    XPSTrackMetricsEntry:
      id: XPSTrackMetricsEntry
      properties:
        meanMismatchRate:
          format: float
          type: number
          description: Output only. The mean mismatch rate over all confidence thresholds.
        iouThreshold:
          format: float
          description: >-
            Output only. The intersection-over-union threshold value between
            bounding boxes across frames used to compute this metric entry.
          type: number
        confidenceMetricsEntries:
          type: array
          description: >-
            Output only. Metrics for each label-match confidence_threshold from
            0.05,0.10,...,0.95,0.96,0.97,0.98,0.99. Precision-recall curve is
            derived from them.
          items:
            $ref: '#/components/schemas/XPSTrackMetricsEntryConfidenceMetricsEntry'
        meanBoundingBoxIou:
          description: >-
            Output only. The mean bounding box iou over all confidence
            thresholds.
          format: float
          type: number
        meanTrackingAveragePrecision:
          type: number
          description: >-
            Output only. The mean average precision over all confidence
            thresholds.
          format: float
      description: >-
        Track matching model metrics for a single track match threshold and
        multiple label match confidence thresholds. Next tag: 6.
      type: object
    XPSTfJsFormat:
      type: object
      description: >-
        A [TensorFlow.js](https://www.tensorflow.org/js) model that can be used
        in the browser and in Node.js using JavaScript.
      id: XPSTfJsFormat
      properties: {}
    XPSIntegratedGradientsAttribution:
      type: object
      deprecated: true
      id: XPSIntegratedGradientsAttribution
      description: >-
        An attribution method that computes the Aumann-Shapley value taking
        advantage of the model's fully differentiable structure. Refer to this
        paper for more details: https://arxiv.org/abs/1703.01365
      properties:
        stepCount:
          format: int32
          type: integer
          description: >-
            The number of steps for approximating the path integral. A good
            value to start is 50 and gradually increase until the sum to diff
            property is within the desired error range. Valid range of its value
            is [1, 100], inclusively.
    XPSCorrelationStats:
      type: object
      id: XPSCorrelationStats
      properties:
        cramersV:
          format: double
          type: number
          description: The correlation value using the Cramer's V measure.
      description: >-
        A correlation statistics between two series of DataType values. The
        series may have differing DataType-s, but within a single series the
        DataType must be the same.
    CpuMetric:
      type: object
      description: Metric for billing reports.
      id: CpuMetric
      properties:
        coreNumber:
          description: Required. Number of CPU cores.
          format: int64
          type: string
        coreSec:
          type: string
          description: Required. Total seconds of core usage, e.g. 4.
          format: int64
        trackingLabels:
          type: object
          description: >-
            Billing tracking labels. They do not contain any user data but only
            the labels set by Vertex Core Infra itself. Tracking labels' keys
            are defined with special format: goog-[\p{Ll}\p{N}]+ E.g. "key":
            "goog-k8s-cluster-name","value": "us-east1-b4rk"
          additionalProperties:
            type: string
        machineSpec:
          type: string
          enum:
            - UNKNOWN_MACHINE_SPEC
            - N1_STANDARD_2
            - N1_STANDARD_4
            - N1_STANDARD_8
            - N1_STANDARD_16
            - N1_STANDARD_32
            - N1_STANDARD_64
            - N1_STANDARD_96
            - N1_HIGHMEM_2
            - N1_HIGHMEM_4
            - N1_HIGHMEM_8
            - N1_HIGHMEM_16
            - N1_HIGHMEM_32
            - N1_HIGHMEM_64
            - N1_HIGHMEM_96
            - N1_HIGHCPU_2
            - N1_HIGHCPU_4
            - N1_HIGHCPU_8
            - N1_HIGHCPU_16
            - N1_HIGHCPU_32
            - N1_HIGHCPU_64
            - N1_HIGHCPU_96
            - A2_HIGHGPU_1G
            - A2_HIGHGPU_2G
            - A2_HIGHGPU_4G
            - A2_HIGHGPU_8G
            - A2_MEGAGPU_16G
            - A2_ULTRAGPU_1G
            - A2_ULTRAGPU_2G
            - A2_ULTRAGPU_4G
            - A2_ULTRAGPU_8G
            - A3_HIGHGPU_1G
            - A3_HIGHGPU_2G
            - A3_HIGHGPU_4G
            - A3_HIGHGPU_8G
            - A3_MEGAGPU_8G
            - A3_ULTRAGPU_8G
            - A3_EDGEGPU_8G
            - A4_HIGHGPU_8G
            - A4X_HIGHGPU_4G
            - E2_STANDARD_2
            - E2_STANDARD_4
            - E2_STANDARD_8
            - E2_STANDARD_16
            - E2_STANDARD_32
            - E2_HIGHMEM_2
            - E2_HIGHMEM_4
            - E2_HIGHMEM_8
            - E2_HIGHMEM_16
            - E2_HIGHCPU_2
            - E2_HIGHCPU_4
            - E2_HIGHCPU_8
            - E2_HIGHCPU_16
            - E2_HIGHCPU_32
            - N2_STANDARD_2
            - N2_STANDARD_4
            - N2_STANDARD_8
            - N2_STANDARD_16
            - N2_STANDARD_32
            - N2_STANDARD_48
            - N2_STANDARD_64
            - N2_STANDARD_80
            - N2_STANDARD_96
            - N2_STANDARD_128
            - N2_HIGHMEM_2
            - N2_HIGHMEM_4
            - N2_HIGHMEM_8
            - N2_HIGHMEM_16
            - N2_HIGHMEM_32
            - N2_HIGHMEM_48
            - N2_HIGHMEM_64
            - N2_HIGHMEM_80
            - N2_HIGHMEM_96
            - N2_HIGHMEM_128
            - N2_HIGHCPU_2
            - N2_HIGHCPU_4
            - N2_HIGHCPU_8
            - N2_HIGHCPU_16
            - N2_HIGHCPU_32
            - N2_HIGHCPU_48
            - N2_HIGHCPU_64
            - N2_HIGHCPU_80
            - N2_HIGHCPU_96
            - N2D_STANDARD_2
            - N2D_STANDARD_4
            - N2D_STANDARD_8
            - N2D_STANDARD_16
            - N2D_STANDARD_32
            - N2D_STANDARD_48
            - N2D_STANDARD_64
            - N2D_STANDARD_80
            - N2D_STANDARD_96
            - N2D_STANDARD_128
            - N2D_STANDARD_224
            - N2D_HIGHMEM_2
            - N2D_HIGHMEM_4
            - N2D_HIGHMEM_8
            - N2D_HIGHMEM_16
            - N2D_HIGHMEM_32
            - N2D_HIGHMEM_48
            - N2D_HIGHMEM_64
            - N2D_HIGHMEM_80
            - N2D_HIGHMEM_96
            - N2D_HIGHCPU_2
            - N2D_HIGHCPU_4
            - N2D_HIGHCPU_8
            - N2D_HIGHCPU_16
            - N2D_HIGHCPU_32
            - N2D_HIGHCPU_48
            - N2D_HIGHCPU_64
            - N2D_HIGHCPU_80
            - N2D_HIGHCPU_96
            - N2D_HIGHCPU_128
            - N2D_HIGHCPU_224
            - C2_STANDARD_4
            - C2_STANDARD_8
            - C2_STANDARD_16
            - C2_STANDARD_30
            - C2_STANDARD_60
            - C2D_STANDARD_2
            - C2D_STANDARD_4
            - C2D_STANDARD_8
            - C2D_STANDARD_16
            - C2D_STANDARD_32
            - C2D_STANDARD_56
            - C2D_STANDARD_112
            - C2D_HIGHCPU_2
            - C2D_HIGHCPU_4
            - C2D_HIGHCPU_8
            - C2D_HIGHCPU_16
            - C2D_HIGHCPU_32
            - C2D_HIGHCPU_56
            - C2D_HIGHCPU_112
            - C2D_HIGHMEM_2
            - C2D_HIGHMEM_4
            - C2D_HIGHMEM_8
            - C2D_HIGHMEM_16
            - C2D_HIGHMEM_32
            - C2D_HIGHMEM_56
            - C2D_HIGHMEM_112
            - G2_STANDARD_4
            - G2_STANDARD_8
            - G2_STANDARD_12
            - G2_STANDARD_16
            - G2_STANDARD_24
            - G2_STANDARD_32
            - G2_STANDARD_48
            - G2_STANDARD_96
            - G4_STANDARD_48
            - C3_STANDARD_4
            - C3_STANDARD_8
            - C3_STANDARD_22
            - C3_STANDARD_44
            - C3_STANDARD_88
            - C3_STANDARD_176
            - C3_HIGHCPU_4
            - C3_HIGHCPU_8
            - C3_HIGHCPU_22
            - C3_HIGHCPU_44
            - C3_HIGHCPU_88
            - C3_HIGHCPU_176
            - C3_HIGHMEM_4
            - C3_HIGHMEM_8
            - C3_HIGHMEM_22
            - C3_HIGHMEM_44
            - C3_HIGHMEM_88
            - C3_HIGHMEM_176
            - C4_STANDARD_8
            - C4_STANDARD_16
            - C4_STANDARD_24
            - C4_STANDARD_32
            - C4_STANDARD_48
            - C4_STANDARD_96
            - C4_STANDARD_144
            - C4_STANDARD_192
            - C4_STANDARD_288
            - C4_HIGHCPU_8
            - C4_HIGHCPU_16
            - C4_HIGHCPU_24
            - C4_HIGHCPU_32
            - C4_HIGHCPU_48
            - C4_HIGHCPU_96
            - C4_HIGHCPU_144
            - C4_HIGHCPU_192
            - C4_HIGHCPU_288
            - C4_HIGHMEM_8
            - C4_HIGHMEM_16
            - C4_HIGHMEM_24
            - C4_HIGHMEM_32
            - C4_HIGHMEM_48
            - C4_HIGHMEM_96
            - C4_HIGHMEM_144
            - C4_HIGHMEM_192
            - C4_HIGHMEM_288
          enumDescriptions:
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
          description: Required. Machine spec, e.g. N1_STANDARD_4.
        cpuType:
          enum:
            - UNKNOWN_CPU_TYPE
            - A2
            - A3
            - A4
            - A4X
            - C2
            - C2D
            - CUSTOM
            - E2
            - G2
            - G4
            - C3
            - C4
            - M2
            - M1
            - N1
            - N2_CUSTOM
            - N2
            - N2D
          type: string
          description: Required. Type of cpu, e.g. N2.
          enumDescriptions:
            - ''
            - GPU-based machine, skip quota reporting.
            - GPU-based machine, skip quota reporting.
            - GPU-based machine, skip quota reporting.
            - GPU-based machine, skip quota reporting.
            - COMPUTE_OPTIMIZED
            - ''
            - ''
            - ''
            - GPU-based machine, skip quota reporting.
            - GPU-based machine, skip quota reporting.
            - ''
            - ''
            - MEMORY_OPTIMIZED_UPGRADE_PREMIUM
            - MEMORY_OPTIMIZED
            - ''
            - ''
            - ''
            - ''
    XPSTablesModelStructureModelParameters:
      properties:
        hyperparameters:
          items:
            $ref: >-
              #/components/schemas/XPSTablesModelStructureModelParametersParameter
          type: array
      description: Model hyper-parameters for a model.
      id: XPSTablesModelStructureModelParameters
      type: object
    XPSImageObjectDetectionModelSpec:
      properties:
        classCount:
          description: Total number of classes.
          type: string
          format: int64
        trainCostNodeSeconds:
          type: string
          description: >-
            The actual train cost of creating this model, expressed in node
            seconds, i.e. 3,600 value in this field means 1 node hour.
          format: int64
        stopReason:
          description: >-
            Stop reason for training job, e.g. 'TRAIN_BUDGET_REACHED',
            'MODEL_CONVERGED'.
          enumDescriptions:
            - ''
            - ''
            - Model fully converged, can not be resumbed training.
            - >-
              Model early converged, can be further trained till full
              convergency.
          enum:
            - TRAIN_STOP_REASON_UNSPECIFIED
            - TRAIN_STOP_REASON_BUDGET_REACHED
            - TRAIN_STOP_REASON_MODEL_CONVERGED
            - TRAIN_STOP_REASON_MODEL_EARLY_STOPPED
          type: string
        exportModelSpec:
          $ref: '#/components/schemas/XPSImageExportModelSpec'
        maxBoundingBoxCount:
          type: string
          description: Max number of bounding box.
          format: int64
        modelArtifactSpec:
          $ref: '#/components/schemas/XPSImageModelArtifactSpec'
          description: '## The fields below are only populated under uCAIP request scope.'
        modelServingSpec:
          $ref: '#/components/schemas/XPSImageModelServingSpec'
      id: XPSImageObjectDetectionModelSpec
      type: object
    XPSTablesPreprocessResponse:
      properties:
        tablesDatasetMetadata:
          description: >-
            The table/column id, column_name and the DataTypes of the columns
            will be populated.
          $ref: '#/components/schemas/XPSTablesDatasetMetadata'
      id: XPSTablesPreprocessResponse
      type: object
    XPSEvaluationMetrics:
      description: >-
        Contains xPS-specific model evaluation metrics either for a single
        annotation spec (label), or for the model overall. Next tag: 18.
      properties:
        textClassificationEvalMetrics:
          $ref: '#/components/schemas/XPSClassificationEvaluationMetrics'
        regressionEvalMetrics:
          $ref: '#/components/schemas/XPSRegressionEvaluationMetrics'
        textSentimentEvalMetrics:
          $ref: '#/components/schemas/XPSTextSentimentEvaluationMetrics'
        annotationSpecIdToken:
          type: string
          description: >-
            The annotation_spec for which this evaluation metrics instance had
            been created. Empty iff this is an overall model evaluation (like
            Tables evaluation metrics), i.e. aggregated across all labels. The
            value comes from the input annotations in AnnotatedExample. For MVP
            product or for text sentiment models where annotation_spec_id_token
            is not available, set label instead.
        evaluatedExampleCount:
          description: >-
            The number of examples used to create this evaluation metrics
            instance.
          format: int32
          type: integer
        videoActionRecognitionEvalMetrics:
          $ref: '#/components/schemas/XPSVideoActionRecognitionEvaluationMetrics'
        translationEvalMetrics:
          $ref: '#/components/schemas/XPSTranslationEvaluationMetrics'
        textExtractionEvalMetrics:
          $ref: '#/components/schemas/XPSTextExtractionEvaluationMetrics'
        videoObjectTrackingEvalMetrics:
          $ref: '#/components/schemas/XPSVideoObjectTrackingEvaluationMetrics'
        category:
          format: int32
          description: >-
            The integer category label for which this evaluation metric instance
            had been created. Valid categories are 0 or higher. Overall model
            evaluation should set this to negative values (rather than implicit
            zero). Only used for Image Segmentation (prefer to set
            annotation_spec_id_token instead). Note: uCAIP Image Segmentation
            should use annotation_spec_id_token.
          type: integer
        imageSegmentationEvalMetrics:
          $ref: '#/components/schemas/XPSImageSegmentationEvaluationMetrics'
        tablesEvalMetrics:
          $ref: '#/components/schemas/XPSTablesEvaluationMetrics'
        imageObjectDetectionEvalMetrics:
          $ref: '#/components/schemas/XPSImageObjectDetectionEvaluationMetrics'
        imageClassificationEvalMetrics:
          $ref: '#/components/schemas/XPSClassificationEvaluationMetrics'
        tablesClassificationEvalMetrics:
          $ref: '#/components/schemas/XPSClassificationEvaluationMetrics'
        label:
          description: >-
            The label for which this evaluation metrics instance had been
            created. Empty iff this is an overall model evaluation (like Tables
            evaluation metrics), i.e. aggregated across all labels. The label
            maps to AnnotationSpec.display_name in Public API protos. Only used
            by MVP implementation and text sentiment FULL implementation.
          type: string
        videoClassificationEvalMetrics:
          $ref: '#/components/schemas/XPSClassificationEvaluationMetrics'
      id: XPSEvaluationMetrics
      type: object
    XPSSpeechEvaluationMetricsSubModelEvaluationMetric:
      type: object
      id: XPSSpeechEvaluationMetricsSubModelEvaluationMetric
      properties:
        numSubstitutions:
          type: integer
          format: int32
        numInsertions:
          format: int32
          type: integer
        isEnhancedModel:
          description: >-
            If true then it means we have an enhanced version of the biasing
            models.
          type: boolean
        wer:
          description: Word error rate (standard error metric used for speech recognition).
          type: number
          format: double
        sentenceAccuracy:
          description: Below fields are used for debugging purposes
          format: double
          type: number
        numWords:
          format: int32
          type: integer
          description: Number of words over which the word error rate was computed.
        numDeletions:
          format: int32
          type: integer
        numUtterances:
          format: int32
          description: Number of utterances used in the wer computation.
          type: integer
        biasingModelType:
          description: Type of the biasing model.
          type: string
          enum:
            - BIASING_MODEL_TYPE_UNSPECIFIED
            - COMMAND_AND_SEARCH
            - PHONE_CALL
            - VIDEO
            - DEFAULT
          enumDescriptions:
            - ''
            - Build biasing model on top of COMMAND_AND_SEARCH model
            - Build biasing model on top of PHONE_CALL model
            - Build biasing model on top of VIDEO model
            - Build biasing model on top of DEFAULT model
    XPSCoreMlFormat:
      type: object
      properties: {}
      id: XPSCoreMlFormat
      description: A model format used for iOS mobile devices.
    XPSFloat64Stats:
      properties:
        histogramBuckets:
          items:
            $ref: '#/components/schemas/XPSFloat64StatsHistogramBucket'
          description: >-
            Histogram buckets of the data series. Sorted by the min value of the
            bucket, ascendingly, and the number of the buckets is dynamically
            generated. The buckets are non-overlapping and completely cover
            whole FLOAT64 range with min of first bucket being `"-Infinity"`,
            and max of the last one being `"Infinity"`.
          type: array
        commonStats:
          $ref: '#/components/schemas/XPSCommonStats'
        standardDeviation:
          description: The standard deviation of the series.
          type: number
          format: double
        quantiles:
          description: >-
            Ordered from 0 to k k-quantile values of the data series of n
            values. The value at index i is, approximately, the i*n/k-th
            smallest value in the series; for i = 0 and i = k these are,
            respectively, the min and max values.
          items:
            type: number
            format: double
          type: array
        mean:
          format: double
          description: The mean of the series.
          type: number
      type: object
      id: XPSFloat64Stats
      description: The data statistics of a series of FLOAT64 values.
    AnnotateTextRequest:
      id: AnnotateTextRequest
      description: >-
        The request message for the text annotation API, which can perform
        multiple analysis types in one call.
      type: object
      properties:
        document:
          description: Required. Input document.
          $ref: '#/components/schemas/Document'
        features:
          $ref: '#/components/schemas/AnnotateTextRequestFeatures'
          description: Required. The enabled features.
        encodingType:
          enumDescriptions:
            - >-
              If `EncodingType` is not specified, encoding-dependent information
              (such as `begin_offset`) will be set at `-1`.
            - >-
              Encoding-dependent information (such as `begin_offset`) is
              calculated based on the UTF-8 encoding of the input. C++ and Go
              are examples of languages that use this encoding natively.
            - >-
              Encoding-dependent information (such as `begin_offset`) is
              calculated based on the UTF-16 encoding of the input. Java and
              JavaScript are examples of languages that use this encoding
              natively.
            - >-
              Encoding-dependent information (such as `begin_offset`) is
              calculated based on the UTF-32 encoding of the input. Python is an
              example of a language that uses this encoding natively.
          enum:
            - NONE
            - UTF8
            - UTF16
            - UTF32
          type: string
          description: The encoding type used by the API to calculate offsets.
    XPSDataStats:
      id: XPSDataStats
      description: The data statistics of a series of values that share the same DataType.
      properties:
        distinctValueCount:
          format: int64
          type: string
          description: The number of distinct values.
        nullValueCount:
          description: The number of values that are null.
          type: string
          format: int64
        categoryStats:
          description: The statistics for CATEGORY DataType.
          $ref: '#/components/schemas/XPSCategoryStats'
        validValueCount:
          description: The number of values that are valid.
          type: string
          format: int64
        arrayStats:
          description: The statistics for ARRAY DataType.
          $ref: '#/components/schemas/XPSArrayStats'
        structStats:
          $ref: '#/components/schemas/XPSStructStats'
          description: The statistics for STRUCT DataType.
        timestampStats:
          description: The statistics for TIMESTAMP DataType.
          $ref: '#/components/schemas/XPSTimestampStats'
        stringStats:
          $ref: '#/components/schemas/XPSStringStats'
          description: The statistics for STRING DataType.
        float64Stats:
          description: The statistics for FLOAT64 DataType.
          $ref: '#/components/schemas/XPSFloat64Stats'
      type: object
    Entity:
      description: >-
        Represents a phrase in the text that is a known entity, such as a
        person, an organization, or location. The API associates information,
        such as probability and mentions, with entities.
      properties:
        name:
          type: string
          description: The representative name for the entity.
        mentions:
          type: array
          description: >-
            The mentions of this entity in the input document. The API currently
            supports proper noun mentions.
          items:
            $ref: '#/components/schemas/EntityMention'
        metadata:
          description: >-
            Metadata associated with the entity. For the metadata associated
            with other entity types, see the Type table below.
          additionalProperties:
            type: string
          type: object
        sentiment:
          description: >-
            For calls to AnalyzeEntitySentiment this field will contain the
            aggregate sentiment expressed for this entity in the provided
            document.
          $ref: '#/components/schemas/Sentiment'
        type:
          enumDescriptions:
            - Unknown
            - Person
            - Location
            - Organization
            - Event
            - Artwork
            - Consumer product
            - Other types of entities
            - >-
              Phone number The metadata lists the phone number, formatted
              according to local convention, plus whichever additional elements
              appear in the text: * `number` - the actual number, broken down
              into sections as per local convention * `national_prefix` -
              country code, if detected * `area_code` - region or area code, if
              detected * `extension` - phone extension (to be dialed after
              connection), if detected
            - >-
              Address The metadata identifies the street number and locality
              plus whichever additional elements appear in the text: *
              `street_number` - street number * `locality` - city or town *
              `street_name` - street/route name, if detected * `postal_code` -
              postal code, if detected * `country` - country, if detected *
              `broad_region` - administrative area, such as the state, if
              detected * `narrow_region` - smaller administrative area, such as
              county, if detected * `sublocality` - used in Asian addresses to
              demark a district within a city, if detected
            - >-
              Date The metadata identifies the components of the date: * `year`
              - four digit year, if detected * `month` - two digit month number,
              if detected * `day` - two digit day number, if detected
            - Number The metadata is the number itself.
            - Price The metadata identifies the `value` and `currency`.
          type: string
          description: The entity type.
          enum:
            - UNKNOWN
            - PERSON
            - LOCATION
            - ORGANIZATION
            - EVENT
            - WORK_OF_ART
            - CONSUMER_GOOD
            - OTHER
            - PHONE_NUMBER
            - ADDRESS
            - DATE
            - NUMBER
            - PRICE
      type: object
      id: Entity
    ClassificationCategory:
      description: Represents a category returned from the text classifier.
      type: object
      properties:
        name:
          type: string
          description: The name of the category representing the document.
        confidence:
          format: float
          description: >-
            The classifier's confidence of the category. Number represents how
            certain the classifier is that this category represents the given
            text.
          type: number
        severity:
          type: number
          format: float
          description: >-
            Optional. The classifier's severity of the category. This is only
            present when the ModerateTextRequest.ModelVersion is set to
            MODEL_VERSION_2, and the corresponding category has a severity
            score.
      id: ClassificationCategory
    XPSBatchPredictResponse:
      type: object
      properties:
        exampleSet:
          description: >-
            Examples for batch prediction result. Under full API implementation,
            results are stored in shared RecordIO of AnnotatedExample protobufs,
            the annotations field of which is populated by XPS backend.
          $ref: '#/components/schemas/XPSExampleSet'
      id: XPSBatchPredictResponse
    XPSTranslationEvaluationMetrics:
      id: XPSTranslationEvaluationMetrics
      type: object
      description: Evaluation metrics for the dataset.
      properties:
        bleuScore:
          format: double
          type: number
          description: BLEU score.
        baseBleuScore:
          format: double
          type: number
          description: BLEU score for base model.
    XPSArrayStats:
      description: The data statistics of a series of ARRAY values.
      type: object
      id: XPSArrayStats
      properties:
        memberStats:
          $ref: '#/components/schemas/XPSDataStats'
          description: >-
            Stats of all the values of all arrays, as if they were a single long
            series of data. The type depends on the element type of the array.
        commonStats:
          $ref: '#/components/schemas/XPSCommonStats'
    XPSVideoObjectTrackingEvaluationMetrics:
      id: XPSVideoObjectTrackingEvaluationMetrics
      description: 'Model evaluation metrics for ObjectTracking problems. Next tag: 10.'
      type: object
      properties:
        boundingBoxMetricsEntries:
          type: array
          items:
            $ref: '#/components/schemas/XPSBoundingBoxMetricsEntry'
          description: >-
            Output only. The bounding boxes match metrics for each
            Intersection-over-union threshold
            0.05,0.10,...,0.95,0.96,0.97,0.98,0.99.
        trackMeanMismatchRate:
          description: >-
            Output only. The single metric for tracking consistency evaluation:
            the mean_mismatch_rate averaged over all track_metrics_entries.
          type: number
          format: float
        trackMeanAveragePrecision:
          description: >-
            Output only. The single metric for tracks accuracy evaluation: the
            mean_average_precision averaged over all track_metrics_entries.
          format: float
          type: number
        trackMetricsEntries:
          description: >-
            Output only. The tracks match metrics for each
            Intersection-over-union threshold
            0.05,0.10,...,0.95,0.96,0.97,0.98,0.99.
          items:
            $ref: '#/components/schemas/XPSTrackMetricsEntry'
          type: array
        trackMeanBoundingBoxIou:
          type: number
          description: >-
            Output only. The single metric for tracks bounding box iou
            evaluation: the mean_bounding_box_iou averaged over all
            track_metrics_entries.
          format: float
        evaluatedFrameCount:
          format: int32
          description: The number of video frames used for model evaluation.
          type: integer
        boundingBoxMeanAveragePrecision:
          format: float
          description: >-
            Output only. The single metric for bounding boxes evaluation: the
            mean_average_precision averaged over all
            bounding_box_metrics_entries.
          type: number
        evaluatedTrackCount:
          description: The number of tracks used for model evaluation.
          format: int32
          type: integer
        evaluatedBoundingboxCount:
          description: The number of bounding boxes used for model evaluation.
          type: integer
          format: int32
    XPSStructType:
      type: object
      properties:
        fields:
          description: Unordered map of struct field names to their data types.
          additionalProperties:
            $ref: '#/components/schemas/XPSDataType'
          type: object
      description: '`StructType` defines the DataType-s of a STRUCT type.'
      id: XPSStructType
    XPSImageModelServingSpecModelThroughputEstimation:
      properties:
        computeEngineAcceleratorType:
          enum:
            - UNSPECIFIED
            - NVIDIA_TESLA_K80
            - NVIDIA_TESLA_P100
            - NVIDIA_TESLA_V100
            - NVIDIA_TESLA_P4
            - NVIDIA_TESLA_T4
            - NVIDIA_TESLA_A100
            - NVIDIA_A100_80GB
            - NVIDIA_L4
            - NVIDIA_H100_80GB
            - NVIDIA_H100_MEGA_80GB
            - NVIDIA_H200_141GB
            - NVIDIA_B200
            - NVIDIA_GB200
            - TPU_V2
            - TPU_V3
            - TPU_V4_POD
            - TPU_V5_LITEPOD
          enumDescriptions:
            - ''
            - Nvidia Tesla K80 GPU.
            - Nvidia Tesla P100 GPU.
            - Nvidia Tesla V100 GPU.
            - Nvidia Tesla P4 GPU.
            - Nvidia Tesla T4 GPU.
            - Nvidia Tesla A100 GPU.
            - Nvidia A100 80GB GPU.
            - Nvidia L4 GPU.
            - Nvidia H100 80Gb GPU.
            - Nvidia H100 80Gb GPU.
            - Nvidia H200 141Gb GPU.
            - Nvidia B200 GPU.
            - Nvidia GB200 GPU.
            - TPU v2 (JellyFish).
            - TPU v3 (DragonFish).
            - TPU_v4 (PufferFish).
            - TPU v5 Lite Pods.
          type: string
        servomaticPartitionType:
          type: string
          enum:
            - PARTITION_TYPE_UNSPECIFIED
            - PARTITION_ZERO
            - PARTITION_REDUCED_HOMING
            - PARTITION_JELLYFISH
            - PARTITION_CPU
            - PARTITION_CUSTOM_STORAGE_CPU
          enumDescriptions:
            - ''
            - The default partition.
            - >-
              It has significantly lower replication than partition-0 and is
              located in the US only. It also has a larger model size limit and
              higher default RAM quota than partition-0. Customers with batch
              traffic, US-based traffic, or very large models should use this
              partition. Capacity in this partition is significantly cheaper
              than partition-0.
            - To be used by customers with Jellyfish-accelerated ops.
            - The partition used by regionalized servomatic cloud regions.
            - The partition used for loading models from custom storage.
        nodeQps:
          format: double
          description: The approximate qps a deployed node can serve.
          type: number
        latencyInMilliseconds:
          format: double
          description: Estimated latency.
          type: number
      id: XPSImageModelServingSpecModelThroughputEstimation
      type: object
    XPSTrainResponse:
      id: XPSTrainResponse
      type: object
      properties:
        videoObjectTrackingTrainResp:
          $ref: '#/components/schemas/XPSVideoObjectTrackingTrainResponse'
        tablesTrainResp:
          $ref: '#/components/schemas/XPSTablesTrainResponse'
        deployedModelSizeBytes:
          type: string
          description: Estimated model size in bytes once deployed.
          format: int64
        imageObjectDetectionTrainResp:
          $ref: '#/components/schemas/XPSImageObjectDetectionModelSpec'
        explanationConfigs:
          description: >-
            VisionExplanationConfig for XAI on test set. Optional for when XAI
            is enable in training request.
          deprecated: true
          type: array
          items:
            $ref: '#/components/schemas/XPSResponseExplanationSpec'
        speechTrainResp:
          $ref: '#/components/schemas/XPSSpeechModelSpec'
        errorAnalysisConfigs:
          type: array
          description: >-
            Optional vision model error analysis configuration. The field is set
            when model error analysis is enabled in the training request. The
            results of error analysis will be binded together with evaluation
            results (in the format of AnnotatedExample).
          items:
            $ref: '#/components/schemas/XPSVisionErrorAnalysisConfig'
        evaluationMetricsSet:
          description: >-
            The trained model evaluation metrics. This can be optionally
            returned.
          $ref: '#/components/schemas/XPSEvaluationMetricsSet'
        imageClassificationTrainResp:
          $ref: '#/components/schemas/XPSImageClassificationTrainResponse'
        modelToken:
          description: >-
            Token that represents the trained model. This is considered
            immutable and is persisted in AutoML. xPS can put their own proto in
            the byte string, to e.g. point to the model checkpoints. The token
            is passed to other xPS APIs to refer to the model.
          format: byte
          type: string
        videoClassificationTrainResp:
          $ref: '#/components/schemas/XPSVideoClassificationTrainResponse'
        translationTrainResp:
          $ref: '#/components/schemas/XPSTranslationTrainResponse'
        textToSpeechTrainResp:
          $ref: '#/components/schemas/XPSTextToSpeechTrainResponse'
        evaluatedExampleSet:
          $ref: '#/components/schemas/XPSExampleSet'
          description: >-
            Examples used to evaluate the model (usually the test set), with the
            predicted annotations. The file_spec should point to recordio
            file(s) of AnnotatedExample. For each returned example, the
            example_id_token and annotations predicted by the model must be set.
            The example payload can and is recommended to be omitted.
        videoActionRecognitionTrainResp:
          $ref: '#/components/schemas/XPSVideoActionRecognitionTrainResponse'
        textTrainResp:
          $ref: '#/components/schemas/XPSTextTrainResponse'
          description: Will only be needed for uCAIP from Beta.
        imageSegmentationTrainResp:
          $ref: '#/components/schemas/XPSImageSegmentationTrainResponse'
    Status:
      type: object
      properties:
        code:
          format: int32
          description: The status code, which should be an enum value of google.rpc.Code.
          type: integer
        message:
          type: string
          description: >-
            A developer-facing error message, which should be in English. Any
            user-facing error message should be localized and sent in the
            google.rpc.Status.details field, or localized by the client.
        details:
          items:
            type: object
            additionalProperties:
              description: Properties of the object. Contains field @type with type URL.
              type: any
          description: >-
            A list of messages that carry the error details. There is a common
            set of message types for APIs to use.
          type: array
      id: Status
      description: >-
        The `Status` type defines a logical error model that is suitable for
        different programming environments, including REST APIs and RPC APIs. It
        is used by [gRPC](https://github.com/grpc). Each `Status` message
        contains three pieces of data: error code, error message, and error
        details. You can find out more about this error model and how to work
        with it in the [API Design
        Guide](https://cloud.google.com/apis/design/errors).
    Document:
      id: Document
      description: Represents the input to API methods.
      properties:
        type:
          description: >-
            Required. If the type is not set or is `TYPE_UNSPECIFIED`, returns
            an `INVALID_ARGUMENT` error.
          enum:
            - TYPE_UNSPECIFIED
            - PLAIN_TEXT
            - HTML
          type: string
          enumDescriptions:
            - The content type is not specified.
            - Plain text
            - HTML
        languageCode:
          type: string
          description: >-
            Optional. The language of the document (if not specified, the
            language is automatically detected). Both ISO and BCP-47 language
            codes are accepted. [Language
            Support](https://cloud.google.com/natural-language/docs/languages)
            lists currently supported languages for each API method. If the
            language (either specified by the caller or automatically detected)
            is not supported by the called API method, an `INVALID_ARGUMENT`
            error is returned.
        content:
          type: string
          description: >-
            The content of the input in string format. Cloud audit logging
            exempt since it is based on user data.
        gcsContentUri:
          type: string
          description: >-
            The Google Cloud Storage URI where the file content is located. This
            URI must be of the form: gs://bucket_name/object_name. For more
            details, see https://cloud.google.com/storage/docs/reference-uris.
            NOTE: Cloud Storage object versioning is not supported.
      type: object
    XPSImageSegmentationEvaluationMetricsConfidenceMetricsEntry:
      type: object
      properties:
        iouScore:
          format: float
          type: number
          description: IOU score.
        confidenceThreshold:
          type: number
          format: float
          description: The confidence threshold value used to compute the metrics.
        diceScoreCoefficient:
          type: number
          description: 'DSC or the F1 score: The harmonic mean of recall and precision.'
          format: float
        confusionMatrix:
          description: >-
            Confusion matrix of the per confidence_threshold evaluation. Pixel
            counts are set here. Only set for model level evaluation, not for
            evaluation per label.
          $ref: '#/components/schemas/XPSConfusionMatrix'
        recall:
          type: number
          description: Recall for the given confidence threshold.
          format: float
        precision:
          format: float
          description: Precision for the given confidence threshold.
          type: number
      description: Metrics for a single confidence threshold.
      id: XPSImageSegmentationEvaluationMetricsConfidenceMetricsEntry
    AnalyzeSentimentResponse:
      properties:
        documentSentiment:
          description: The overall sentiment of the input document.
          $ref: '#/components/schemas/Sentiment'
        languageSupported:
          type: boolean
          description: >-
            Whether the language is officially supported. The API may still
            return a response when the language is not supported, but it is on a
            best effort basis.
        languageCode:
          description: >-
            The language of the text, which will be the same as the language
            specified in the request or, if not specified, the
            automatically-detected language. See Document.language_code field
            for more details.
          type: string
        sentences:
          items:
            $ref: '#/components/schemas/Sentence'
          description: The sentiment for all the sentences in the document.
          type: array
      type: object
      description: The sentiment analysis response message.
      id: AnalyzeSentimentResponse
    Color:
      type: object
      id: Color
      properties:
        alpha:
          type: number
          format: float
          description: >-
            The fraction of this color that should be applied to the pixel. That
            is, the final pixel color is defined by the equation: `pixel color =
            alpha * (this color) + (1.0 - alpha) * (background color)` This
            means that a value of 1.0 corresponds to a solid color, whereas a
            value of 0.0 corresponds to a completely transparent color. This
            uses a wrapper message rather than a simple float scalar so that it
            is possible to distinguish between a default value and the value
            being unset. If omitted, this color object is rendered as a solid
            color (as if the alpha value had been explicitly given a value of
            1.0).
        red:
          format: float
          description: The amount of red in the color as a value in the interval [0, 1].
          type: number
        green:
          format: float
          description: The amount of green in the color as a value in the interval [0, 1].
          type: number
        blue:
          type: number
          description: The amount of blue in the color as a value in the interval [0, 1].
          format: float
      description: >-
        Represents a color in the RGBA color space. This representation is
        designed for simplicity of conversion to and from color representations
        in various languages over compactness. For example, the fields of this
        representation can be trivially provided to the constructor of
        `java.awt.Color` in Java; it can also be trivially provided to UIColor's
        `+colorWithRed:green:blue:alpha` method in iOS; and, with just a little
        work, it can be easily formatted into a CSS `rgba()` string in
        JavaScript. This reference page doesn't have information about the
        absolute color space that should be used to interpret the RGB valuefor
        example, sRGB, Adobe RGB, DCI-P3, and BT.2020. By default, applications
        should assume the sRGB color space. When color equality needs to be
        decided, implementations, unless documented otherwise, treat two colors
        as equal if all their red, green, blue, and alpha values each differ by
        at most `1e-5`. Example (Java): import com.google.type.Color; // ...
        public static java.awt.Color fromProto(Color protocolor) { float alpha =
        protocolor.hasAlpha() ? protocolor.getAlpha().getValue() : 1.0; return
        new java.awt.Color( protocolor.getRed(), protocolor.getGreen(),
        protocolor.getBlue(), alpha); } public static Color
        toProto(java.awt.Color color) { float red = (float) color.getRed();
        float green = (float) color.getGreen(); float blue = (float)
        color.getBlue(); float denominator = 255.0; Color.Builder resultBuilder
        = Color .newBuilder() .setRed(red / denominator) .setGreen(green /
        denominator) .setBlue(blue / denominator); int alpha = color.getAlpha();
        if (alpha != 255) { result.setAlpha( FloatValue .newBuilder()
        .setValue(((float) alpha) / denominator) .build()); } return
        resultBuilder.build(); } // ... Example (iOS / Obj-C): // ... static
        UIColor* fromProto(Color* protocolor) { float red = [protocolor red];
        float green = [protocolor green]; float blue = [protocolor blue];
        FloatValue* alpha_wrapper = [protocolor alpha]; float alpha = 1.0; if
        (alpha_wrapper != nil) { alpha = [alpha_wrapper value]; } return
        [UIColor colorWithRed:red green:green blue:blue alpha:alpha]; } static
        Color* toProto(UIColor* color) { CGFloat red, green, blue, alpha; if
        (![color getRed:&red green:&green blue:&blue alpha:&alpha]) { return
        nil; } Color* result = [[Color alloc] init]; [result setRed:red];
        [result setGreen:green]; [result setBlue:blue]; if (alpha <= 0.9999) {
        [result setAlpha:floatWrapperWithValue(alpha)]; } [result autorelease];
        return result; } // ... Example (JavaScript): // ... var protoToCssColor
        = function(rgb_color) { var redFrac = rgb_color.red || 0.0; var
        greenFrac = rgb_color.green || 0.0; var blueFrac = rgb_color.blue ||
        0.0; var red = Math.floor(redFrac * 255); var green =
        Math.floor(greenFrac * 255); var blue = Math.floor(blueFrac * 255); if
        (!('alpha' in rgb_color)) { return rgbToCssColor(red, green, blue); }
        var alphaFrac = rgb_color.alpha.value || 0.0; var rgbParams = [red,
        green, blue].join(','); return ['rgba(', rgbParams, ',', alphaFrac,
        ')'].join(''); }; var rgbToCssColor = function(red, green, blue) { var
        rgbNumber = new Number((red << 16) | (green << 8) | blue); var hexString
        = rgbNumber.toString(16); var missingZeros = 6 - hexString.length; var
        resultBuilder = ['#']; for (var i = 0; i < missingZeros; i++) {
        resultBuilder.push('0'); } resultBuilder.push(hexString); return
        resultBuilder.join(''); }; // ...
    XPSEdgeTpuTfLiteFormat:
      id: XPSEdgeTpuTfLiteFormat
      properties: {}
      description: >-
        A model format used for [Edge TPU](https://cloud.google.com/edge-tpu/)
        devices.
      type: object
    XPSCategoryStats:
      properties:
        topCategoryStats:
          description: >-
            The statistics of the top 20 CATEGORY values, ordered by
            CategoryStats.SingleCategoryStats.count.
          type: array
          items:
            $ref: '#/components/schemas/XPSCategoryStatsSingleCategoryStats'
        commonStats:
          $ref: '#/components/schemas/XPSCommonStats'
      type: object
      id: XPSCategoryStats
      description: The data statistics of a series of CATEGORY values.
    GpuMetric:
      type: object
      id: GpuMetric
      properties:
        trackingLabels:
          additionalProperties:
            type: string
          type: object
          description: >-
            Billing tracking labels. They do not contain any user data but only
            the labels set by Vertex Core Infra itself. Tracking labels' keys
            are defined with special format: goog-[\p{Ll}\p{N}]+ E.g. "key":
            "goog-k8s-cluster-name","value": "us-east1-b4rk"
        machineSpec:
          enum:
            - UNKNOWN_MACHINE_SPEC
            - N1_STANDARD_2
            - N1_STANDARD_4
            - N1_STANDARD_8
            - N1_STANDARD_16
            - N1_STANDARD_32
            - N1_STANDARD_64
            - N1_STANDARD_96
            - N1_HIGHMEM_2
            - N1_HIGHMEM_4
            - N1_HIGHMEM_8
            - N1_HIGHMEM_16
            - N1_HIGHMEM_32
            - N1_HIGHMEM_64
            - N1_HIGHMEM_96
            - N1_HIGHCPU_2
            - N1_HIGHCPU_4
            - N1_HIGHCPU_8
            - N1_HIGHCPU_16
            - N1_HIGHCPU_32
            - N1_HIGHCPU_64
            - N1_HIGHCPU_96
            - A2_HIGHGPU_1G
            - A2_HIGHGPU_2G
            - A2_HIGHGPU_4G
            - A2_HIGHGPU_8G
            - A2_MEGAGPU_16G
            - A2_ULTRAGPU_1G
            - A2_ULTRAGPU_2G
            - A2_ULTRAGPU_4G
            - A2_ULTRAGPU_8G
            - A3_HIGHGPU_1G
            - A3_HIGHGPU_2G
            - A3_HIGHGPU_4G
            - A3_HIGHGPU_8G
            - A3_MEGAGPU_8G
            - A3_ULTRAGPU_8G
            - A3_EDGEGPU_8G
            - A4_HIGHGPU_8G
            - A4X_HIGHGPU_4G
            - E2_STANDARD_2
            - E2_STANDARD_4
            - E2_STANDARD_8
            - E2_STANDARD_16
            - E2_STANDARD_32
            - E2_HIGHMEM_2
            - E2_HIGHMEM_4
            - E2_HIGHMEM_8
            - E2_HIGHMEM_16
            - E2_HIGHCPU_2
            - E2_HIGHCPU_4
            - E2_HIGHCPU_8
            - E2_HIGHCPU_16
            - E2_HIGHCPU_32
            - N2_STANDARD_2
            - N2_STANDARD_4
            - N2_STANDARD_8
            - N2_STANDARD_16
            - N2_STANDARD_32
            - N2_STANDARD_48
            - N2_STANDARD_64
            - N2_STANDARD_80
            - N2_STANDARD_96
            - N2_STANDARD_128
            - N2_HIGHMEM_2
            - N2_HIGHMEM_4
            - N2_HIGHMEM_8
            - N2_HIGHMEM_16
            - N2_HIGHMEM_32
            - N2_HIGHMEM_48
            - N2_HIGHMEM_64
            - N2_HIGHMEM_80
            - N2_HIGHMEM_96
            - N2_HIGHMEM_128
            - N2_HIGHCPU_2
            - N2_HIGHCPU_4
            - N2_HIGHCPU_8
            - N2_HIGHCPU_16
            - N2_HIGHCPU_32
            - N2_HIGHCPU_48
            - N2_HIGHCPU_64
            - N2_HIGHCPU_80
            - N2_HIGHCPU_96
            - N2D_STANDARD_2
            - N2D_STANDARD_4
            - N2D_STANDARD_8
            - N2D_STANDARD_16
            - N2D_STANDARD_32
            - N2D_STANDARD_48
            - N2D_STANDARD_64
            - N2D_STANDARD_80
            - N2D_STANDARD_96
            - N2D_STANDARD_128
            - N2D_STANDARD_224
            - N2D_HIGHMEM_2
            - N2D_HIGHMEM_4
            - N2D_HIGHMEM_8
            - N2D_HIGHMEM_16
            - N2D_HIGHMEM_32
            - N2D_HIGHMEM_48
            - N2D_HIGHMEM_64
            - N2D_HIGHMEM_80
            - N2D_HIGHMEM_96
            - N2D_HIGHCPU_2
            - N2D_HIGHCPU_4
            - N2D_HIGHCPU_8
            - N2D_HIGHCPU_16
            - N2D_HIGHCPU_32
            - N2D_HIGHCPU_48
            - N2D_HIGHCPU_64
            - N2D_HIGHCPU_80
            - N2D_HIGHCPU_96
            - N2D_HIGHCPU_128
            - N2D_HIGHCPU_224
            - C2_STANDARD_4
            - C2_STANDARD_8
            - C2_STANDARD_16
            - C2_STANDARD_30
            - C2_STANDARD_60
            - C2D_STANDARD_2
            - C2D_STANDARD_4
            - C2D_STANDARD_8
            - C2D_STANDARD_16
            - C2D_STANDARD_32
            - C2D_STANDARD_56
            - C2D_STANDARD_112
            - C2D_HIGHCPU_2
            - C2D_HIGHCPU_4
            - C2D_HIGHCPU_8
            - C2D_HIGHCPU_16
            - C2D_HIGHCPU_32
            - C2D_HIGHCPU_56
            - C2D_HIGHCPU_112
            - C2D_HIGHMEM_2
            - C2D_HIGHMEM_4
            - C2D_HIGHMEM_8
            - C2D_HIGHMEM_16
            - C2D_HIGHMEM_32
            - C2D_HIGHMEM_56
            - C2D_HIGHMEM_112
            - G2_STANDARD_4
            - G2_STANDARD_8
            - G2_STANDARD_12
            - G2_STANDARD_16
            - G2_STANDARD_24
            - G2_STANDARD_32
            - G2_STANDARD_48
            - G2_STANDARD_96
            - G4_STANDARD_48
            - C3_STANDARD_4
            - C3_STANDARD_8
            - C3_STANDARD_22
            - C3_STANDARD_44
            - C3_STANDARD_88
            - C3_STANDARD_176
            - C3_HIGHCPU_4
            - C3_HIGHCPU_8
            - C3_HIGHCPU_22
            - C3_HIGHCPU_44
            - C3_HIGHCPU_88
            - C3_HIGHCPU_176
            - C3_HIGHMEM_4
            - C3_HIGHMEM_8
            - C3_HIGHMEM_22
            - C3_HIGHMEM_44
            - C3_HIGHMEM_88
            - C3_HIGHMEM_176
            - C4_STANDARD_8
            - C4_STANDARD_16
            - C4_STANDARD_24
            - C4_STANDARD_32
            - C4_STANDARD_48
            - C4_STANDARD_96
            - C4_STANDARD_144
            - C4_STANDARD_192
            - C4_STANDARD_288
            - C4_HIGHCPU_8
            - C4_HIGHCPU_16
            - C4_HIGHCPU_24
            - C4_HIGHCPU_32
            - C4_HIGHCPU_48
            - C4_HIGHCPU_96
            - C4_HIGHCPU_144
            - C4_HIGHCPU_192
            - C4_HIGHCPU_288
            - C4_HIGHMEM_8
            - C4_HIGHMEM_16
            - C4_HIGHMEM_24
            - C4_HIGHMEM_32
            - C4_HIGHMEM_48
            - C4_HIGHMEM_96
            - C4_HIGHMEM_144
            - C4_HIGHMEM_192
            - C4_HIGHMEM_288
          description: Required. Machine spec, e.g. N1_STANDARD_4.
          enumDescriptions:
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
          type: string
        gpuSec:
          type: string
          description: Required. Seconds of GPU usage, e.g. 3600.
          format: int64
        gpuType:
          enumDescriptions:
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
          description: Required. Type of GPU, e.g. NVIDIA_TESLA_V100.
          type: string
          enum:
            - UNKNOWN_GPU_TYPE
            - NVIDIA_TESLA_A100
            - NVIDIA_A100_80GB
            - NVIDIA_B200
            - NVIDIA_GB200
            - NVIDIA_TESLA_K80
            - NVIDIA_L4
            - NVIDIA_TESLA_P100
            - NVIDIA_TESLA_P4
            - NVIDIA_TESLA_T4
            - NVIDIA_TESLA_V100
            - NVIDIA_H100_80GB
            - NVIDIA_H100_MEGA_80GB
            - NVIDIA_H200_141GB
            - NVIDIA_RTX_PRO_6000
    XPSSpeechModelSpec:
      properties:
        datasetId:
          description: >-
            Required for speech xps backend. Speech xps has to use dataset_id
            and model_id as the primary key in db so that speech API can query
            the db directly.
          type: string
          format: int64
        language:
          type: string
        subModelSpecs:
          type: array
          description: Model specs for all submodels contained in this model.
          items:
            $ref: '#/components/schemas/XPSSpeechModelSpecSubModelSpec'
      id: XPSSpeechModelSpec
      type: object
    XPSImageModelArtifactSpec:
      type: object
      id: XPSImageModelArtifactSpec
      description: >-
        Stores the locations and related metadata of the model artifacts.
        Populated for uCAIP requests only.
      properties:
        exportArtifact:
          description: The model binary files in different formats for model export.
          items:
            $ref: '#/components/schemas/XPSModelArtifactItem'
          type: array
        tfLiteMetadataGcsUri:
          description: >-
            Google Cloud Storage URI of Tensorflow Lite metadata
            'tflite_metadata.json'.
          type: string
        tfJsBinaryGcsPrefix:
          description: >-
            Google Cloud Storage URI prefix of Tensorflow JavaScript binary
            files 'groupX-shardXofX.bin'. Deprecated.
          type: string
        labelGcsUri:
          description: >-
            Google Cloud Storage URI of decoded labels file for model export
            'dict.txt'.
          type: string
        servingArtifact:
          description: >-
            The default model binary file used for serving (e.g. online predict,
            batch predict) via public Cloud AI Platform API.
          $ref: '#/components/schemas/XPSModelArtifactItem'
        checkpointArtifact:
          $ref: '#/components/schemas/XPSModelArtifactItem'
          description: The Tensorflow checkpoint files. e.g. Used for resumable training.
    XPSVideoClassificationTrainResponse:
      id: XPSVideoClassificationTrainResponse
      type: object
      properties:
        modelArtifactSpec:
          $ref: '#/components/schemas/XPSVideoModelArtifactSpec'
          description: '## The fields below are only populated under uCAIP request scope.'
        trainCostNodeSeconds:
          description: >-
            The actual train cost of creating this model, expressed in node
            seconds, i.e. 3,600 value in this field means 1 node hour.
          format: int64
          type: string
    XPSTextSentimentEvaluationMetrics:
      properties:
        f1Score:
          type: number
          description: Output only. The harmonic mean of recall and precision.
          format: float
        recall:
          type: number
          format: float
          description: Output only. Recall.
        meanSquaredError:
          description: >-
            Output only. Mean squared error. Only set for the overall model
            evaluation, not for evaluation of a single annotation spec.
          format: float
          type: number
        meanAbsoluteError:
          type: number
          description: >-
            Output only. Mean absolute error. Only set for the overall model
            evaluation, not for evaluation of a single annotation spec.
          format: float
        linearKappa:
          type: number
          format: float
          description: >-
            Output only. Linear weighted kappa. Only set for the overall model
            evaluation, not for evaluation of a single annotation spec.
        confusionMatrix:
          description: >-
            Output only. Confusion matrix of the evaluation. Only set for the
            overall model evaluation, not for evaluation of a single annotation
            spec.
          $ref: '#/components/schemas/XPSConfusionMatrix'
        quadraticKappa:
          type: number
          description: >-
            Output only. Quadratic weighted kappa. Only set for the overall
            model evaluation, not for evaluation of a single annotation spec.
          format: float
        precision:
          type: number
          format: float
          description: Output only. Precision.
      id: XPSTextSentimentEvaluationMetrics
      description: Model evaluation metrics for text sentiment problems.
      type: object
    XPSVideoBatchPredictOperationMetadata:
      properties:
        outputExamples:
          type: array
          items:
            type: string
          description: >-
            All the partial batch prediction results that are completed at the
            moment. Output examples are sorted by completion time. The order
            will not be changed. Each output example should be the path of a
            single RecordIO file of AnnotatedExamples.
      id: XPSVideoBatchPredictOperationMetadata
      type: object
    XPSVideoActionMetricsEntry:
      description: The Evaluation metrics entry given a specific precision_window_length.
      properties:
        meanAveragePrecision:
          description: The mean average precision.
          format: float
          type: number
        precisionWindowLength:
          description: >-
            This VideoActionMetricsEntry is calculated based on this prediction
            window length. If the predicted action's timestamp is inside the
            time window whose center is the ground truth action's timestamp with
            this specific length, the prediction result is treated as a true
            positive.
          type: string
          format: google-duration
        confidenceMetricsEntries:
          items:
            $ref: >-
              #/components/schemas/XPSVideoActionMetricsEntryConfidenceMetricsEntry
          type: array
          description: >-
            Metrics for each label-match confidence_threshold from
            0.05,0.10,...,0.95,0.96,0.97,0.98,0.99.
      type: object
      id: XPSVideoActionMetricsEntry
    XPSConfusionMatrix:
      properties:
        row:
          type: array
          description: >-
            Rows in the confusion matrix. The number of rows is equal to the
            size of `annotation_spec_id_token`. `row[i].value[j]` is the number
            of examples that have ground truth of the
            `annotation_spec_id_token[i]` and are predicted as
            `annotation_spec_id_token[j]` by the model being evaluated.
          items:
            $ref: '#/components/schemas/XPSConfusionMatrixRow'
        sentimentLabel:
          items:
            type: integer
            format: int32
          description: >-
            Sentiment labels used in the confusion matrix. Set only for text
            sentiment models. For AutoML Text Revamp, use
            `annotation_spec_id_token` instead and leave this field empty.
          type: array
        annotationSpecIdToken:
          description: >-
            For the following three repeated fields, only one is intended to be
            set. annotation_spec_id_token is preferable to be set. ID tokens of
            the annotation specs used in the confusion matrix.
          type: array
          items:
            type: string
        category:
          type: array
          items:
            type: integer
            format: int32
          description: >-
            Category (mainly for segmentation). Set only for image segmentation
            models. Note: uCAIP Image Segmentation should use
            annotation_spec_id_token.
      id: XPSConfusionMatrix
      type: object
      description: Confusion matrix of the model running the classification.
    XPSTablesClassificationMetrics:
      id: XPSTablesClassificationMetrics
      type: object
      description: Metrics for Tables classification problems.
      properties:
        curveMetrics:
          description: Metrics building a curve.
          type: array
          items:
            $ref: '#/components/schemas/XPSTablesClassificationMetricsCurveMetrics'
    XPSImageSegmentationTrainResponse:
      properties:
        trainCostNodeSeconds:
          description: >-
            The actual train cost of creating this model, expressed in node
            seconds, i.e. 3,600 value in this field means 1 node hour.
          format: int64
          type: string
        exportModelSpec:
          description: 'NOTE: These fields are not used/needed in EAP but will be set later.'
          $ref: '#/components/schemas/XPSImageExportModelSpec'
        modelServingSpec:
          $ref: '#/components/schemas/XPSImageModelServingSpec'
        stopReason:
          enumDescriptions:
            - ''
            - ''
            - Model fully converged, can not be resumbed training.
            - >-
              Model early converged, can be further trained till full
              convergency.
          enum:
            - TRAIN_STOP_REASON_UNSPECIFIED
            - TRAIN_STOP_REASON_BUDGET_REACHED
            - TRAIN_STOP_REASON_MODEL_CONVERGED
            - TRAIN_STOP_REASON_MODEL_EARLY_STOPPED
          type: string
          description: >-
            Stop reason for training job, e.g. 'TRAIN_BUDGET_REACHED',
            'MODEL_CONVERGED'.
        modelArtifactSpec:
          description: >-
            ## The fields below are only populated under uCAIP request scope.
            Model artifact spec stores and model gcs pathes and related metadata
          $ref: '#/components/schemas/XPSImageModelArtifactSpec'
        colorMaps:
          items:
            $ref: '#/components/schemas/XPSColorMap'
          type: array
          description: Color map of the model.
      type: object
      id: XPSImageSegmentationTrainResponse
    XPSModelArtifactItem:
      id: XPSModelArtifactItem
      description: A single model artifact item.
      properties:
        artifactFormat:
          enumDescriptions:
            - Should not be used.
            - >-
              The Tensorflow checkpoints. See
              https://www.tensorflow.org/guide/checkpoint.
            - The Tensorflow SavedModel binary.
            - >-
              Model artifact in generic TensorFlow Lite (.tflite) format. See
              https://www.tensorflow.org/lite.
            - Used for [Edge TPU](https://cloud.google.com/edge-tpu/) devices.
            - >-
              A [TensorFlow.js](https://www.tensorflow.org/js) model that can be
              used in the browser and in Node.js using JavaScript.
            - >-
              Used for iOS mobile devices in (.mlmodel) format. See
              https://developer.apple.com/documentation/coreml
          type: string
          enum:
            - ARTIFACT_FORMAT_UNSPECIFIED
            - TF_CHECKPOINT
            - TF_SAVED_MODEL
            - TF_LITE
            - EDGE_TPU_TF_LITE
            - TF_JS
            - CORE_ML
          description: The model artifact format.
        gcsUri:
          description: The Google Cloud Storage URI that stores the model binary files.
          type: string
      type: object
    XPSResponseExplanationParameters:
      properties:
        integratedGradientsAttribution:
          description: >-
            An attribution method that computes Aumann-Shapley values taking
            advantage of the model's fully differentiable structure. Refer to
            this paper for more details: https://arxiv.org/abs/1703.01365
          $ref: '#/components/schemas/XPSIntegratedGradientsAttribution'
        xraiAttribution:
          description: >-
            An attribution method that redistributes Integrated Gradients
            attribution to segmented regions, taking advantage of the model's
            fully differentiable structure. Refer to this paper for more
            details: https://arxiv.org/abs/1906.02825 XRAI currently performs
            better on natural images, like a picture of a house or an animal. If
            the images are taken in artificial environments, like a lab or
            manufacturing line, or from diagnostic equipment, like x-rays or
            quality-control cameras, use Integrated Gradients instead.
          $ref: '#/components/schemas/XPSXraiAttribution'
      deprecated: true
      id: XPSResponseExplanationParameters
      type: object
    XPSImageModelServingSpec:
      description: Serving specification for image models.
      id: XPSImageModelServingSpec
      type: object
      properties:
        modelThroughputEstimation:
          description: Populate under uCAIP request scope.
          items:
            $ref: >-
              #/components/schemas/XPSImageModelServingSpecModelThroughputEstimation
          type: array
        nodeQps:
          description: >-
            An estimated value of how much traffic a node can serve. Populated
            for AutoMl request only.
          format: double
          type: number
        tfRuntimeVersion:
          type: string
          description: >-
            ## The fields below are only populated under uCAIP request scope.
            https://cloud.google.com/ml-engine/docs/runtime-version-list
    XPSTablesModelStructureModelParametersParameter:
      type: object
      id: XPSTablesModelStructureModelParametersParameter
      properties:
        floatValue:
          type: number
          description: Float type parameter value.
          format: double
        name:
          description: Parameter name.
          type: string
        stringValue:
          type: string
          description: String type parameter value.
        intValue:
          description: Integer type parameter value.
          format: int64
          type: string
    XPSTrainingObjectivePoint:
      type: object
      id: XPSTrainingObjectivePoint
      properties:
        createTime:
          type: string
          format: google-datetime
          description: The time at which this point was recorded.
        value:
          format: float
          description: The objective value when this point was recorded.
          type: number
    XPSTextTrainResponse:
      properties:
        componentModel:
          description: Component submodels.
          items:
            $ref: '#/components/schemas/XPSTextComponentModel'
          type: array
      id: XPSTextTrainResponse
      type: object
    XPSTrackMetricsEntryConfidenceMetricsEntry:
      id: XPSTrackMetricsEntryConfidenceMetricsEntry
      properties:
        boundingBoxIou:
          format: float
          type: number
          description: >-
            Output only. Bounding box intersection-over-union precision.
            Measures how well the bounding boxes overlap between each other
            (e.g. complete overlap or just barely above iou_threshold).
        trackingPrecision:
          format: float
          type: number
          description: Output only. Tracking precision.
        trackingRecall:
          description: Output only. Tracking recall.
          format: float
          type: number
        confidenceThreshold:
          format: float
          type: number
          description: >-
            Output only. The confidence threshold value used to compute the
            metrics.
        mismatchRate:
          description: >-
            Output only. Mismatch rate, which measures the tracking consistency,
            i.e. correctness of instance ID continuity.
          format: float
          type: number
      type: object
      description: 'Metrics for a single confidence threshold. Next tag: 6.'
    XPSMetricEntry:
      properties:
        doubleValue:
          format: double
          type: number
          description: A double value.
        int64Value:
          type: string
          format: int64
          description: A signed 64-bit integer value.
        metricName:
          description: The metric name defined in the service configuration.
          type: string
        argentumMetricId:
          description: >-
            For billing metrics that are using legacy sku's, set the legacy
            billing metric id here. This will be sent to Chemist as the
            "cloudbilling.googleapis.com/argentum_metric_id" label. Otherwise
            leave empty.
          type: string
        systemLabels:
          description: Billing system labels for this (metric, value) pair.
          items:
            $ref: '#/components/schemas/XPSMetricEntryLabel'
          type: array
      type: object
      id: XPSMetricEntry
    XPSTextExtractionEvaluationMetrics:
      type: object
      id: XPSTextExtractionEvaluationMetrics
      properties:
        perLabelConfidenceMetrics:
          description: Only recall, precision, and f1_score will be set.
          type: object
          additionalProperties:
            $ref: '#/components/schemas/XPSConfidenceMetricsEntry'
          deprecated: true
        bestF1ConfidenceMetrics:
          $ref: '#/components/schemas/XPSConfidenceMetricsEntry'
          description: >-
            Values are at the highest F1 score on the precision-recall curve.
            Only confidence_threshold, recall, precision, and f1_score will be
            set.
          deprecated: true
        confusionMatrix:
          description: >-
            Confusion matrix of the model, at the default confidence threshold
            (0.0). Only set for whole-model evaluation, not for evaluation per
            label.
          $ref: '#/components/schemas/XPSConfusionMatrix'
        confidenceMetricsEntries:
          type: array
          description: >-
            If the enclosing EvaluationMetrics.label is empty,
            confidence_metrics_entries is an evaluation of the entire model
            across all labels. If the enclosing EvaluationMetrics.label is set,
            confidence_metrics_entries applies to that label.
          items:
            $ref: '#/components/schemas/XPSConfidenceMetricsEntry'
    XPSTablesTrainingOperationMetadata:
      properties:
        trainingStartTime:
          type: string
          format: google-datetime
          description: Timestamp when training process starts.
        topTrials:
          items:
            $ref: '#/components/schemas/XPSTuningTrial'
          type: array
          description: >-
            This field is for training. When the operation is terminated
            successfully, AutoML Backend post this field to operation metadata
            in spanner. If the metadata has no trials returned, the training
            operation is supposed to be a failure.
        trainingObjectivePoints:
          type: array
          items:
            $ref: '#/components/schemas/XPSTrainingObjectivePoint'
          description: >-
            This field records the training objective value with respect to
            time, giving insight into how the model architecture search is
            performing as training time elapses.
        trainBudgetMilliNodeHours:
          type: string
          format: int64
          description: Creating model budget.
        optimizationObjective:
          type: string
          description: The optimization objective for model.
        createModelStage:
          description: Current stage of creating model.
          type: string
          enum:
            - CREATE_MODEL_STAGE_UNSPECIFIED
            - DATA_PREPROCESSING
            - TRAINING
            - EVALUATING
            - MODEL_POST_PROCESSING
          enumDescriptions:
            - Unspecified stage.
            - Prepare the model training pipeline and run data processing.
            - Training model.
            - Run evaluation.
            - Finalizing model training pipeline.
      id: XPSTablesTrainingOperationMetadata
      type: object
    AnnotateTextResponse:
      id: AnnotateTextResponse
      properties:
        entities:
          items:
            $ref: '#/components/schemas/Entity'
          type: array
          description: >-
            Entities, along with their semantic information, in the input
            document. Populated if the user enables
            AnnotateTextRequest.Features.extract_entities .
        categories:
          type: array
          description: Categories identified in the input document.
          items:
            $ref: '#/components/schemas/ClassificationCategory'
        documentSentiment:
          description: >-
            The overall sentiment for the document. Populated if the user
            enables AnnotateTextRequest.Features.extract_document_sentiment.
          $ref: '#/components/schemas/Sentiment'
        languageCode:
          description: >-
            The language of the text, which will be the same as the language
            specified in the request or, if not specified, the
            automatically-detected language. See Document.language_code field
            for more details.
          type: string
        moderationCategories:
          type: array
          description: Harmful and sensitive categories identified in the input document.
          items:
            $ref: '#/components/schemas/ClassificationCategory'
        languageSupported:
          description: >-
            Whether the language is officially supported by all requested
            features. The API may still return a response when the language is
            not supported, but it is on a best effort basis.
          type: boolean
        sentences:
          items:
            $ref: '#/components/schemas/Sentence'
          type: array
          description: >-
            Sentences in the input document. Populated if the user enables
            AnnotateTextRequest.Features.extract_document_sentiment.
      type: object
      description: The text annotations response message.
    TextSpan:
      id: TextSpan
      type: object
      description: Represents a text span in the input document.
      properties:
        beginOffset:
          type: integer
          description: >-
            The API calculates the beginning offset of the content in the
            original document according to the EncodingType specified in the API
            request.
          format: int32
        content:
          type: string
          description: The content of the text span, which is a substring of the document.
    XPSRow:
      properties:
        columnIds:
          description: >-
            The ids of the columns. Note: The below `values` field must match
            order of this field, if this field is set.
          items:
            type: integer
            format: int32
          type: array
        values:
          type: array
          description: >-
            The values of the row cells, given in the same order as the
            column_ids. If column_ids is not set, then in the same order as the
            input_feature_column_ids in TablesModelMetadata.
          items:
            type: any
      id: XPSRow
      type: object
    XPSBoundingBoxMetricsEntry:
      id: XPSBoundingBoxMetricsEntry
      type: object
      description: >-
        Bounding box matching model metrics for a single intersection-over-union
        threshold and multiple label match confidence thresholds.
      properties:
        confidenceMetricsEntries:
          type: array
          description: >-
            Metrics for each label-match confidence_threshold from
            0.05,0.10,...,0.95,0.96,0.97,0.98,0.99.
          items:
            $ref: >-
              #/components/schemas/XPSBoundingBoxMetricsEntryConfidenceMetricsEntry
        iouThreshold:
          type: number
          format: float
          description: >-
            The intersection-over-union threshold value used to compute this
            metrics entry.
        meanAveragePrecision:
          description: The mean average precision.
          type: number
          format: float
    XPSTablesEvaluationMetrics:
      properties:
        regressionMetrics:
          $ref: '#/components/schemas/XPSTablesRegressionMetrics'
          description: Regression metrics.
        classificationMetrics:
          description: Classification metrics.
          $ref: '#/components/schemas/XPSTablesClassificationMetrics'
      id: XPSTablesEvaluationMetrics
      type: object
    XPSTranslationPreprocessResponse:
      type: object
      id: XPSTranslationPreprocessResponse
      properties:
        validExampleCount:
          format: int64
          type: string
          description: Total valid example count.
        parsedExampleCount:
          format: int64
          type: string
          description: Total example count parsed.
      description: Translation preprocess response.
    XPSBoundingBoxMetricsEntryConfidenceMetricsEntry:
      properties:
        precision:
          format: float
          type: number
          description: Precision for the given confidence threshold.
        recall:
          description: Recall for the given confidence threshold.
          format: float
          type: number
        confidenceThreshold:
          description: The confidence threshold value used to compute the metrics.
          type: number
          format: float
        f1Score:
          description: The harmonic mean of recall and precision.
          type: number
          format: float
      type: object
      id: XPSBoundingBoxMetricsEntryConfidenceMetricsEntry
      description: Metrics for a single confidence threshold.
    AnalyzeEntitiesResponse:
      id: AnalyzeEntitiesResponse
      type: object
      description: The entity analysis response message.
      properties:
        languageCode:
          type: string
          description: >-
            The language of the text, which will be the same as the language
            specified in the request or, if not specified, the
            automatically-detected language. See Document.language_code field
            for more details.
        entities:
          description: The recognized entities in the input document.
          items:
            $ref: '#/components/schemas/Entity'
          type: array
        languageSupported:
          description: >-
            Whether the language is officially supported. The API may still
            return a response when the language is not supported, but it is on a
            best effort basis.
          type: boolean
    XPSTablesDatasetMetadata:
      id: XPSTablesDatasetMetadata
      description: Metadata for a dataset used for AutoML Tables.
      properties:
        primaryTableSpec:
          $ref: '#/components/schemas/XPSTableSpec'
          description: Primary table.
        targetColumnId:
          description: >-
            Id of the primary table column that should be used as the training
            label.
          format: int32
          type: integer
        targetColumnCorrelations:
          additionalProperties:
            $ref: '#/components/schemas/XPSCorrelationStats'
          type: object
          description: '(the column id : its CorrelationStats with target column).'
        weightColumnId:
          type: integer
          description: >-
            Id of the primary table column that should be used as the weight
            column.
          format: int32
        mlUseColumnId:
          format: int32
          description: Id the column to split the table.
          type: integer
      type: object
    XPSTuningTrial:
      description: >-
        Metrics for a tuning job generated, will get forwarded to Stackdriver as
        model tuning logs. Setting this as a standalone message out of
        CreateModelMetadata to avoid confusion as we expose this message only to
        users.
      properties:
        modelStructure:
          description: Model parameters for the trial.
          $ref: '#/components/schemas/XPSTablesModelStructure'
        trainingObjectivePoint:
          description: The optimization objective evaluation of the eval split data.
          $ref: '#/components/schemas/XPSTrainingObjectivePoint'
      id: XPSTuningTrial
      type: object
    XPSTablesRegressionMetrics:
      id: XPSTablesRegressionMetrics
      type: object
      properties:
        rootMeanSquaredLogError:
          format: double
          description: Root mean squared log error.
          type: number
        rSquared:
          description: R squared.
          type: number
          format: double
        meanAbsoluteError:
          format: double
          description: Mean absolute error.
          type: number
        meanAbsolutePercentageError:
          type: number
          description: >-
            Mean absolute percentage error, only set if all of the target
            column's values are positive.
          format: double
        regressionMetricsEntries:
          description: >-
            A list of actual versus predicted points for the model being
            evaluated.
          type: array
          items:
            $ref: '#/components/schemas/XPSRegressionMetricsEntry'
        rootMeanSquaredError:
          type: number
          format: double
          description: Root mean squared error.
      description: Metrics for Tables regression problems.
    XPSTablesModelStructure:
      id: XPSTablesModelStructure
      properties:
        modelParameters:
          description: A list of models.
          items:
            $ref: '#/components/schemas/XPSTablesModelStructureModelParameters'
          type: array
      type: object
      description: A description of Tables model structure.
    XPSColumnSpecCorrelatedColumn:
      description: >-
        Identifies a table's column, and its correlation with the column this
        ColumnSpec describes.
      type: object
      id: XPSColumnSpecCorrelatedColumn
      properties:
        columnId:
          type: integer
          format: int32
        correlationStats:
          $ref: '#/components/schemas/XPSCorrelationStats'
    XPSCommonStats:
      id: XPSCommonStats
      description: Common statistics for a column with a specified data type.
      type: object
      properties:
        validValueCount:
          format: int64
          type: string
        distinctValueCount:
          format: int64
          type: string
        nullValueCount:
          type: string
          format: int64
    AnnotateTextRequestFeatures:
      properties:
        extractEntities:
          type: boolean
          description: Optional. Extract entities.
        moderateText:
          description: >-
            Optional. Moderate the document for harmful and sensitive
            categories.
          type: boolean
        classifyText:
          type: boolean
          description: Optional. Classify the full document into categories.
        extractDocumentSentiment:
          type: boolean
          description: Optional. Extract document-level sentiment.
      description: >-
        All available features. Setting each one to true will enable that
        specific analysis for the input.
      type: object
      id: AnnotateTextRequestFeatures
    XPSStructStats:
      description: The data statistics of a series of STRUCT values.
      properties:
        fieldStats:
          type: object
          additionalProperties:
            $ref: '#/components/schemas/XPSDataStats'
          description: >-
            Map from a field name of the struct to data stats aggregated over
            series of all data in that field across all the structs.
        commonStats:
          $ref: '#/components/schemas/XPSCommonStats'
      type: object
      id: XPSStructStats
    RamMetric:
      id: RamMetric
      type: object
      properties:
        trackingLabels:
          type: object
          description: >-
            Billing tracking labels. They do not contain any user data but only
            the labels set by Vertex Core Infra itself. Tracking labels' keys
            are defined with special format: goog-[\p{Ll}\p{N}]+ E.g. "key":
            "goog-k8s-cluster-name","value": "us-east1-b4rk"
          additionalProperties:
            type: string
        memories:
          type: number
          format: double
          description: Required. VM memory in gb.
        gibSec:
          format: int64
          description: >-
            Required. VM memory in Gigabyte second, e.g. 3600. Using int64 type
            to match billing metrics definition.
          type: string
        machineSpec:
          description: Required. Machine spec, e.g. N1_STANDARD_4.
          type: string
          enum:
            - UNKNOWN_MACHINE_SPEC
            - N1_STANDARD_2
            - N1_STANDARD_4
            - N1_STANDARD_8
            - N1_STANDARD_16
            - N1_STANDARD_32
            - N1_STANDARD_64
            - N1_STANDARD_96
            - N1_HIGHMEM_2
            - N1_HIGHMEM_4
            - N1_HIGHMEM_8
            - N1_HIGHMEM_16
            - N1_HIGHMEM_32
            - N1_HIGHMEM_64
            - N1_HIGHMEM_96
            - N1_HIGHCPU_2
            - N1_HIGHCPU_4
            - N1_HIGHCPU_8
            - N1_HIGHCPU_16
            - N1_HIGHCPU_32
            - N1_HIGHCPU_64
            - N1_HIGHCPU_96
            - A2_HIGHGPU_1G
            - A2_HIGHGPU_2G
            - A2_HIGHGPU_4G
            - A2_HIGHGPU_8G
            - A2_MEGAGPU_16G
            - A2_ULTRAGPU_1G
            - A2_ULTRAGPU_2G
            - A2_ULTRAGPU_4G
            - A2_ULTRAGPU_8G
            - A3_HIGHGPU_1G
            - A3_HIGHGPU_2G
            - A3_HIGHGPU_4G
            - A3_HIGHGPU_8G
            - A3_MEGAGPU_8G
            - A3_ULTRAGPU_8G
            - A3_EDGEGPU_8G
            - A4_HIGHGPU_8G
            - A4X_HIGHGPU_4G
            - E2_STANDARD_2
            - E2_STANDARD_4
            - E2_STANDARD_8
            - E2_STANDARD_16
            - E2_STANDARD_32
            - E2_HIGHMEM_2
            - E2_HIGHMEM_4
            - E2_HIGHMEM_8
            - E2_HIGHMEM_16
            - E2_HIGHCPU_2
            - E2_HIGHCPU_4
            - E2_HIGHCPU_8
            - E2_HIGHCPU_16
            - E2_HIGHCPU_32
            - N2_STANDARD_2
            - N2_STANDARD_4
            - N2_STANDARD_8
            - N2_STANDARD_16
            - N2_STANDARD_32
            - N2_STANDARD_48
            - N2_STANDARD_64
            - N2_STANDARD_80
            - N2_STANDARD_96
            - N2_STANDARD_128
            - N2_HIGHMEM_2
            - N2_HIGHMEM_4
            - N2_HIGHMEM_8
            - N2_HIGHMEM_16
            - N2_HIGHMEM_32
            - N2_HIGHMEM_48
            - N2_HIGHMEM_64
            - N2_HIGHMEM_80
            - N2_HIGHMEM_96
            - N2_HIGHMEM_128
            - N2_HIGHCPU_2
            - N2_HIGHCPU_4
            - N2_HIGHCPU_8
            - N2_HIGHCPU_16
            - N2_HIGHCPU_32
            - N2_HIGHCPU_48
            - N2_HIGHCPU_64
            - N2_HIGHCPU_80
            - N2_HIGHCPU_96
            - N2D_STANDARD_2
            - N2D_STANDARD_4
            - N2D_STANDARD_8
            - N2D_STANDARD_16
            - N2D_STANDARD_32
            - N2D_STANDARD_48
            - N2D_STANDARD_64
            - N2D_STANDARD_80
            - N2D_STANDARD_96
            - N2D_STANDARD_128
            - N2D_STANDARD_224
            - N2D_HIGHMEM_2
            - N2D_HIGHMEM_4
            - N2D_HIGHMEM_8
            - N2D_HIGHMEM_16
            - N2D_HIGHMEM_32
            - N2D_HIGHMEM_48
            - N2D_HIGHMEM_64
            - N2D_HIGHMEM_80
            - N2D_HIGHMEM_96
            - N2D_HIGHCPU_2
            - N2D_HIGHCPU_4
            - N2D_HIGHCPU_8
            - N2D_HIGHCPU_16
            - N2D_HIGHCPU_32
            - N2D_HIGHCPU_48
            - N2D_HIGHCPU_64
            - N2D_HIGHCPU_80
            - N2D_HIGHCPU_96
            - N2D_HIGHCPU_128
            - N2D_HIGHCPU_224
            - C2_STANDARD_4
            - C2_STANDARD_8
            - C2_STANDARD_16
            - C2_STANDARD_30
            - C2_STANDARD_60
            - C2D_STANDARD_2
            - C2D_STANDARD_4
            - C2D_STANDARD_8
            - C2D_STANDARD_16
            - C2D_STANDARD_32
            - C2D_STANDARD_56
            - C2D_STANDARD_112
            - C2D_HIGHCPU_2
            - C2D_HIGHCPU_4
            - C2D_HIGHCPU_8
            - C2D_HIGHCPU_16
            - C2D_HIGHCPU_32
            - C2D_HIGHCPU_56
            - C2D_HIGHCPU_112
            - C2D_HIGHMEM_2
            - C2D_HIGHMEM_4
            - C2D_HIGHMEM_8
            - C2D_HIGHMEM_16
            - C2D_HIGHMEM_32
            - C2D_HIGHMEM_56
            - C2D_HIGHMEM_112
            - G2_STANDARD_4
            - G2_STANDARD_8
            - G2_STANDARD_12
            - G2_STANDARD_16
            - G2_STANDARD_24
            - G2_STANDARD_32
            - G2_STANDARD_48
            - G2_STANDARD_96
            - G4_STANDARD_48
            - C3_STANDARD_4
            - C3_STANDARD_8
            - C3_STANDARD_22
            - C3_STANDARD_44
            - C3_STANDARD_88
            - C3_STANDARD_176
            - C3_HIGHCPU_4
            - C3_HIGHCPU_8
            - C3_HIGHCPU_22
            - C3_HIGHCPU_44
            - C3_HIGHCPU_88
            - C3_HIGHCPU_176
            - C3_HIGHMEM_4
            - C3_HIGHMEM_8
            - C3_HIGHMEM_22
            - C3_HIGHMEM_44
            - C3_HIGHMEM_88
            - C3_HIGHMEM_176
            - C4_STANDARD_8
            - C4_STANDARD_16
            - C4_STANDARD_24
            - C4_STANDARD_32
            - C4_STANDARD_48
            - C4_STANDARD_96
            - C4_STANDARD_144
            - C4_STANDARD_192
            - C4_STANDARD_288
            - C4_HIGHCPU_8
            - C4_HIGHCPU_16
            - C4_HIGHCPU_24
            - C4_HIGHCPU_32
            - C4_HIGHCPU_48
            - C4_HIGHCPU_96
            - C4_HIGHCPU_144
            - C4_HIGHCPU_192
            - C4_HIGHCPU_288
            - C4_HIGHMEM_8
            - C4_HIGHMEM_16
            - C4_HIGHMEM_24
            - C4_HIGHMEM_32
            - C4_HIGHMEM_48
            - C4_HIGHMEM_96
            - C4_HIGHMEM_144
            - C4_HIGHMEM_192
            - C4_HIGHMEM_288
          enumDescriptions:
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
        ramType:
          enumDescriptions:
            - ''
            - ''
            - ''
            - ''
            - ''
            - COMPUTE_OPTIMIZED
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - MEMORY_OPTIMIZED_UPGRADE_PREMIUM
            - MEMORY_OPTIMIZED
            - ''
            - ''
            - ''
            - ''
          enum:
            - UNKNOWN_RAM_TYPE
            - A2
            - A3
            - A4
            - A4X
            - C2
            - C2D
            - CUSTOM
            - E2
            - G2
            - G4
            - C4
            - C3
            - M2
            - M1
            - N1
            - N2_CUSTOM
            - N2
            - N2D
          type: string
          description: Required. Type of ram.
    XPSVisionErrorAnalysisConfig:
      description: 'The vision model error analysis configuration. Next tag: 3'
      properties:
        exampleCount:
          format: int32
          type: integer
          description: The number of query examples in error analysis.
        queryType:
          type: string
          enumDescriptions:
            - Unspecified query type for model error analysis.
            - Query similar samples across all classes in the dataset.
            - Query similar samples from the same class of the input sample.
            - Query dissimilar samples from the same class of the input sample.
          enum:
            - QUERY_TYPE_UNSPECIFIED
            - QUERY_TYPE_ALL_SIMILAR
            - QUERY_TYPE_SAME_CLASS_SIMILAR
            - QUERY_TYPE_SAME_CLASS_DISSIMILAR
          description: >-
            The query type used in retrieval. The enum values are frozen in the
            foreseeable future.
      type: object
      id: XPSVisionErrorAnalysisConfig
    XPSRegressionMetricsEntry:
      properties:
        trueValue:
          description: The actual target value for a row in the dataset.
          type: number
          format: float
        predictedValue:
          format: float
          type: number
          description: The observed value for a row in the dataset.
      id: XPSRegressionMetricsEntry
      type: object
      description: A pair of actual & observed values for the model being evaluated.
    XPSColumnSpecForecastingMetadata:
      properties:
        columnType:
          enum:
            - COLUMN_TYPE_UNSPECIFIED
            - KEY
            - KEY_METADATA
            - TIME_SERIES_AVAILABLE_PAST_ONLY
            - TIME_SERIES_AVAILABLE_PAST_AND_FUTURE
          description: The type of the column for FORECASTING model training purposes.
          type: string
          enumDescriptions:
            - An un-set value of this enum.
            - Key columns are used to identify timeseries.
            - >-
              This column contains information describing static properties of
              the entities identified by the key column(s) (e.g. city's ZIP
              code).
            - >-
              This column contains information for the given entity, at any time
              poinrt, they are only available in the time series before.
            - >-
              This column contains information for the given entity is known
              both for the past and the sufficiently far future.
      id: XPSColumnSpecForecastingMetadata
      type: object
    XPSDataErrors:
      id: XPSDataErrors
      description: Different types of errors and the stats associatesd with each error.
      type: object
      properties:
        count:
          type: integer
          description: Number of records having errors associated with the enum.
          format: int32
        errorType:
          enum:
            - ERROR_TYPE_UNSPECIFIED
            - UNSUPPORTED_AUDIO_FORMAT
            - FILE_EXTENSION_MISMATCH_WITH_AUDIO_FORMAT
            - FILE_TOO_LARGE
            - MISSING_TRANSCRIPTION
          enumDescriptions:
            - Not specified.
            - >-
              Audio format not in the formats by cloud-speech AutoML. Currently
              only wav and flac file formats are supported.
            - >-
              File format differnt from what is specified in the file name
              extension.
            - File too large. Maximum allowed size is 50 MB.
            - Transcript is missing.
          description: Type of the error.
          type: string
    XPSFileSpec:
      id: XPSFileSpec
      type: object
      description: >-
        Spec of input and output files, on external file systems (for example,
        Colossus Namespace System or Google Cloud Storage).
      properties:
        fileFormat:
          type: string
          enumDescriptions:
            - ''
            - ''
            - Internal format for parallel text data used by Google Translate.
            - ''
            - >-
              Only the lexicographically first file described by the file_spec
              contains the header line.
            - ''
          enumDeprecated:
            - false
            - true
            - false
            - false
            - false
            - false
          enum:
            - FILE_FORMAT_UNKNOWN
            - FILE_FORMAT_SSTABLE
            - FILE_FORMAT_TRANSLATION_RKV
            - FILE_FORMAT_RECORDIO
            - FILE_FORMAT_RAW_CSV
            - FILE_FORMAT_RAW_CAPACITOR
        fileSpec:
          type: string
          description: >-
            Single file path, or file pattern of format
            "/path/to/file@shard_count". E.g. /cns/cell-d/somewhere/file@2 is
            expanded to two files: /cns/cell-d/somewhere/file-00000-of-00002 and
            /cns/cell-d/somewhere/file-00001-of-00002.
        singleFilePath:
          type: string
          description: Deprecated. Use file_spec.
          deprecated: true
        directoryPath:
          deprecated: true
          description: Deprecated. Use file_spec.
          type: string
    XPSConfidenceMetricsEntry:
      description: >-
        ConfidenceMetricsEntry includes generic precision, recall, f1 score etc.
        Next tag: 16.
      id: XPSConfidenceMetricsEntry
      properties:
        precision:
          type: number
          description: Precision for the given confidence threshold.
          format: float
        confidenceThreshold:
          description: >-
            Metrics are computed with an assumption that the model never return
            predictions with score lower than this value.
          format: float
          type: number
        falsePositiveRateAt1:
          type: number
          description: >-
            The False Positive Rate when only considering the label that has the
            highest prediction score and not below the confidence threshold for
            each example.
          format: float
        falsePositiveCount:
          type: string
          format: int64
          description: >-
            The number of model created labels that do not match a ground truth
            label.
        precisionAt1:
          format: float
          description: >-
            The precision when only considering the label that has the highest
            prediction score and not below the confidence threshold for each
            example.
          type: number
        falsePositiveRate:
          type: number
          description: False Positive Rate for the given confidence threshold.
          format: float
        recallAt1:
          format: float
          type: number
          description: >-
            The recall (true positive rate) when only considering the label that
            has the highest prediction score and not below the confidence
            threshold for each example.
        positionThreshold:
          format: int32
          type: integer
          description: >-
            Metrics are computed with an assumption that the model always
            returns at most this many predictions (ordered by their score,
            descendingly), but they all still need to meet the
            confidence_threshold.
        trueNegativeCount:
          format: int64
          type: string
          description: >-
            The number of labels that were not created by the model, but if they
            would, they would not match a ground truth label.
        f1Score:
          format: float
          type: number
          description: The harmonic mean of recall and precision.
        truePositiveCount:
          type: string
          format: int64
          description: The number of model created labels that match a ground truth label.
        f1ScoreAt1:
          description: The harmonic mean of recall_at1 and precision_at1.
          type: number
          format: float
        falseNegativeCount:
          type: string
          format: int64
          description: >-
            The number of ground truth labels that are not matched by a model
            created label.
        recall:
          description: Recall (true positive rate) for the given confidence threshold.
          type: number
          format: float
      type: object
    XPSExampleSet:
      type: object
      description: Set of examples or input sources.
      id: XPSExampleSet
      properties:
        fileSpec:
          description: File spec of the examples or input sources.
          $ref: '#/components/schemas/XPSFileSpec'
        numInputSources:
          type: string
          format: int64
          description: Number of input sources.
        numExamples:
          type: string
          description: Number of examples.
          format: int64
        fingerprint:
          type: string
          description: Fingerprint of the example set.
          format: int64
    XPSImageExportModelSpec:
      properties:
        exportModelOutputConfig:
          description: >-
            Contains the model format and internal location of the model files
            to be exported/downloaded. Use the Google Cloud Storage bucket name
            which is provided via TrainRequest.gcs_bucket_name to store the
            model files.
          type: array
          items:
            $ref: '#/components/schemas/XPSExportModelOutputConfig'
      description: >-
        Information of downloadable models that are pre-generated as part of
        training flow and will be persisted in AutoMl backend. Upon receiving
        ExportModel request from user, AutoMl backend can serve the
        pre-generated models to user if exists (by copying the files from
        internal path to user provided location), otherwise, AutoMl backend will
        call xPS ExportModel API to generate the model on the fly with the
        requesting format.
      id: XPSImageExportModelSpec
      type: object
    XPSTextComponentModel:
      description: Component model.
      properties:
        onlinePredictionModelGcsUri:
          description: The Cloud Storage resource path to hold online prediction model.
          type: string
        partition:
          type: string
          description: >-
            The partition where the model is deployed. Populated by uCAIP BE as
            part of online PredictRequest.
          enumDescriptions:
            - ''
            - The default partition.
            - >-
              It has significantly lower replication than partition-0 and is
              located in the US only. It also has a larger model size limit and
              higher default RAM quota than partition-0. Customers with batch
              traffic, US-based traffic, or very large models should use this
              partition. Capacity in this partition is significantly cheaper
              than partition-0.
            - To be used by customers with Jellyfish-accelerated ops.
            - The partition used by regionalized servomatic cloud regions.
            - The partition used for loading models from custom storage.
          enum:
            - PARTITION_TYPE_UNSPECIFIED
            - PARTITION_ZERO
            - PARTITION_REDUCED_HOMING
            - PARTITION_JELLYFISH
            - PARTITION_CPU
            - PARTITION_CUSTOM_STORAGE_CPU
        tfRuntimeVersion:
          description: >-
            ## The fields below are only populated under uCAIP request scope.
            https://cloud.google.com/ml-engine/docs/runtime-version-list
          type: string
        servingArtifact:
          $ref: '#/components/schemas/XPSModelArtifactItem'
          description: >-
            The default model binary file used for serving (e.g. online predict,
            batch predict) via public Cloud Ai Platform API.
        batchPredictionModelGcsUri:
          description: The Cloud Storage resource path to hold batch prediction model.
          type: string
        submodelType:
          enum:
            - TEXT_MODEL_TYPE_UNSPECIFIED
            - TEXT_MODEL_TYPE_DEFAULT
            - TEXT_MODEL_TYPE_META_ARCHITECT
            - TEXT_MODEL_TYPE_ATC
            - TEXT_MODEL_TYPE_CLARA2
            - TEXT_MODEL_TYPE_CHATBASE
            - TEXT_MODEL_TYPE_SAFT_SPAN_LABELING
            - TEXT_MODEL_TYPE_TEXT_EXTRACTION
            - TEXT_MODEL_TYPE_RELATIONSHIP_EXTRACTION
            - TEXT_MODEL_TYPE_COMPOSITE
            - TEXT_MODEL_TYPE_ALL_MODELS
            - TEXT_MODEL_TYPE_BERT
            - TEXT_MODEL_TYPE_ENC_PALM
          enumDescriptions:
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
            - Model type for entity extraction.
            - Model type for relationship extraction.
            - >-
              A composite model represents a set of component models that have
              to be used together for prediction. A composite model appears to
              be a single model to the model user. It may contain only one
              component model.
            - >-
              Model type used to train default, MA, and ATC models in a single
              batch worker pipeline.
            - >-
              BERT pipeline needs a specific model type, since it uses a
              different TFX configuration compared with DEFAULT (despite sharing
              most of the code).
            - Model type for EncPaLM.
          type: string
          description: The type of trained NL submodel
        submodelName:
          description: The name of the trained NL submodel.
          type: string
        servoModelName:
          type: string
          description: >-
            The name of servo model. Populated by uCAIP BE as part of online
            PredictRequest.
        versionNumber:
          description: >-
            The servomatic model version number. Populated by uCAIP BE as part
            of online PredictRequest.
          type: string
          format: int64
      id: XPSTextComponentModel
      type: object
    EntityMention:
      type: object
      properties:
        probability:
          type: number
          format: float
          description: >-
            Probability score associated with the entity. The score shows the
            probability of the entity mention being the entity type. The score
            is in (0, 1] range.
        text:
          $ref: '#/components/schemas/TextSpan'
          description: The mention text.
        sentiment:
          description: >-
            For calls to AnalyzeEntitySentiment this field will contain the
            sentiment expressed for this mention of the entity in the provided
            document.
          $ref: '#/components/schemas/Sentiment'
        type:
          type: string
          enum:
            - TYPE_UNKNOWN
            - PROPER
            - COMMON
          description: The type of the entity mention.
          enumDescriptions:
            - Unknown
            - Proper name
            - Common noun (or noun compound)
      id: EntityMention
      description: >-
        Represents a mention for an entity in the text. Currently, proper noun
        mentions are supported.
    XPSColorMapIntColor:
      type: object
      properties:
        red:
          format: int32
          type: integer
          description: The value should be in range of [0, 255].
        blue:
          format: int32
          description: The value should be in range of [0, 255].
          type: integer
        green:
          format: int32
          description: The value should be in range of [0, 255].
          type: integer
      id: XPSColorMapIntColor
      description: RGB color and each channel is represented by an integer.
    XPSTimestampStats:
      properties:
        medianTimestampNanos:
          format: int64
          type: string
        granularStats:
          type: object
          description: >-
            The string key is the pre-defined granularity. Currently supported:
            hour_of_day, day_of_week, month_of_year. Granularities finer that
            the granularity of timestamp data are not populated (e.g. if
            timestamps are at day granularity, then hour_of_day is not
            populated).
          additionalProperties:
            $ref: '#/components/schemas/XPSTimestampStatsGranularStats'
        commonStats:
          $ref: '#/components/schemas/XPSCommonStats'
      id: XPSTimestampStats
      description: The data statistics of a series of TIMESTAMP values.
      type: object
    XPSVideoTrainingOperationMetadata:
      id: XPSVideoTrainingOperationMetadata
      type: object
      properties:
        trainCostMilliNodeHour:
          type: string
          description: >-
            This is an estimation of the node hours necessary for training a
            model, expressed in milli node hours (i.e. 1,000 value in this field
            means 1 node hour). A node hour represents the time a virtual
            machine spends running your training job. The cost of one node
            running for one hour is a node hour.
          format: int64
    ClassifyTextRequest:
      properties:
        document:
          description: Required. Input document.
          $ref: '#/components/schemas/Document'
      id: ClassifyTextRequest
      description: The document classification request message.
      type: object
    XPSClassificationEvaluationMetrics:
      properties:
        baseAuPrc:
          type: number
          format: float
          description: The Area under precision recall curve metric based on priors.
        confusionMatrix:
          description: >-
            Confusion matrix of the evaluation. Only set for MULTICLASS
            classification problems where number of annotation specs is no more
            than 10. Only set for model level evaluation, not for evaluation per
            label.
          $ref: '#/components/schemas/XPSConfusionMatrix'
        auRoc:
          format: float
          type: number
          description: >-
            The Area Under Receiver Operating Characteristic curve metric.
            Micro-averaged for the overall evaluation.
        confidenceMetricsEntries:
          items:
            $ref: '#/components/schemas/XPSConfidenceMetricsEntry'
          type: array
          description: >-
            Metrics that have confidence thresholds. Precision-recall curve can
            be derived from it.
        evaluatedExamplesCount:
          type: integer
          format: int32
          description: The number of examples used for model evaluation.
        logLoss:
          type: number
          description: The Log Loss metric.
          format: float
        auPrc:
          format: float
          type: number
          description: The Area under precision recall curve metric.
      id: XPSClassificationEvaluationMetrics
      description: >-
        Model evaluation metrics for classification problems. It can be used for
        image and video classification. Next tag: 9.
      type: object
    ModerateTextRequest:
      id: ModerateTextRequest
      description: The document moderation request message.
      type: object
      properties:
        document:
          $ref: '#/components/schemas/Document'
          description: Required. Input document.
        modelVersion:
          description: Optional. The model version to use for ModerateText.
          enum:
            - MODEL_VERSION_UNSPECIFIED
            - MODEL_VERSION_1
            - MODEL_VERSION_2
          type: string
          enumDescriptions:
            - The default model version.
            - >-
              Use the v1 model, this model is used by default when not provided.
              The v1 model only returns probability (confidence) score for each
              category.
            - >-
              Use the v2 model. The v2 model only returns probability
              (confidence) score for each category, and returns severity score
              for a subset of the categories.
    XPSTranslationTrainResponse:
      description: Train response for translation.
      id: XPSTranslationTrainResponse
      properties:
        modelType:
          enumDescriptions:
            - Default
            - Legacy model. Will be deprecated.
            - Current model.
          enum:
            - MODEL_TYPE_UNSPECIFIED
            - LEGACY
            - CURRENT
          description: Type of the model.
          type: string
      type: object
    XPSTextToSpeechTrainResponse:
      type: object
      id: XPSTextToSpeechTrainResponse
      description: TextToSpeech train response
      properties: {}
    XPSDataType:
      id: XPSDataType
      properties:
        typeCode:
          description: Required. The TypeCode for this type.
          enum:
            - TYPE_CODE_UNSPECIFIED
            - FLOAT64
            - TIMESTAMP
            - STRING
            - ARRAY
            - STRUCT
            - CATEGORY
          type: string
          enumDescriptions:
            - Not specified. Should not be used.
            - >-
              Encoded as `number`, or the strings `"NaN"`, `"Infinity"`, or
              `"-Infinity"`.
            - >-
              Must be between 0AD and 9999AD. Encoded as `string` according to
              time_format, or, if that format is not set, then in RFC 3339
              `date-time` format, where `time-offset` = `"Z"` (e.g.
              1985-04-12T23:20:50.52Z).
            - Encoded as `string`.
            - >-
              Encoded as `list`, where the list elements are represented
              according to list_element_type.
            - >-
              Encoded as `struct`, where field values are represented according
              to struct_type.
            - >-
              Values of this type are not further understood by AutoML, e.g.
              AutoML is unable to tell the order of values (as it could with
              FLOAT64), or is unable to say if one value contains another (as it
              could with STRING). Encoded as `string` (bytes should be
              base64-encoded, as described in RFC 4648, section 4).
        timeFormat:
          description: >-
            If type_code == TIMESTAMP then `time_format` provides the format in
            which that time field is expressed. The time_format must be written
            in `strftime` syntax. If time_format is not set, then the default
            format as described on the field is used.
          type: string
        listElementType:
          $ref: '#/components/schemas/XPSDataType'
          description: >-
            If type_code == ARRAY, then `list_element_type` is the type of the
            elements.
        structType:
          description: >-
            If type_code == STRUCT, then `struct_type` provides type information
            for the struct's fields.
          $ref: '#/components/schemas/XPSStructType'
        nullable:
          type: boolean
          description: If true, this DataType can also be `null`.
        compatibleDataTypes:
          description: The highly compatible data types to this data type.
          type: array
          items:
            $ref: '#/components/schemas/XPSDataType'
      description: >-
        Indicated the type of data that can be stored in a structured data
        entity (e.g. a table).
      type: object
    TpuMetric:
      type: object
      id: TpuMetric
      properties:
        tpuType:
          type: string
          enum:
            - UNKNOWN_TPU_TYPE
            - TPU_V2_POD
            - TPU_V2
            - TPU_V3_POD
            - TPU_V3
            - TPU_V5_LITEPOD
          description: Required. Type of TPU, e.g. TPU_V2, TPU_V3_POD.
          enumDescriptions:
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
        tpuSec:
          format: int64
          type: string
          description: Required. Seconds of TPU usage, e.g. 3600.
    ClassifyTextResponse:
      id: ClassifyTextResponse
      description: The document classification response message.
      type: object
      properties:
        categories:
          type: array
          items:
            $ref: '#/components/schemas/ClassificationCategory'
          description: Categories representing the input document.
        languageCode:
          description: >-
            The language of the text, which will be the same as the language
            specified in the request or, if not specified, the
            automatically-detected language. See Document.language_code field
            for more details.
          type: string
        languageSupported:
          description: >-
            Whether the language is officially supported. The API may still
            return a response when the language is not supported, but it is on a
            best effort basis.
          type: boolean
    DiskMetric:
      properties:
        diskType:
          type: string
          enumDescriptions:
            - ''
            - ''
            - ''
            - ''
            - ''
            - ''
          enum:
            - UNKNOWN_DISK_TYPE
            - REGIONAL_SSD
            - REGIONAL_STORAGE
            - PD_SSD
            - PD_STANDARD
            - STORAGE_SNAPSHOT
          description: Required. Type of Disk, e.g. REGIONAL_SSD.
        gibSec:
          description: Required. Seconds of physical disk usage, e.g. 3600.
          type: string
          format: int64
      id: DiskMetric
      type: object
    XPSTimestampStatsGranularStats:
      id: XPSTimestampStatsGranularStats
      properties:
        buckets:
          type: object
          description: >-
            A map from granularity key to example count for that key. E.g. for
            hour_of_day `13` means 1pm, or for month_of_year `5` means May).
          additionalProperties:
            format: int64
            type: string
      description: Stats split by a defined in context granularity.
      type: object
    XPSExportModelOutputConfig:
      id: XPSExportModelOutputConfig
      properties:
        edgeTpuTfLiteFormat:
          $ref: '#/components/schemas/XPSEdgeTpuTfLiteFormat'
        outputGcrUri:
          description: >-
            The Google Contained Registry path the exported files to be pushed
            to. This location is set if the exported format is DOCKDER.
          type: string
        coreMlFormat:
          $ref: '#/components/schemas/XPSCoreMlFormat'
        tfSavedModelFormat:
          $ref: '#/components/schemas/XPSTfSavedModelFormat'
        outputGcsUri:
          type: string
          description: >-
            The Google Cloud Storage directory where XPS will output the
            exported models and related files. Format: gs://bucket/directory
        tfLiteFormat:
          $ref: '#/components/schemas/XPSTfLiteFormat'
        dockerFormat:
          $ref: '#/components/schemas/XPSDockerFormat'
        tfJsFormat:
          $ref: '#/components/schemas/XPSTfJsFormat'
        exportFirebaseAuxiliaryInfo:
          type: boolean
          description: >-
            For any model and format: If true, will additionally export
            FirebaseExportedModelInfo in a firebase.txt file.
      type: object
    XPSVideoExportModelSpec:
      description: >-
        Information of downloadable models that are pre-generated as part of
        training flow and will be persisted in AutoMl backend. Upon receiving
        ExportModel request from user, AutoMl backend can serve the
        pre-generated models to user if exists (by copying the files from
        internal path to user provided location), otherwise, AutoMl backend will
        call xPS ExportModel API to generate the model on the fly with the
        requesting format.
      type: object
      properties:
        exportModelOutputConfig:
          description: >-
            Contains the model format and internal location of the model files
            to be exported/downloaded. Use the Google Cloud Storage bucket name
            which is provided via TrainRequest.gcs_bucket_name to store the
            model files.
          type: array
          items:
            $ref: '#/components/schemas/XPSExportModelOutputConfig'
      id: XPSVideoExportModelSpec
    XPSSpeechModelSpecSubModelSpec:
      type: object
      id: XPSSpeechModelSpecSubModelSpec
      properties:
        isEnhancedModel:
          type: boolean
          description: >-
            If true then it means we have an enhanced version of the biasing
            models.
        clientId:
          description: In S3, Recognition ClientContextId.client_id
          type: string
        contextId:
          type: string
          description: In S3, Recognition ClientContextId.context_id
        biasingModelType:
          type: string
          enum:
            - BIASING_MODEL_TYPE_UNSPECIFIED
            - COMMAND_AND_SEARCH
            - PHONE_CALL
            - VIDEO
            - DEFAULT
          description: Type of the biasing model.
          enumDescriptions:
            - ''
            - Build biasing model on top of COMMAND_AND_SEARCH model
            - Build biasing model on top of PHONE_CALL model
            - Build biasing model on top of VIDEO model
            - Build biasing model on top of DEFAULT model
    XPSSpeechPreprocessResponse:
      id: XPSSpeechPreprocessResponse
      properties:
        cnsTrainDataPath:
          description: >-
            Location of shards of sstables (training data) of DataUtterance
            protos.
          type: string
        prebuiltModelEvaluationMetrics:
          $ref: '#/components/schemas/XPSSpeechEvaluationMetrics'
          description: >-
            The metrics for prebuilt speech models. They are included here
            because there is no prebuilt speech models stored in the AutoML.
        speechPreprocessStats:
          $ref: '#/components/schemas/XPSSpeechPreprocessStats'
          description: Stats associated with the data.
        cnsTestDataPath:
          description: Location od shards of sstables (test data) of DataUtterance protos.
          type: string
      type: object
    XPSTablesModelColumnInfo:
      properties:
        featureImportance:
          format: float
          description: >-
            When given as part of a Model: Measurement of how much model
            predictions correctness on the TEST data depend on values in this
            column. A value between 0 and 1, higher means higher influence.
            These values are normalized - for all input feature columns of a
            given model they add to 1. When given back by Predict or Batch
            Predict: Measurement of how impactful for the prediction returned
            for the given row the value in this column was. Specifically, the
            feature importance specifies the marginal contribution that the
            feature made to the prediction score compared to the baseline score.
            These values are computed using the Sampled Shapley method.
          type: number
        columnId:
          description: The ID of the column.
          type: integer
          format: int32
      type: object
      id: XPSTablesModelColumnInfo
      description: >-
        An information specific to given column and Tables Model, in context of
        the Model and the predictions created by it.
    XPSResponseExplanationMetadata:
      deprecated: true
      type: object
      properties:
        outputs:
          additionalProperties:
            $ref: '#/components/schemas/XPSResponseExplanationMetadataOutputMetadata'
          description: Metadata of the output.
          type: object
        inputs:
          type: object
          additionalProperties:
            $ref: '#/components/schemas/XPSResponseExplanationMetadataInputMetadata'
          description: Metadata of the input.
      id: XPSResponseExplanationMetadata
    XPSImageClassificationTrainResponse:
      id: XPSImageClassificationTrainResponse
      properties:
        exportModelSpec:
          $ref: '#/components/schemas/XPSImageExportModelSpec'
          description: >-
            Information of downloadable models that are pre-generated as part of
            training flow and will be persisted in AutoMl backend. Populated for
            AutoMl requests.
        trainCostNodeSeconds:
          description: >-
            The actual training cost, expressed in node seconds. Populated for
            models trained in node time.
          type: string
          format: int64
        modelArtifactSpec:
          description: '## The fields below are only populated under uCAIP request scope.'
          $ref: '#/components/schemas/XPSImageModelArtifactSpec'
        trainCostInNodeTime:
          description: >-
            The actual cost to create this model. - For edge type model, the
            cost is expressed in node hour. - For cloud type model,the cost is
            expressed in compute hour. - Populated for models created before GA.
            To be deprecated after GA.
          format: google-duration
          type: string
        modelServingSpec:
          $ref: '#/components/schemas/XPSImageModelServingSpec'
        classCount:
          description: Total number of classes.
          format: int64
          type: string
        stopReason:
          enumDescriptions:
            - ''
            - ''
            - Model fully converged, can not be resumbed training.
            - >-
              Model early converged, can be further trained till full
              convergency.
          description: >-
            Stop reason for training job, e.g. 'TRAIN_BUDGET_REACHED',
            'MODEL_CONVERGED', 'MODEL_EARLY_STOPPED'.
          type: string
          enum:
            - TRAIN_STOP_REASON_UNSPECIFIED
            - TRAIN_STOP_REASON_BUDGET_REACHED
            - TRAIN_STOP_REASON_MODEL_CONVERGED
            - TRAIN_STOP_REASON_MODEL_EARLY_STOPPED
      type: object
    XPSStringStats:
      id: XPSStringStats
      type: object
      description: The data statistics of a series of STRING values.
      properties:
        topUnigramStats:
          items:
            $ref: '#/components/schemas/XPSStringStatsUnigramStats'
          type: array
          description: >-
            The statistics of the top 20 unigrams, ordered by
            StringStats.UnigramStats.count.
        commonStats:
          $ref: '#/components/schemas/XPSCommonStats'
    XPSEvaluationMetricsSet:
      description: Specifies location of model evaluation metrics.
      type: object
      properties:
        fileSpec:
          $ref: '#/components/schemas/XPSFileSpec'
          description: >-
            File spec containing evaluation metrics of a model, must point to
            RecordIO file(s) of intelligence.cloud.automl.xps.EvaluationMetrics
            messages.
        numEvaluationMetrics:
          type: string
          description: >-
            Number of the evaluation metrics (usually one per label plus
            overall).
          format: int64
        evaluationMetrics:
          items:
            $ref: '#/components/schemas/XPSEvaluationMetrics'
          description: >-
            Inline EvaluationMetrics - should be relatively small. For passing
            large quantities of exhaustive metrics, use file_spec.
          type: array
      id: XPSEvaluationMetricsSet
    InfraUsage:
      id: InfraUsage
      description: 'LINT: LEGACY_NAMES Infra Usage of billing metrics.'
      type: object
      properties:
        gpuMetrics:
          items:
            $ref: '#/components/schemas/GpuMetric'
          description: Aggregated gpu metrics since requested start_time.
          type: array
        diskMetrics:
          type: array
          items:
            $ref: '#/components/schemas/DiskMetric'
          description: Aggregated persistent disk metrics since requested start_time.
        tpuMetrics:
          description: Aggregated tpu metrics since requested start_time.
          items:
            $ref: '#/components/schemas/TpuMetric'
          type: array
        cpuMetrics:
          items:
            $ref: '#/components/schemas/CpuMetric'
          description: Aggregated core metrics since requested start_time.
          type: array
        ramMetrics:
          description: Aggregated ram metrics since requested start_time.
          type: array
          items:
            $ref: '#/components/schemas/RamMetric'
    XPSStringStatsUnigramStats:
      id: XPSStringStatsUnigramStats
      properties:
        value:
          description: The unigram.
          type: string
        count:
          type: string
          description: The number of occurrences of this unigram in the series.
          format: int64
      description: The statistics of a unigram.
      type: object
    XPSImageObjectDetectionEvaluationMetrics:
      properties:
        evaluatedBoundingBoxCount:
          type: integer
          format: int32
          description: >-
            The total number of bounding boxes (i.e. summed over all images) the
            ground truth used to create this evaluation had.
        boundingBoxMeanAveragePrecision:
          type: number
          format: float
          description: >-
            The single metric for bounding boxes evaluation: the
            mean_average_precision averaged over all
            bounding_box_metrics_entries.
        boundingBoxMetricsEntries:
          type: array
          description: >-
            The bounding boxes match metrics for each Intersection-over-union
            threshold 0.05,0.10,...,0.95,0.96,0.97,0.98,0.99 and each label
            confidence threshold 0.05,0.10,...,0.95,0.96,0.97,0.98,0.99 pair.
          items:
            $ref: '#/components/schemas/XPSBoundingBoxMetricsEntry'
      id: XPSImageObjectDetectionEvaluationMetrics
      description: >-
        Model evaluation metrics for image object detection problems. Evaluates
        prediction quality of labeled bounding boxes.
      type: object
    ModerateTextResponse:
      properties:
        moderationCategories:
          type: array
          items:
            $ref: '#/components/schemas/ClassificationCategory'
          description: Harmful and sensitive categories representing the input document.
        languageSupported:
          type: boolean
          description: >-
            Whether the language is officially supported. The API may still
            return a response when the language is not supported, but it is on a
            best effort basis.
        languageCode:
          description: >-
            The language of the text, which will be the same as the language
            specified in the request or, if not specified, the
            automatically-detected language. See Document.language_code field
            for more details.
          type: string
      description: The document moderation response message.
      type: object
      id: ModerateTextResponse
    XPSVisualization:
      type: object
      deprecated: true
      id: XPSVisualization
      properties:
        colorMap:
          enumDescriptions:
            - Should not be used.
            - 'Positive: green. Negative: pink.'
            - >-
              Viridis color map: A perceptually uniform color mapping which is
              easier to see by those with colorblindness and progresses from
              yellow to green to blue. Positive: yellow. Negative: blue.
            - 'Positive: red. Negative: red.'
            - 'Positive: green. Negative: green.'
            - 'Positive: green. Negative: red.'
            - PiYG palette.
          enum:
            - COLOR_MAP_UNSPECIFIED
            - PINK_GREEN
            - VIRIDIS
            - RED
            - GREEN
            - RED_GREEN
            - PINK_WHITE_GREEN
          description: >-
            The color scheme used for the highlighted areas. Defaults to
            PINK_GREEN for Integrated Gradients attribution, which shows
            positive attributions in green and negative in pink. Defaults to
            VIRIDIS for XRAI attribution, which highlights the most influential
            regions in yellow and the least influential in blue.
          type: string
        polarity:
          type: string
          description: >-
            Whether to only highlight pixels with positive contributions,
            negative or both. Defaults to POSITIVE.
          enumDescriptions:
            - Default value. This is the same as POSITIVE.
            - >-
              Highlights the pixels/outlines that were most influential to the
              model's prediction.
            - >-
              Setting polarity to negative highlights areas that does not lead
              to the models's current prediction.
            - Shows both positive and negative attributions.
          enum:
            - POLARITY_UNSPECIFIED
            - POSITIVE
            - NEGATIVE
            - BOTH
        clipPercentLowerbound:
          description: >-
            Excludes attributions below the specified percentile, from the
            highlighted areas. Defaults to 62.
          format: float
          type: number
        type:
          type: string
          enum:
            - TYPE_UNSPECIFIED
            - PIXELS
            - OUTLINES
          enumDescriptions:
            - Should not be used.
            - Shows which pixel contributed to the image prediction.
            - >-
              Shows which region contributed to the image prediction by
              outlining the region.
          description: >-
            Type of the image visualization. Only applicable to Integrated
            Gradients attribution. OUTLINES shows regions of attribution, while
            PIXELS shows per-pixel attribution. Defaults to OUTLINES.
        overlayType:
          enumDescriptions:
            - Default value. This is the same as NONE.
            - No overlay.
            - The attributions are shown on top of the original image.
            - >-
              The attributions are shown on top of grayscaled version of the
              original image.
            - >-
              The attributions are used as a mask to reveal predictive parts of
              the image and hide the un-predictive parts.
          description: >-
            How the original image is displayed in the visualization. Adjusting
            the overlay can help increase visual clarity if the original image
            makes it difficult to view the visualization. Defaults to NONE.
          enum:
            - OVERLAY_TYPE_UNSPECIFIED
            - NONE
            - ORIGINAL
            - GRAYSCALE
            - MASK_BLACK
          type: string
        clipPercentUpperbound:
          type: number
          format: float
          description: >-
            Excludes attributions above the specified percentile from the
            highlighted areas. Using the clip_percent_upperbound and
            clip_percent_lowerbound together can be useful for filtering out
            noise and making it easier to see areas of strong attribution.
            Defaults to 99.9.
      description: Visualization configurations for image explanation.
    XPSResponseExplanationMetadataInputMetadata:
      properties:
        modality:
          type: string
          enum:
            - MODALITY_UNSPECIFIED
            - NUMERIC
            - IMAGE
            - CATEGORICAL
          description: >-
            Modality of the feature. Valid values are: numeric, image. Defaults
            to numeric.
          enumDescriptions:
            - ''
            - ''
            - ''
            - ''
        inputTensorName:
          type: string
          description: >-
            Name of the input tensor for this model. Only needed in train
            response.
        visualizationConfig:
          description: Visualization configurations for image explanation.
          $ref: '#/components/schemas/XPSVisualization'
      id: XPSResponseExplanationMetadataInputMetadata
      description: Metadata of the input of a feature.
      type: object
    XPSColorMap:
      id: XPSColorMap
      type: object
      description: >-
        Map from color to display name. Will only be used by Image Segmentation
        for uCAIP.
      properties:
        displayName:
          description: Should be used during preprocessing.
          type: string
        intColor:
          $ref: '#/components/schemas/XPSColorMapIntColor'
        color:
          description: >-
            This type is deprecated in favor of the IntColor below. This is
            because google.type.Color represent color has a float which
            semantically does not reflect discrete classes/categories concept.
            Moreover, to handle it well we need to have some tolerance when
            converting to a discretized color. As such, the recommendation is to
            have API surface still use google.type.Color while internally
            IntColor is used.
          $ref: '#/components/schemas/Color'
          deprecated: true
        annotationSpecIdToken:
          type: string
          description: Should be used during training.
    XPSResponseExplanationSpec:
      id: XPSResponseExplanationSpec
      properties:
        parameters:
          description: Parameters that configure explaining of the Model's predictions.
          $ref: '#/components/schemas/XPSResponseExplanationParameters'
        metadata:
          description: Metadata describing the Model's input and output for explanation.
          $ref: '#/components/schemas/XPSResponseExplanationMetadata'
        explanationType:
          type: string
          description: >-
            Explanation type. For AutoML Image Classification models, possible
            values are: * `image-integrated-gradients` * `image-xrai`
      type: object
      deprecated: true
      description: >-
        Specification of Model explanation. Feature-based XAI in AutoML Vision
        ICN is deprecated.
    XPSColumnSpec:
      id: XPSColumnSpec
      properties:
        columnId:
          type: integer
          format: int32
          description: >-
            The unique id of the column. When Preprocess, the Tables BE will
            popuate the order id of the column, which reflects the order of the
            column inside the table, i.e. 0 means the first column in the table,
            N-1 means the last column. AutoML BE will persist this order id in
            Spanner and set the order id here when calling RefreshTablesStats
            and Train. Note: it's different than the column_spec_id that is
            generated in AutoML BE.
        dataType:
          $ref: '#/components/schemas/XPSDataType'
          description: >-
            The data type of the column. It's outputed in Preprocess rpc and a
            required input for RefreshTablesStats and Train.
        dataStats:
          description: >-
            The data stats of the column. It's outputed in RefreshTablesStats
            and a required input for Train.
          $ref: '#/components/schemas/XPSDataStats'
        displayName:
          type: string
          description: >-
            The display name of the column. It's outputed in Preprocess and a
            required input for RefreshTablesStats and Train.
        forecastingMetadata:
          $ref: '#/components/schemas/XPSColumnSpecForecastingMetadata'
        topCorrelatedColumns:
          items:
            $ref: '#/components/schemas/XPSColumnSpecCorrelatedColumn'
          type: array
          description: It's outputed in RefreshTablesStats, and a required input in Train.
      type: object
    XPSCategoryStatsSingleCategoryStats:
      properties:
        count:
          description: The number of occurrences of this value in the series.
          format: int64
          type: string
        value:
          description: The CATEGORY value.
          type: string
      type: object
      description: The statistics of a single CATEGORY value.
      id: XPSCategoryStatsSingleCategoryStats
    XPSRegressionEvaluationMetrics:
      type: object
      id: XPSRegressionEvaluationMetrics
      description: >-
        Model evaluation metrics for regression problems. It can be used for
        Tables.
      properties:
        rSquared:
          type: number
          description: R squared.
          format: float
        rootMeanSquaredLogError:
          format: float
          description: Root mean squared log error.
          type: number
        meanAbsoluteError:
          format: float
          type: number
          description: Mean Absolute Error (MAE).
        regressionMetricsEntries:
          description: >-
            A list of actual versus predicted points for the model being
            evaluated.
          type: array
          items:
            $ref: '#/components/schemas/XPSRegressionMetricsEntry'
        meanAbsolutePercentageError:
          description: >-
            Mean absolute percentage error. Only set if all ground truth values
            are positive.
          type: number
          format: float
        rootMeanSquaredError:
          description: Root Mean Squared Error (RMSE).
          type: number
          format: float
    AnalyzeEntitiesRequest:
      properties:
        document:
          $ref: '#/components/schemas/Document'
          description: Required. Input document.
        encodingType:
          type: string
          enumDescriptions:
            - >-
              If `EncodingType` is not specified, encoding-dependent information
              (such as `begin_offset`) will be set at `-1`.
            - >-
              Encoding-dependent information (such as `begin_offset`) is
              calculated based on the UTF-8 encoding of the input. C++ and Go
              are examples of languages that use this encoding natively.
            - >-
              Encoding-dependent information (such as `begin_offset`) is
              calculated based on the UTF-16 encoding of the input. Java and
              JavaScript are examples of languages that use this encoding
              natively.
            - >-
              Encoding-dependent information (such as `begin_offset`) is
              calculated based on the UTF-32 encoding of the input. Python is an
              example of a language that uses this encoding natively.
          enum:
            - NONE
            - UTF8
            - UTF16
            - UTF32
          description: The encoding type used by the API to calculate offsets.
      id: AnalyzeEntitiesRequest
      description: The entity analysis request message.
      type: object
    XPSTablesTrainResponse:
      properties:
        trainCostMilliNodeHours:
          format: int64
          type: string
          description: >-
            The actual training cost of the model, expressed in milli node
            hours, i.e. 1,000 value in this field means 1 node hour. Guaranteed
            to not exceed the train budget.
        modelStructure:
          $ref: '#/components/schemas/XPSTablesModelStructure'
        tablesModelColumnInfo:
          type: array
          items:
            $ref: '#/components/schemas/XPSTablesModelColumnInfo'
          description: >-
            Output only. Auxiliary information for each of the
            input_feature_column_specs, with respect to this particular model.
        predictionSampleRows:
          type: array
          description: Sample rows from the dataset this model was trained.
          items:
            $ref: '#/components/schemas/XPSRow'
      id: XPSTablesTrainResponse
      type: object
  parameters:
    access_token:
      description: OAuth access token.
      in: query
      name: access_token
      schema:
        type: string
    fields:
      description: Selector specifying which fields to include in a partial response.
      in: query
      name: fields
      schema:
        type: string
    quotaUser:
      description: >-
        Available to use for quota purposes for server-side applications. Can be
        any arbitrary string assigned to a user, but should not exceed 40
        characters.
      in: query
      name: quotaUser
      schema:
        type: string
    _.xgafv:
      description: V1 error format.
      in: query
      name: $.xgafv
      schema:
        type: string
        enum:
          - '1'
          - '2'
    prettyPrint:
      description: Returns response with indentations and line breaks.
      in: query
      name: prettyPrint
      schema:
        type: boolean
    uploadType:
      description: Legacy upload protocol for media (e.g. "media", "multipart").
      in: query
      name: uploadType
      schema:
        type: string
    key:
      description: >-
        API key. Your API key identifies your project and provides you with API
        access, quota, and reports. Required unless you provide an OAuth 2.0
        token.
      in: query
      name: key
      schema:
        type: string
    alt:
      description: Data format for response.
      in: query
      name: alt
      schema:
        type: string
        enum:
          - json
          - media
          - proto
    callback:
      description: JSONP
      in: query
      name: callback
      schema:
        type: string
    upload_protocol:
      description: Upload protocol for media (e.g. "raw", "multipart").
      in: query
      name: upload_protocol
      schema:
        type: string
    oauth_token:
      description: OAuth 2.0 token for the current user.
      in: query
      name: oauth_token
      schema:
        type: string
  x-stackQL-resources:
    documents:
      id: google.language.documents
      name: documents
      title: Documents
      methods:
        analyze_entities:
          operation:
            $ref: '#/paths/~1v2~1documents:analyzeEntities/post'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        annotate_text:
          operation:
            $ref: '#/paths/~1v2~1documents:annotateText/post'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        moderate_text:
          operation:
            $ref: '#/paths/~1v2~1documents:moderateText/post'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        analyze_sentiment:
          operation:
            $ref: '#/paths/~1v2~1documents:analyzeSentiment/post'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
        classify_text:
          operation:
            $ref: '#/paths/~1v2~1documents:classifyText/post'
          response:
            mediaType: application/json
            openAPIDocKey: '200'
      sqlVerbs:
        select: []
        insert: []
        update: []
        replace: []
        delete: []
paths:
  /v2/documents:analyzeEntities:
    parameters: &ref_1
      - $ref: '#/components/parameters/access_token'
      - $ref: '#/components/parameters/fields'
      - $ref: '#/components/parameters/quotaUser'
      - $ref: '#/components/parameters/_.xgafv'
      - $ref: '#/components/parameters/prettyPrint'
      - $ref: '#/components/parameters/uploadType'
      - $ref: '#/components/parameters/key'
      - $ref: '#/components/parameters/alt'
      - $ref: '#/components/parameters/callback'
      - $ref: '#/components/parameters/upload_protocol'
      - $ref: '#/components/parameters/oauth_token'
    post:
      description: >-
        Finds named entities (currently proper names and common nouns) in the
        text along with entity types, probability, mentions for each entity, and
        other properties.
      operationId: language.documents.analyzeEntities
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/AnalyzeEntitiesRequest'
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-language
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-language
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AnalyzeEntitiesResponse'
      parameters: []
  /v2/documents:annotateText:
    parameters: *ref_1
    post:
      description: A convenience method that provides all features in one call.
      operationId: language.documents.annotateText
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/AnnotateTextRequest'
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-language
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-language
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AnnotateTextResponse'
      parameters: []
  /v2/documents:moderateText:
    parameters: *ref_1
    post:
      description: Moderates a document for harmful and sensitive categories.
      operationId: language.documents.moderateText
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModerateTextRequest'
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-language
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-language
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModerateTextResponse'
      parameters: []
  /v2/documents:analyzeSentiment:
    parameters: *ref_1
    post:
      description: Analyzes the sentiment of the provided text.
      operationId: language.documents.analyzeSentiment
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/AnalyzeSentimentRequest'
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-language
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-language
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AnalyzeSentimentResponse'
      parameters: []
  /v2/documents:classifyText:
    parameters: *ref_1
    post:
      description: Classifies a document into categories.
      operationId: language.documents.classifyText
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ClassifyTextRequest'
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-language
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-language
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ClassifyTextResponse'
      parameters: []
